id,abstract,author,cites,cites_id,journal,number,pages,publisher,title,url,volume,year,citation_link,id_citations

1010000,"The quantitative evaluation of optical flow algorithms by Barron et al. (1994) led to significant advances in performance. The challenges for optical flow algorithms today go beyond the datasets and evaluation methods proposed in that paper. Instead, they center on problems associated with complex natural scenes, including nonrigid motion, real sensor noise, and motion discontinuities. We propose a new set of benchmarks and evaluation methods for the next generation of optical flow algorithms. To that end, we contribute four types of data to test different aspects of optical flow algorithms: (1) sequences with nonrigid motion where the ground-truth flow is determined by tracking hidden fluorescent texture, (2) realistic synthetic sequences, (3) high frame-rate video used to study interpolation error, and (4) modified stereo sequences of static scenes. In addition to the average angular error used by Barron et al …",Simon Baker and Daniel Scharstein and JP Lewis and Stefan Roth and Michael J Black and Richard Szeliski,2527,5697474256105237450,International journal of computer vision,1,1-31,Springer US,A database and evaluation methodology for optical flow,https://link.springer.com/content/pdf/10.1007/s11263-010-0390-2.pdf,92,2011,/scholar?cites=5697474256105237450,6NjbexEAAAAJ:Y0pCki6q_DkC

1010001,"Most approaches for estimating optical flow assume that, within a finite image region, only a single motion is present. Thissingle motion assumptionis violated in common situations involving transparency, depth discontinuities, independently moving objects, shadows, and specular reflections. To robustly estimate optical flow, the single motion assumption must be relaxed. This paper presents a framework based onrobust estimationthat addresses violations of the brightness constancy and spatial smoothness assumptions caused by multiple motions. We show how therobust estimation frameworkcan be applied to standard formulations of the optical flow problem thus reducing their sensitivity to violations of their underlying assumptions. The approach has been applied to three standard techniques for recovering optical flow: area-based regression, correlation, and regularization with motion discontinuities. This paper …",Michael J Black and P. Anandan,2084,2191279618413329639,Computer Vision and Image Understanding,1,75-104,Academic Press,The robust estimation of multiple motions: Parametric and piecewise-smooth flow fields,https://www.sciencedirect.com/science/article/pii/S1077314296900065,63,1996,/scholar?cites=2191279618413329639,6NjbexEAAAAJ:u5HHmVD_uO8C

1010002,"Relations between anisotropic diffusion and robust statistics are described in this paper. Specifically, we show that anisotropic diffusion can be seen as a robust estimation procedure that estimates a piecewise smooth image from a noisy input image. The ""edge-stopping"" function in the anisotropic diffusion equation is closely related to the error norm and influence function in the robust estimation framework. This connection leads to a new ""edge-stopping"" function based on Tukey's biweight robust estimator that preserves sharper boundaries than previous formulations and improves the automatic stopping of the diffusion. The robust statistical interpretation also provides a means for detecting the boundaries (edges) between the piecewise smooth regions in an image that has been smoothed with anisotropic diffusion. Additionally, we derive a relationship between anisotropic diffusion and regularization with line …",Michael J Black and Guillermo Sapiro and David H Marimont and David Heeger,1746,16127856943004115951,IEEE Transactions on image processing,3,421-432,IEEE,Robust anisotropic diffusion,https://ieeexplore.ieee.org/abstract/document/661192/,7,1998,/scholar?cites=16127856943004115951,6NjbexEAAAAJ:u-x6o8ySG0sC

1010003,"The accuracy of optical flow estimation algorithms has been improving steadily as evidenced by results on the Middlebury optical flow benchmark. The typical formulation, however, has changed little since the work of Horn and Schunck. We attempt to uncover what has made recent advances possible through a thorough analysis of how the objective function, the optimization method, and modern implementation practices influence accuracy. We discover that “classical” flow formulations perform surprisingly well when combined with modern optimization and implementation techniques. Moreover, we find that while median filtering of intermediate flow fields during optimization is a key to recent performance gains, it leads to higher energy solutions. To understand the principles behind this phenomenon, we derive a new objective that formalizes the median filtering heuristic. This objective includes a nonlocal term that …",Deqing Sun and Stefan Roth and Michael J Black,1502,5821194254180746892,,,2432-2439,IEEE,Secrets of optical flow estimation and their principles,https://ieeexplore.ieee.org/abstract/document/5539939/,,2010,/scholar?cites=5821194254180746892,6NjbexEAAAAJ:maZDTaKrznsC

1010004,"This paper describes an approach for tracking rigid and articulated objects using a view-based representation. The approach builds on and extends work on eigenspace representations, robust estimation techniques, and parameterized optical flow estimation. First, we note that the least-squares image reconstruction of standard eigenspace techniques has a number of problems and we reformulate the reconstruction problem as one of robust estimation. Second we define a “subspace constancy assumption” that allows us to exploit techniques for parameterized optical flow estimation to simultaneously solve for the view of an object and the affine transformation between the eigenspace and the image. To account for large affine transformations between the eigenspace and the image we define a multi-scale eigenspace representation and a coarse-to-fine matching strategy. Finally, we use these techniques to track …",Michael J Black and Allan D Jepson,1302,14758372155546699643,International Journal of Computer Vision,1,63-84,Kluwer Academic Publishers,Eigentracking: Robust matching and tracking of articulated objects using a view-based representation,https://link.springer.com/article/10.1023/A:1007939232436,26,1998,/scholar?cites=14758372155546699643,6NjbexEAAAAJ:9yKSN-GCB0IC

1010005,"Ground truth optical flow is difficult to measure in real scenes with natural motion. As a result, optical flow data sets are restricted in terms of size, complexity, and diversity, making optical flow algorithms difficult to train and test on realistic data. We introduce a new optical flow data set derived from the open source 3D animated short film Sintel. This data set has important features not present in the popular Middlebury flow evaluation: long sequences, large motions, specular reflections, motion blur, defocus blur, and atmospheric effects. Because the graphics data that generated the movie is open source, we are able to render scenes under conditions of varying complexity to evaluate where existing flow algorithms fail. We evaluate several recent optical flow algorithms and find that current highly-ranked methods on the Middlebury evaluation have difficulty with this more complex data set suggesting further …",Daniel J Butler and Jonas Wulff and Garrett B Stanley and Michael J Black,1144,15124407213489971559,,,611-625,"Springer, Berlin, Heidelberg",A naturalistic open source movie for optical flow evaluation,https://link.springer.com/chapter/10.1007/978-3-642-33783-3_44,,2012,/scholar?cites=15124407213489971559,6NjbexEAAAAJ:t7zJ5fGR-2UC

1010006,"We develop a framework for learning generic, expressive image priors that capture the statistics of natural scenes and can be used for a variety of machine vision tasks. The approach extends traditional Markov random field (MRF) models by learning potential functions over extended pixel neighborhoods. Field potentials are modeled using a Products-of-Experts framework that exploits nonlinear functions of many linear filter responses. In contrast to previous MRF approaches all parameters, including the linear filters themselves, are learned from training data. We demonstrate the capabilities of this Field of Experts model with two example applications, image denoising and image inpainting, which are implemented using a simple, approximate inference scheme. While the model is trained on a generic image database and is not tuned toward a specific application, we obtain results that compete with and even …",Stefan Roth and Michael J Black,1091,14126995997625697465,,,860-867,IEEE,Fields of experts: A framework for learning image priors,https://ieeexplore.ieee.org/abstract/document/1467533/,2,2005,/scholar?cites=14126995997625697465,6NjbexEAAAAJ:YsMSGLbcyi4C

1010007,"A probabilistic method for tracking 3D articulated human figures in monocular image sequences is presented. Within a Bayesian framework, we define a generative model of image appearance, a robust likelihood function based on image graylevel differences, and a prior probability distribution over pose and joint angles that models how humans move. The posterior probability distribution over model parameters is represented using a discrete set of samples and is propagated over time using particle filtering. The approach extends previous work on parameterized optical flow estimation to exploit a complex 3D articulated motion model. It also extends previous work on human motion tracking by including a perspective camera model, by modeling limb self occlusion, and by recovering 3D motion from a monocular sequence. The explicit posterior probability distribution represents ambiguities due to image …",Hedvig Sidenbladh and Michael Black and David Fleet,959,12916118103818184422,,,702-718,Springer Berlin/Heidelberg,Stochastic tracking of 3D human figures using 2D image motion,https://link.springer.com/chapter/10.1007/3-540-45053-X_45,,2000,/scholar?cites=12916118103818184422,6NjbexEAAAAJ:d1gkVwhDpl0C

1010008,"We present a learned model of human body shape and pose-dependent shape variation that is more accurate than previous models and is compatible with existing graphics pipelines. Our Skinned Multi-Person Linear model (SMPL) is a skinned vertex-based model that accurately represents a wide variety of body shapes in natural human poses. The parameters of the model are learned from data including the rest pose template, blend weights, pose-dependent blend shapes, identity-dependent blend shapes, and a regressor from vertices to joint locations. Unlike previous models, the pose-dependent blend shapes are a linear function of the elements of the pose rotation matrices. This simple formulation enables training the entire model from a relatively large number of aligned 3D meshes of different people in different poses. We quantitatively evaluate variants of SMPL using linear or dual-quaternion blend …",Matthew Loper and Naureen Mahmood and Javier Romero and Gerard Pons-Moll and Michael J Black,864,2337848845105698621,ACM transactions on graphics (TOG),6,1-16,ACM,SMPL: A skinned multi-person linear model,https://dl.acm.org/doi/abs/10.1145/2816795.2818013,34,2015,/scholar?cites=2337848845105698621,6NjbexEAAAAJ:iHaZ0gpiSgoC

1010009,"While research on articulated human motion and pose estimation has progressed rapidly in the last few years, there has been no systematic quantitative evaluation of competing methods to establish the current state of the art. We present data obtained using a hardware system that is able to capture synchronized video and ground-truth 3D motion. The resulting HumanEva datasets contain multiple subjects performing a set of predefined actions with a number of repetitions. On the order of 40,000 frames of synchronized motion capture and multi-view video (resulting in over one quarter million image frames in total) were collected at 60 Hz with an additional 37,000 time instants of pure motion capture data. A standard set of error measures is defined for evaluating both 2D and 3D pose estimation and tracking algorithms. We also describe a baseline algorithm for 3D articulated tracking that uses a relatively …",Leonid Sigal and Alexandru O Balan and Michael J Black,863,3923223945017663892,International journal of computer vision,1-2,4,Springer US,HumanEva: Synchronized Video and Motion Capture Dataset and Baseline Algorithm for Evaluation of Articulated Human Motion,https://link.springer.com/content/pdf/10.1007/s11263-009-0273-6.pdf,87,2010,/scholar?cites=3923223945017663892,6NjbexEAAAAJ:LkGwnXOMwfcC

1010010,"The modeling of spatial discontinuities for problems such as surface recovery, segmentation, image reconstruction, and optical flow has been intensely studied in computer vision. While “line-process” models of discontinuities have received a great deal of attention, there has been recent interest in the use of robust statistical techniques to account for discontinuities. This paper unifies the two approaches. To achieve this we generalize the notion of a “line process” to that of an analog “outlier process” and show how a problem formulated in terms of outlier processes can be viewed in terms of robust statistics. We also characterize a class of robust statistical problems for which an equivalent outlier-process formulation exists and give a straightforward method for converting a robust estimation problem into an outlier-process formulation. We show how prior assumptions about the spatial structure of outliers can …",Michael J Black and Anand Rangarajan,836,783474445880302199,International journal of computer vision,1,57-91,Kluwer Academic Publishers,"On the unification of line processes, outlier rejection, and robust statistics with applications in early vision",https://link.springer.com/content/pdf/10.1007/BF00131148.pdf,19,1996,/scholar?cites=783474445880302199,6NjbexEAAAAJ:2osOgNQ5qMEC

1010011,"We develop a framework for learning generic, expressive image priors that capture the statistics of natural scenes and can be used for a variety of machine vision tasks. The approach provides a practical method for learning high-order Markov random field (MRF) models with potential functions that extend over large pixel neighborhoods. These clique potentials are modeled using the Product-of-Experts framework that uses non-linear functions of many linear filter responses. In contrast to previous MRF approaches all parameters, including the linear filters themselves, are learned from training data. We demonstrate the capabilities of this Field-of-Experts model with two example applications, image denoising and image inpainting, which are implemented using a simple, approximate inference scheme. While the model is trained on a generic image database and is not tuned toward a specific application, we …",Stefan Roth and Michael J Black,736,3645651095975315530,International Journal of Computer Vision,2,205,Springer US,Fields of experts,https://link.springer.com/content/pdf/10.1007/s11263-008-0197-6.pdf,82,2009,/scholar?cites=3645651095975315530,6NjbexEAAAAJ:hFOr9nPyWt4C

1010012,"This paper explores the use of local parametrized models of image motion for recovering and recognizing the non-rigid and articulated motion of human faces. Parametric flow models (for example affine) are popular for estimating motion in rigid scenes. We observe that within local regions in space and time, such models not only accurately model non-rigid facial motions but also provide a concise description of the motion in terms of a small number of parameters. These parameters are intuitively related to the motion of facial features during facial expressions and we show how expressions such as anger, happiness, surprise, fear, disgust and sadness can be recognized from the local parametric motions in the presence of significant head motion. The motion tracking and expression recognition approach performs with high accuracy in extensive laboratory experiments involving 40 subjects as well as in television …",Michael J Black and Yaser Yacoob,673,4250115136217735629,,,374-381,IEEE,Tracking and recognizing rigid and non-rigid facial motions using local parametric models of image motion,https://ieeexplore.ieee.org/abstract/document/466915/,,1995,/scholar?cites=4250115136217735629,6NjbexEAAAAJ:qjMakFHDy7sC

1010013,"Many computer vision, signal processing and statistical problems can be posed as problems of learning low dimensional linear or multi-linear models. These models have been widely used for the representation of shape, appearance, motion, etc., in computer vision applications. Methods for learning linear models can be seen as a special case of subspace fitting. One draw-back of previous learning methods is that they are based on least squares estimation techniques and hence fail to account for “outliers” which are common in realistic training sets. We review previous approaches for making linear learning methods robust to outliers and present a new method that uses an intra-sample outlier process to account for pixel outliers. We develop the theory of Robust Subspace Learning (RSL) for linear models within a continuous optimization framework based on robust M-estimation. The framework applies to …",Fernando De La Torre and Michael J Black,660,8994355536796467955,International Journal of Computer Vision,1-3,117-142,Kluwer Academic Publishers,A framework for robust subspace learning,https://link.springer.com/article/10.1023/A:1023709501986,54,2003,/scholar?cites=8994355536796467955,6NjbexEAAAAJ:0EnyYjriUFMC

1010014,"We extend the work of Black and Yacoob (1995) on the tracking and recognition of human facial expressions using parametrized models of optical flow to deal with the articulated motion of human limbs. We define a ""card-board person model"" in which a person's limbs are represented by a set of connected planar patches. The parametrized image motion of these patches in constrained to enforce articulated motion and is solved for directly using a robust estimation technique. The recovered motion parameters provide a rich and concise description of the activity that can be used for recognition. We propose a method for performing view-based recognition of human activities from the optical flow parameters that extends previous methods to cope with the cyclical nature of human motion. We illustrate the method with examples of tracking human legs of long image sequences.",Shanon X Ju and Michael J Black and Yaser Yacoob,648,13619572792256124420,,,38-44,IEEE,Cardboard people: A parameterized model of articulated image motion,https://ieeexplore.ieee.org/abstract/document/557241/,,1996,/scholar?cites=13619572792256124420,6NjbexEAAAAJ:UeHWp8X0CEIC

1010015,"This paper explores the use of local parametrized models of image motion for recovering and recognizing the non-rigid and articulated motion of human faces. Parametric flow models (for example affine) are popular for estimating motion in rigid scenes. We observe that within local regions in space and time, such models not only accurately model non-rigid facial motions but also provide a concise description of the motion in terms of a small number of parameters. These parameters are intuitively related to the motion of facial features during facial expressions and we show how expressions such as anger, happiness, surprise, fear, disgust, and sadness can be recognized from the local parametric motions in the presence of significant head motion. The motion tracking and expression recognition approach performed with high accuracy in extensive laboratory experiments involving 40 subjects as well as in …",Michael J Black and Yaser Yacoob,642,13838129290175547143,International Journal of Computer Vision,1,23-48,Kluwer Academic Publishers,Recognizing facial expressions in image sequences using local parameterized models of image motion,https://link.springer.com/article/10.1023/A:1007977618277,25,1997,/scholar?cites=13838129290175547143,6NjbexEAAAAJ:zYLM7Y9cAGgC

1010016,"We describe the first method to automatically estimate the 3D pose of the human body as well as its 3D shape from a single unconstrained image. We estimate a full 3D mesh and show that 2D joints alone carry a surprising amount of information about body shape. The problem is challenging because of the complexity of the human body, articulation, occlusion, clothing, lighting, and the inherent ambiguity in inferring 3D from 2D. To solve this, we first use a recently published CNN-based method, DeepCut, to predict (bottom-up) the 2D body joint locations. We then fit (top-down) a recently published statistical body shape model, called SMPL, to the 2D joints. We do so by minimizing an objective function that penalizes the error between the projected 3D model joints and detected 2D joints. Because SMPL captures correlations in human shape across the population, we are able to robustly fit it to very little …",Federica Bogo and Angjoo Kanazawa and Christoph Lassner and Peter Gehler and Javier Romero and Michael J Black,632,8170741491731797357,,,561-578,"Springer, Cham",Keep it SMPL: Automatic estimation of 3D human pose and shape from a single image,https://link.springer.com/chapter/10.1007/978-3-319-46454-1_34,,2016,/scholar?cites=8170741491731797357,6NjbexEAAAAJ:eKGuBlYFiu8C

1010017,"This paper describes a new approach for tracking rigid and articulated objects using a view-based representation. The approach builds on and extends work on eigenspace representations, robust estimation techniques, and parameterized optical flow estimation. First, we note that the least-squares image reconstruction of standard eigenspace techniques has a number of problems and we reformulate the reconstruction problem as one of robust estimation. Second we define a “subspace constancy assumption” that allows us to exploit techniques for parameterized optical flow estimation to simultaneously solve for the view of an object and the affine transformation between the eigenspace and the image. To account for large affine transformations between the eigenspace and the image we define an EigenPyramid representation and a coarse-to-fine matching strategy. Finally, we use these techniques to …",Michael Black and Allan Jepson,605,12631785280273834564,,,329-342,Springer Berlin/Heidelberg,Eigentracking: Robust matching and tracking of articulated objects using a view-based representation,https://link.springer.com/chapter/10.1007/BFb0015548,,1996,/scholar?cites=12631785280273834564,6NjbexEAAAAJ:IjCSPb-OGe4C

1010018,"The authors consider the problem of robustly estimating optical flow from a pair of images using a new framework based on robust estimation which addresses violations of the brightness constancy and spatial smoothness assumptions. They also show the relationship between the robust estimation framework and line-process approaches for coping with spatial discontinuities. In doing so, the notion of a line process is generalized to that of an outlier process that can account for violations in both the brightness and smoothness assumptions. A graduated non-convexity algorithm is presented for recovering optical flow and motion discontinuities. The performance of the robust formulation is demonstrated on both synthetic data and natural images.< >",Michael J Black and Padmanabhan Anandan,580,10067473846455320271,,,231-236,IEEE,A framework for the robust estimation of optical flow,https://ieeexplore.ieee.org/abstract/document/378214/,,1993,/scholar?cites=10067473846455320271,6NjbexEAAAAJ:W7OEmFMy1HYC

1010019,"In this paper we consider a class of human activities—atomic activities—which can be represented as a set of measurements over a finite temporal window (e.g., the motion of human body parts during a walking cycle) and which has a relatively small space of variations in performance. A new approach for modeling and recognition of atomic activities that employs principal component analysis and analytical global transformations is proposed. The modeling of sets of exemplar instances of activities that are similar in duration and involve similar body part motions is achieved by parameterizing their representation using principal component analysis. The recognition of variants of modeled activities is achieved by searching the space of admissible parameterized transformations that these activities can undergo. This formulation iteratively refines the recognition of the class to which the observed activity belongs and …",Yaser Yacoob and Michael J Black,559,9077591851550508889,Computer Vision and Image Understanding,2,232-247,Academic Press,Parameterized modeling and recognition of activities,https://www.sciencedirect.com/science/article/pii/S1077314298907263,73,1999,/scholar?cites=9077591851550508889,6NjbexEAAAAJ:Tyk-4Ss8FVUC

1010020,"We describe Human Mesh Recovery (HMR), an end-to-end framework for reconstructing a full 3D mesh of a human body from a single RGB image. In contrast to most current methods that compute 2D or 3D joint locations, we produce a richer and more useful mesh representation that is parameterized by shape and 3D joint angles. The main objective is to minimize the reprojection loss of keypoints, which allows our model to be trained using in-the-wild images that only have ground truth 2D annotations. However, the reprojection loss alone is highly underconstrained. In this work we address this problem by introducing an adversary trained to tell whether human body shape and pose are real or not using a large database of 3D human meshes. We show that HMR can be trained with and without using any paired 2D-to-3D supervision. We do not rely on intermediate 2D keypoint detections and infer 3D pose and shape parameters directly from image pixels. Our model runs in real-time given a bounding box containing the person. We demonstrate our approach on various images in-the-wild and out-perform previous optimization-based methods that output 3D meshes and show competitive results on tasks such as 3D joint location estimation and part segmentation.",Angjoo Kanazawa and Michael J Black and David W Jacobs and Jitendra Malik,540,1235713119272923345,,,7122-7131,,End-to-end recovery of human shape and pose,http://openaccess.thecvf.com/content_cvpr_2018/html/Kanazawa_End-to-End_Recovery_of_CVPR_2018_paper.html,,2018,/scholar?cites=1235713119272923345,6NjbexEAAAAJ:f9jR0vFhilIC

1010021,"We pose the problem of 3D human tracking as one of inference in a graphical model. Unlike traditional kinematic tree representations, our model of the body is a collection of loosely-connected limbs. Conditional probabilities relating the 3D pose of connected limbs are learned from motion-captured training data. Similarly, we learn probabilistic models for the temporal evolution of each limb (forward and backward in time). Human pose and motion estimation is then solved with non-parametric belief propagation using a variation of particle filtering that can be applied over a general loopy graph. The loose-limbed model and decentralized graph structure facilitate the use of low-level visual cues. We adopt simple limb and head detectors to provide ""bottom-up"" information that is incorporated into the inference process at every time-step; these detectors permit automatic initialization and aid recovery from transient …",Leonid Sigal and Sidharth Bhatia and Stefan Roth and Michael J Black and Michael Isard,535,1762810620604120858,,,I-I,IEEE,Tracking loose-limbed people,https://ieeexplore.ieee.org/abstract/document/1315063/,1,2004,/scholar?cites=1762810620604120858,6NjbexEAAAAJ:eQOLeE2rZwMC

1010022,"A system tracks human head and facial features over time by analyzing a sequence of images. The system provides descriptions of motion of both head and facial features between two image frames. These descriptions of motion are further analyzed by the system to recognize facial movement and expression. The system analyzes motion between two images using parameterized models of image motion. Initially, a first image in a sequence of images is segmented into a face region and a plurality of facial feature regions. A planar model is used to recover motion parameters that estimate motion between the segmented face region in the first image and a second image in the sequence of images. The second image is warped or shifted back towards the first image using the estimated motion parameters of the planar model, in order to model the facial features relative to the first image. An affine model and an affine …",,510,6223029669074197361,,,,,Apparatus and method for recognizing facial expressions and facial gestures in a sequence of images,https://patents.google.com/patent/US5774591A/en,,1998,/scholar?cites=6223029669074197361,6NjbexEAAAAJ:5nxA0vEk-isC

1010023,"Although action recognition in videos is widely studied, current methods often fail on real-world datasets. Many recent approaches improve accuracy and robustness to cope with challenging video sequences, but it is often unclear what affects the results most. This paper attempts to provide insights based on a systematic performance evaluation using thoroughly-annotated data of human actions. We annotate human Joints for the HMDB dataset (J-HMDB). This annotation can be used to derive ground truth optical flow and segmentation. We evaluate current methods using this dataset and systematically replace the output of various algorithms with ground truth. This enables us to discover what is important for example, should we work on improving flow algorithms, estimating human bounding boxes, or enabling pose estimation? In summary, we find that highlevel pose features greatly outperform low/mid level features; in particular, pose over time is critical. While current pose estimation algorithms are far from perfect, features extracted from estimated pose on a subset of J-HMDB, in which the full body is visible, outperform low/mid-level features. We also find that the accuracy of the action recognition framework can be greatly increased by refining the underlying low/mid level features; this suggests it is important to improve optical flow and human detection algorithms. Our analysis and J-HMDB dataset should facilitate a deeper understanding of action recognition algorithms.",Hueihan Jhuang and Juergen Gall and Silvia Zuffi and Cordelia Schmid and Michael J Black,503,17337761512800381475,,,3192-3199,,Towards understanding action recognition,https://www.cv-foundation.org/openaccess/content_iccv_2013/html/Jhuang_Towards_Understanding_Action_2013_ICCV_paper.html,,2013,/scholar?cites=17337761512800381475,6NjbexEAAAAJ:PVjk1bu6vJQC

1010024,"Principal Component Analysis (PCA) has been widely used for the representation of shape, appearance and motion. One drawback of typical PCA methods is that they are least squares estimation techniques and hence fail to account for ""outliers"" which are common in realistic training sets. In computer vision applications, outliers typically occur within a sample (image) due to pixels that are corrupted by noise, alignment errors, or occlusion. We review previous approaches for making PCA robust to outliers and present a new method that uses an intra-sample outlier process to account for pixel outliers. We develop the theory of Robust Principal Component Analysis (RPCA) and describe a robust M-estimation algorithm for learning linear multi-variate representations of high dimensional data such as images. Quantitative comparisons with traditional PCA and previous robust algorithms illustrate the benefits of RPCA …",Fernando De la Torre and Michael J Black,487,2115263367929720486,,,362-369,IEEE,Robust principal component analysis for computer vision,https://ieeexplore.ieee.org/abstract/document/937541/,1,2001,/scholar?cites=2115263367929720486,6NjbexEAAAAJ:roLk4NBRz8UC

1010025,"The accuracy of optical flow estimation algorithms has been improving steadily as evidenced by results on the Middlebury optical flow benchmark. The typical formulation, however, has changed little since the work of Horn and Schunck. We attempt to uncover what has made recent advances possible through a thorough analysis of how the objective function, the optimization method, and modern implementation practices influence accuracy. We discover that “classical” flow formulations perform surprisingly well when combined with modern optimization and implementation techniques. One key implementation detail is the median filtering of intermediate flow fields during optimization. While this improves the robustness of classical methods it actually leads to higher energy solutions, meaning that these methods are not optimizing the original objective function. To understand the principles behind this …",Deqing Sun and Stefan Roth and Michael J Black,479,6511291691793140015,International Journal of Computer Vision,2,115-137,Springer US,A quantitative analysis of current practices in optical flow estimation and the principles behind them,https://link.springer.com/content/pdf/10.1007/s11263-013-0644-x.pdf,106,2014,/scholar?cites=6511291691793140015,6NjbexEAAAAJ:b1wdh0AR-JQC

1010026,"Effective neural motor prostheses require a method for decoding neural activity representing desired movement. In particular, the accurate reconstruction of a continuous motion signal is necessary for the control of devices such as computer cursors, robots, or a patient's own paralyzed limbs. For such applications, we developed a real-time system that uses Bayesian inference techniques to estimate hand motion from the firing rates of multiple neurons. In this study, we used recordings that were previously made in the arm area of primary motor cortex in awake behaving monkeys using a chronically implanted multielectrode microarray. Bayesian inference involves computing the posterior probability of the hand motion conditioned on a sequence of observed firing rates; this is formulated in terms of the product of a likelihood and a prior. The likelihood term models the probability of firing rates given a particular hand …",Wei Wu and Yun Gao and Elie Bienenstock and John P Donoghue and Michael J Black,453,13628930139950253017,Neural computation,1,80-118,MIT Press,Bayesian population decoding of motor cortical activity using a Kalman filter,https://www.mitpressjournals.org/doi/abs/10.1162/089976606774841585,18,2006,/scholar?cites=13628930139950253017,6NjbexEAAAAJ:8k81kl-MbHgC

1010027,"The ongoing pilot clinical trial of the BrainGate neural interface system aims in part to assess the feasibility of using neural activity obtained from a small-scale, chronically implanted, intracortical microelectrode array to provide control signals for a neural prosthesis system. Critical questions include how long implanted microelectrodes will record useful neural signals, how reliably those signals can be acquired and decoded, and how effectively they can be used to control various assistive technologies such as computers and robotic assistive devices, or to enable functional electrical stimulation of paralyzed muscles. Here we examined these questions by assessing neural cursor control and BrainGate system characteristics on five consecutive days 1000 days after implant of a 4× 4 mm array of 100 microelectrodes in the motor cortex of a human with longstanding tetraplegia subsequent to a brainstem stroke. On …",JD Simeral and Sung-Phil Kim and MJ Black and JP Donoghue and LR Hochberg,452,6881546591995650669,Journal of neural engineering,2,025027,IOP Publishing,Neural control of cursor trajectory and click by a human with tetraplegia 1000 days after implant of an intracortical microelectrode array,https://iopscience.iop.org/article/10.1088/1741-2560/8/2/025027/meta,8,2011,/scholar?cites=6881546591995650669,6NjbexEAAAAJ:UxriW0iASnsC

1010028,"We learn to compute optical flow by combining a classical spatial-pyramid formulation with deep learning. This estimates large motions in a coarse-to-fine approach by warping one image of a pair at each pyramid level by the current flow estimate and computing an update to the flow. Instead of the standard minimization of an objective function at each pyramid level, we train one deep network per level to compute the flow update. Unlike the recent FlowNet approach, the networks do not need to deal with large motions; these are dealt with by the pyramid. This has several advantages. First, our Spatial Pyramid Network (SPyNet) is much simpler and 96% smaller than FlowNet in terms of model parameters. This makes it more efficient and appropriate for embedded applications. Second, since the flow at each pyramid level is small (< 1 pixel), a convolutional approach applied to pairs of warped images is appropriate. Third, unlike FlowNet, the learned convolution filters appear similar to classical spatio-temporal filters, giving insight into the method and how to improve it. Our results are more accurate than FlowNet on most standard benchmarks, suggesting a new direction of combining classical flow methods with deep learning.",Anurag Ranjan and Michael J Black,438,1776399510420952171,,,4161-4170,,Optical flow estimation using a spatial pyramid network,http://openaccess.thecvf.com/content_cvpr_2017/html/Ranjan_Optical_Flow_Estimation_CVPR_2017_paper.html,,2017,/scholar?cites=1776399510420952171,6NjbexEAAAAJ:YAnBoHO8NTMC

1010029,"While research on articulated human motion and pose estimation has progressed rapidly in the last few years, there has been no systematic quantitative evaluation of competing methods to establish the current state of the art. Current algorithms make many different choices about how to model the human body, how to exploit image evidence and how to approach the inference problem. We argue that there is a need for common datasets that allow fair comparison between different methods and their design choices. Until recently gathering ground-truth data for evaluation of results (especially in 3D) was challenging. In this report we present a novel dataset obtained using a unique setup for capturing synchronized video and ground-truth 3D motion. Data was captured simultaneously using a calibrated marker-based motion capture system and multiple high-speed video capture systems. The video and motion capture streams were synchronized in software using a direct optimization method. The resulting HumanEva-I dataset contains multiple subjects performing a set of predefined actions with a number of repetitions. On the order of 50,000 frames of synchronized motion capture and video was collected at 60 Hz with an additional 37,000 frames of pure motion capture data. The data is partitioned into training, validation, and testing sub-sets. A standard set of error metrics is defined that can be used for evaluation of both 2D and 3D pose estimation and tracking algorithms. Support software and an on-line evaluation system for quantifying results using the test data is being made available to the community. This report provides an overview of the …",Leonid Sigal and Michael J Black,423,17841948788893671339,Brown Univertsity TR,,,,Humaneva: Synchronized video and motion capture dataset for evaluation of articulated human motion,http://www.academia.edu/download/45440135/cs06-08.pdf,120,2006,/scholar?cites=17841948788893671339,6NjbexEAAAAJ:5y95FQUaxGgC

1010030,"This paper addresses the problem of probabilistically modeling 3D human motion for synthesis and tracking. Given the high dimensional nature of human motion, learning an explicit probabilistic model from available training data is currently impractical. Instead we exploit methods from texture synthesis that treat images as representing an implicit empirical distribution. These methods replace the problem of representing the probability of a texture pattern with that of searching the training data for similar instances of that pattern. We extend this idea to temporal data representing 3D human motion with a large database of example motions. To make the method useful in practice, we must address the problem of efficient search in a large training set; efficiency is particularly important for tracking. Towards that end, we learn a low dimensional linear model of human motion that is used to structure the example …",Hedvig Sidenbladh and Michael Black and Leonid Sigal,412,4927880651391874765,,,784-800,Springer Berlin/Heidelberg,Implicit probabilistic models of human motion for synthesis and tracking,https://link.springer.com/chapter/10.1007/3-540-47969-4_52,,2002,/scholar?cites=4927880651391874765,6NjbexEAAAAJ:ufrVoPGSRksC

1010031,"Estimating human pose, shape, and motion from images and video are fundamental challenges with many applications. Recent advances in 2D human pose estimation use large amounts of manually-labeled training data for learning convolutional neural networks (CNNs). Such data is time consuming to acquire and difficult to extend. Moreover, manual labeling of 3D pose, depth and motion is impractical. In this work we present SURREAL: a new large-scale dataset with synthetically-generated but realistic images of people rendered from 3D sequences of human motion capture data. We generate more than 6 million frames together with ground truth pose, depth maps, and segmentation masks. We show that CNNs trained on our synthetic dataset allow for accurate human depth estimation and human part segmentation in real RGB images. Our results and the new datast open up new possibilities for advancing person analysis using chap and large-scale synthetic data.",Gul Varol and Javier Romero and Xavier Martin and Naureen Mahmood and Michael J Black and Ivan Laptev and Cordelia Schmid,411,3070187880069123504,,,109-117,,Learning from synthetic humans,http://openaccess.thecvf.com/content_cvpr_2017/html/Varol_Learning_From_Synthetic_CVPR_2017_paper.html,,2017,/scholar?cites=3070187880069123504,6NjbexEAAAAJ:rywEMSoAiS0C

1010032,"Computer-mediated connections between human motor cortical neurons and assistive devices promise to improve or restore lost function in people with paralysis. Recently, a pilot clinical study of an intracortical neural interface system demonstrated that a tetraplegic human was able to obtain continuous two-dimensional control of a computer cursor using neural activity recorded from his motor cortex. This control, however, was not sufficiently accurate for reliable use in many common computer control tasks. Here, we studied several central design choices for such a system including the kinematic representation for cursor movement, the decoding method that translates neuronal ensemble spiking activity into a control signal and the cursor control task used during training for optimizing the parameters of the decoding method. In two tetraplegic participants, we found that controlling a cursor's velocity resulted in more …",Sung-Phil Kim and John D Simeral and Leigh R Hochberg and John P Donoghue and Michael J Black,389,10826885457420189673,Journal of neural engineering,4,455,IOP Publishing,Neural control of computer cursor velocity by decoding motor cortical spiking activity in humans with tetraplegia,https://iopscience.iop.org/article/10.1088/1741-2560/5/4/010/meta,5,2008,/scholar?cites=10826885457420189673,6NjbexEAAAAJ:e5wmG9Sq2KIC

1010033,"A system and method of estimating the body shape of an individual from input data such as images or range maps. The body may appear in one or more poses captured at different times and a consistent body shape is computed for all poses. The body may appear in minimal tight-fitting clothing or in normal clothing wherein the described method produces an estimate of the body shape under the clothing. Clothed or bare regions of the body are detected via image classification and the fitting method is adapted to treat each region differently. Body shapes are represented parametrically and are matched to other bodies based on shape similarity and other features. Standard measurements are extracted using parametric or non-parametric functions of body shape. The system components support many applications in body scanning, advertising, social networking, collaborative filtering and Internet clothing shopping.",,383,14964576589696492244,,,,,Method and apparatus for estimating body shape,https://patents.google.com/patent/US9189886B2/en,,2015,/scholar?cites=14964576589696492244,6NjbexEAAAAJ:4fKUyHm3Qg0C

1010034,"A system tracks human head and facial features over time by analyzing a sequence of images. The system provides descriptions of motion of both head and facial features between two image frames. These descriptions of motion are further analyzed by the system to recognize facial movement and expression. The system analyzes motion between two images using parameterized models of image motion. Initially, a first image in a sequence of images is segmented into a face region and a plurality of facial feature regions. A planar model is used to recover motion parameters that estimate motion between the segmented face region in the first image and a second image in the sequence of images. The second image is warped or shifted back towards the first image using the estimated motion parameters of the planar model, in order to model the facial features relative to the first image. An affine model and an affine …",,371,9181034999526044076,,,,,Apparatus and method for tracking facial motion through a sequence of images,https://patents.google.com/patent/US5802220A/en,,1998,/scholar?cites=9181034999526044076,6NjbexEAAAAJ:MXK_kJrjxJIC

1010035,"New scanning technologies are increasing the importance of 3D mesh data and the need for algorithms that can reliably align it. Surface registration is important for building full 3D models from partial scans, creating statistical shape models, shape retrieval, and tracking. The problem is particularly challenging for non-rigid and articulated objects like human bodies. While the challenges of real-world data registration are not present in existing synthetic datasets, establishing ground-truth correspondences for real 3D scans is difficult. We address this with a novel mesh registration technique that combines 3D shape and appearance information to produce high-quality alignments. We define a new dataset called FAUST that contains 300 scans of 10 people in a wide range of poses together with an evaluation methodology. To achieve accurate registration, we paint the subjects with high-frequency textures and use an extensive validation process to ensure accurate ground truth. We find that current shape registration methods have trouble with this real-world data. The dataset and evaluation website are available for research purposes at http://faust. is. tue. mpg. de.",Federica Bogo and Javier Romero and Matthew Loper and Michael J Black,362,10067394907513412250,,,3794-3801,,FAUST: Dataset and evaluation for 3D mesh registration,https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Bogo_FAUST_Dataset_and_2014_CVPR_paper.html,,2014,/scholar?cites=10067394907513412250,6NjbexEAAAAJ:CoqsOaBEKcQC

1010036,"The 3D shape of the human body is useful for applications in fitness, games and apparel. Accurate body scanners, however, are expensive, limiting the availability of 3D body models. We present a method for human shape reconstruction from noisy monocular image and range data using a single inexpensive commodity sensor. The approach combines low-resolution image silhouettes with coarse range data to estimate a parametric model of the body. Accurate 3D shape estimates are obtained by combining multiple monocular views of a person moving in front of the sensor. To cope with varying body pose, we use a SCAPE body model which factors 3D body shape and pose variations. This enables the estimation of a single consistent shape while allowing pose to vary. Additionally, we describe a novel method to minimize the distance between the projected 3D body contour and the image silhouette that uses …",Alexander Weiss and David Hirshberg and Michael J Black,353,8190324017448472799,,,,,Home 3D Body Scans from Noisy Image and Range Data,https://ieeexplore.ieee.org/abstract/document/6126465/,,2011,/scholar?cites=8190324017448472799,6NjbexEAAAAJ:BrmTIyaxlBUC

1010037,"This paper presents a novel approach to incrementally estimating visual motion over a sequence of images. We start by realistically reformulating constraints on image motion to account for the possibility of multiple motions. This is achieved by exploiting the notions of weak continuity and robust statistics in the formulation of a minimization problem. The resulting objective function is non-convex. Traditional stochastic relaxation techniques for solving the minimization problem prove inappropriate for the task as they require many iterations to converge whereas motion estimation must be dynamic. We present a highly parallel incremental stochastic minimization algorithm which has a number of advantages over previous approaches. Between any pair of frames in an image sequence, only simple local computations take place. Robustness and accuracy are then achieved by extending the estimation task over time. The …",Michael J Black and Padmanabhan Anandan,353,9155391633062536737,CVPR,,296-203,,Robust dynamic motion estimation over time.,https://www.cs.yale.edu/publications/techreports/tr835.pdf,91,1991,/scholar?cites=9155391633062536737,6NjbexEAAAAJ:_FxGoFyzp5QC

1010038,"The computation of optical flow relies on merging information available over an image patch to form an estimate of 2-D image velocity at a point. This merging process raises many issues. These include the treatment of outliers in component velocity measurements and the modeling of multiple motions within a patch which arise from occlusion boundaries or transparency. A new approach for dealing with these issues is presented. It is based on the use of a probabilistic mixture model to explicitly represent multiple motions within a patch. A simple extension of the EM-algorithm is used to compute a maximum likelihood estimate for the various motion parameters. Preliminary experiments indicate that this approach is computationally efficient, and that it can provide robust estimates of the optical flow values in the presence of outliers and multiple motions.< >",Allan Jepson and Michael J Black,346,1151908395475516901,,,760-761,IEEE,Mixture models for optical flow computation,https://ieeexplore.ieee.org/abstract/document/341161/,,1993,/scholar?cites=1151908395475516901,6NjbexEAAAAJ:WF5omc3nYNoC

1010039,"We describe a solution to the challenging problem of estimating human body shape from a single photograph or painting. Our approach computes shape and pose parameters of a 3D human body model directly from monocular image cues and advances the state of the art in several directions. First, given a user-supplied estimate of the subject's height and a few clicked points on the body we estimate an initial 3D articulated body pose and shape. Second, using this initial guess we generate a tri-map of regions inside, outside and on the boundary of the human, which is used to segment the image using graph cuts. Third, we learn a low-dimensional linear model of human shape in which variations due to height are concentrated along a single dimension, enabling height-constrained estimation of body shape. Fourth, we formulate the problem of parametric human shape from shading. We estimate the body pose …",Peng Guan and Alexander Weiss and Alexandru O Balan and Michael J Black,333,1802973208355945904,,,1381-1388,IEEE,Estimating human shape and pose from a single image,https://ieeexplore.ieee.org/abstract/document/5459300/,,2009,/scholar?cites=1802973208355945904,6NjbexEAAAAJ:zA6iFVUQeVQC

1010040,"Much of the research on video-based human motion capture assumes the body shape is known a priori and is represented coarsely (e.g. using cylinders or superquadrics to model limbs). These body models stand in sharp contrast to the richly detailed 3D body models used by the graphics community. Here we propose a method for recovering such models directly from images. Specifically, we represent the body using a recently proposed triangulated mesh model called SCAPE which employs a low-dimensional, but detailed, parametric model of shape and pose-dependent deformations that is learned from a database of range scans of human bodies. Previous work showed that the parameters of the SCAPE model could be estimated from marker-based motion capture data. Here we go further to estimate the parameters directly from image data. We define a cost function between image observations and a …",Alexandru O Balan and Leonid Sigal and Michael J Black and James E Davis and Horst W Haussecker,330,12235159987890701578,,,1-8,IEEE,Detailed human shape and pose from images,https://ieeexplore.ieee.org/abstract/document/4270338/,,2007,/scholar?cites=12235159987890701578,6NjbexEAAAAJ:mVmsd5A6BfQC

1010041,"We present an analysis of the spatial and temporal statistics of “natural” optical flow fields and a novel flow algorithm that exploits their spatial statistics. Training flow fields are constructed using range images of natural scenes and 3D camera motions recovered from hand-held and car-mounted video sequences. A detailed analysis of optical flow statistics in natural scenes is presented and machine learning methods are developed to learn a Markov random field model of optical flow. The prior probability of a flow field is formulated as a Field-of-Experts model that captures the spatial statistics in overlapping patches and is trained using contrastive divergence. This new optical flow prior is compared with previous robust priors and is incorporated into a recent, accurate algorithm for dense optical flow computation. Experiments with natural and synthetic sequences illustrate how the learned optical flow prior …",Stefan Roth and Michael J Black,322,16159094483958543635,International Journal of Computer Vision,1,33-50,Kluwer Academic Publishers-Plenum Publishers,On the spatial statistics of optical flow,https://link.springer.com/content/pdf/10.1007/s11263-006-0016-x.pdf,74,2007,/scholar?cites=16159094483958543635,6NjbexEAAAAJ:4JMBOYKVnBMC

1010042,"State-of-the-art research on MRFs, successful MRF applications, and advanced topics for future study. This volume demonstrates the power of the Markov random field (MRF) in vision, treating the MRF both as a tool for modeling image data and, utilizing recently developed algorithms, as a means of making inferences about images. These inferences concern underlying image and scene structure as well as solutions to such problems as image reconstruction, image segmentation, 3D vision, and object labeling. It offers key findings and state-of-the-art research on both algorithms and applications. After an introduction to the fundamental concepts used in MRFs, the book reviews some of the main algorithms for performing inference with MRFs; presents successful applications of MRFs, including segmentation, super-resolution, and image restoration, along with a comparison of various optimization methods; discusses advanced algorithmic topics; addresses limitations of the strong locality assumptions in the MRFs discussed in earlier chapters; and showcases applications that use MRFs in more complex ways, as components in bigger systems or with multiterm energy functions. The book will be an essential guide to current research on these powerful mathematical tools.",Andrew Blake and Pushmeet Kohli and Carsten Rother,307,13213294692896756091,,,,Mit Press,Markov random fields for vision and image processing,http://books.google.com/books?hl=en&lr=&id=dQE5k7DY-dAC&oi=fnd&pg=PP1&dq=info:e1GqIoQNX7cJ:scholar.google.com&ots=bE8ld5xenS&sig=iGLB0OGIycN812jldftibYQP8fg,,2011,/scholar?cites=13213294692896756091,6NjbexEAAAAJ:KbeHZ-DlqmcC

1010043,"Assumptions of brightness constancy and spatial smoothness underlie most optical flow estimation methods. In contrast to standard heuristic formulations, we learn a statistical model of both brightness constancy error and the spatial properties of optical flow using image sequences with associated ground truth flow fields. The result is a complete probabilistic model of optical flow. Specifically, the ground truth enables us to model how the assumption of brightness constancy is violated in naturalistic sequences, resulting in a probabilistic model of “brightness inconstancy”. We also generalize previous high-order constancy assumptions, such as gradient constancy, by modeling the constancy of responses to various linear filters in a high-order random field framework. These filters are free variables that can be learned from training data. Additionally we study the spatial structure of the optical flow and how …",Deqing Sun and Stefan Roth and J Lewis and Michael Black,307,12628563045908321649,,,83-97,Springer Berlin/Heidelberg,Learning optical flow,https://link.springer.com/chapter/10.1007/978-3-540-88690-7_7,,2008,/scholar?cites=12628563045908321649,6NjbexEAAAAJ:isC4tDSrTZIC

1010044,"Human motion modelling is a classical problem at the intersection of graphics and computer vision, with applications spanning human-computer interaction, motion synthesis, and motion prediction for virtual and augmented reality. Following the success of deep learning methods in several computer vision tasks, recent work has focused on using deep recurrent neural networks (RNNs) to model human motion, with the goal of learning time-dependent representations that perform tasks such as short-term motion prediction and long-term human motion synthesis. We examine recent work, with a focus on the evaluation methodologies commonly used in the literature, and show that, surprisingly, state of the art performance can be achieved by a simple baseline that does not attempt to model motion at all. We investigate this result, and analyze recent RNN methods by looking at the architectures, loss functions, and training procedures used in state-of-the-art approaches. We propose three changes to the standard RNN models typically used for human motion, which results in a simple and scalable RNN architecture that obtains state-of-the-art performance on human motion prediction.",Julieta Martinez and Michael J Black and Javier Romero,303,1667028470840876283,,,2891-2900,,On human motion prediction using recurrent neural networks,http://openaccess.thecvf.com/content_cvpr_2017/html/Martinez_On_Human_Motion_CVPR_2017_paper.html,,2017,/scholar?cites=1667028470840876283,6NjbexEAAAAJ:RiW20FJDrgsC

1010045,"The recognition of human gestures and facial expressions in image sequences is an important and challenging problem that enables a host of human-computer interaction applications. This paper describes a framework for incremental recognition of human motion that extends the “Condensation” algorithm proposed by Isard and Blake (ECCV'96). Human motions are modeled as temporal trajectories of some estimated parameters over time. The Condensation algorithm uses random sampling techniques to incrementally match the trajectory models to the multi-variate input data. The recognition framework is demonstrated with two examples. The first example involves an augmented office whiteboard with which a user can make simple hand gestures to grab regions of the board, print them, save them, etc. The second example illustrates the recognition of human facial expressions using the estimated …",Michael J Black and Allan D Jepson,299,7237884216735057014,,,909-924,"Springer, Berlin, Heidelberg",A probabilistic framework for matching temporal trajectories: Condensation-based recognition of gestures and expressions,https://link.springer.com/chapter/10.1007/BFb0055712,,1998,/scholar?cites=7237884216735057014,6NjbexEAAAAJ:UebtZRa9Y70C

1010046,"Part-based tree-structured models have been widely used for 2D articulated human pose-estimation. These approaches admit efficient inference algorithms while capturing the important kinematic constraints of the human body as a graphical model. These methods often fail however when multiple body parts fit the same image region resulting in global pose estimates that poorly explain the overall image evidence. Attempts to solve this problem have focused on the use of strong prior models that are limited to learned activities such as walking. We argue that the problem actually lies with the image observations and not with the prior. In particular, image evidence for each body part is estimated independently of other parts without regard to self-occlusion. To address this we introduce occlusion-sensitive local likelihoods that approximate the global image likelihood using per-pixel hidden binary variables that encode …",Leonid Sigal and Michael J Black,296,16604709649183156818,,,2041-2048,IEEE,"Measure locally, reason globally: Occlusion-sensitive articulated pose estimation",https://ieeexplore.ieee.org/abstract/document/1641003/,2,2006,/scholar?cites=16604709649183156818,6NjbexEAAAAJ:M3ejUd6NZC8C

1010047,"This paper presents a new model for estimating optical flow based on the motion of planar regions plus local deformations. The approach exploits brightness information to organize and constrain the interpretation of the motion by using segmented regions of piecewise smooth brightness to hypothesize planar regions in the scene. Parametric flow models are estimated in these regions in a two step process which first computes a coarse fit and then estimates the appropriate parametrization of the motion of the region. The initial fit is refined using a generalization of the standard area-based regression approaches. Since the assumption of planarity is likely to be violated, we allow local deformations from the planar assumption in the same spirit as physically-based approaches which model shape using coarse parametric models plus local deformations. This parametric plus deformation model exploits the strong …",Michael J Black and Allan D Jepson,284,9078511087952064543,IEEE Transactions on Pattern Analysis and Machine Intelligence,10,972-986,IEEE,Estimating optical flow in segmented images using variable-order parametric models with local deformations,https://ieeexplore.ieee.org/abstract/document/541407/,18,1996,/scholar?cites=9078511087952064543,6NjbexEAAAAJ:Se3iqnhoufwC

1010048,"This thesis addresses the problem of recovering 2D image velocity, or optical flow, robustly over long image sequences. We develop a robust estimation framework for improving the reliability of motion estimates and an incremental minimization framework for recovering flow estimates over time.Attempts to improve the robustness of optical flow have focused on detecting and accounting for motion discontinuities in the optical flow field. We show that motion discontinuities are one example of a more general class of model violations and that by formulating the optical flow problem as one of robust estimation the problems posed by motion discontinuities can be reduced, and the violations can be detected. Additionally, robust estimation provides a powerful framework for early vision problems that generalizes the popular “line process” approaches.",Michael Julian Black,273,16350166031888078846,,,,,Robust incremental optical flow,http://128.148.32.110/people/mjblack/Thesis/thesis.pdf,,1992,/scholar?cites=16350166031888078846,6NjbexEAAAAJ:hqOjcs7Dif8C

1010049,"Estimating 3D human pose from 2D joint locations is central to the analysis of people in images and video. To address the fact that the problem is inherently ill posed, many methods impose a prior over human poses. Unfortunately these priors admit invalid poses because they do not model how joint-limits vary with pose. Here we make two key contributions. First, we collect a motion capture dataset that explores a wide range of human poses. From this we learn a pose-dependent model of joint limits that forms our prior. Both dataset and prior are available for research purposes. Second, we define a general parametrization of body pose and a new, multi-stage, method to estimate 3D pose from 2D joint locations using an over-complete dictionary of poses. Our method shows good generalization while avoiding impossible poses. We quantitatively compare our method with recent work and show state-of-the-art results on 2D to 3D pose estimation using the CMU mocap dataset. We also show superior results using manual annotations on real images and automatic detections on the Leeds sports pose dataset.",Ijaz Akhter and Michael J Black,269,2362213149413781225,,,1446-1455,,Pose-conditioned joint angle limits for 3D human pose reconstruction,https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Akhter_Pose-Conditioned_Joint_Angle_2015_CVPR_paper.html,,2015,/scholar?cites=2362213149413781225,6NjbexEAAAAJ:i_acAUMCj1cC

1010050,"Inverse graphics attempts to take sensor data and infer 3D geometry, illumination, materials, and motions such that a graphics renderer could realistically reproduce the observed scene. Renderers, however, are designed to solve the forward process of image synthesis. To go in the other direction, we propose an approximate differentiable renderer (DR) that explicitly models the relationship between changes in model parameters and image observations. We describe a publicly available OpenDR framework that makes it easy to express a forward graphics model and then automatically obtain derivatives with respect to the model parameters and to optimize over them. Built on a new auto-differentiation package and OpenGL, OpenDR provides a local optimization method that can be incorporated into probabilistic programming frameworks. We demonstrate the power and simplicity of programming with …",Matthew M Loper and Michael J Black,269,14180974105121584086,,,154-169,"Springer, Cham",OpenDR: An approximate differentiable renderer,https://link.springer.com/chapter/10.1007/978-3-319-10584-0_11,,2014,/scholar?cites=14180974105121584086,6NjbexEAAAAJ:i_QFVEgXGzMC

1010051,"We present a switching Kalman filter model for the real-time inference of hand kinematics from a population of motor cortical neurons. Firing rates are modeled as a Gaussian mixture where the mean of each Gaussian component is a linear function of hand kinematics. A ""hidden state"" models the probability of each mixture component and evolves over time in a Markov chain. The model generalizes previous encoding and decoding methods, addresses the non-Gaussian nature of firing rates, and can cope with crudely sorted neural data common in on-line prosthetic applications.",Wei Wu and Michael J Black and David Mumford and Yun Gao and Elie Bienenstock and John P Donoghue,251,8458462279888542787,IEEE transactions on biomedical engineering,6,933-942,IEEE,Modeling and decoding motor cortical activity using a switching Kalman filter,https://ieeexplore.ieee.org/abstract/document/1300785/,51,2004,/scholar?cites=8458462279888542787,6NjbexEAAAAJ:_kc_bZDykSQC

1010052,"Video object segmentation is challenging due to fast moving objects, deforming shapes, and cluttered backgrounds. Optical flow can be used to propagate an object segmentation over time but, unfortunately, flow is often inaccurate, particularly around object boundaries. Such boundaries are precisely where we want our segmentation to be accurate. To obtain accurate segmentation across time, we propose an efficient algorithm that considers video segmentation and optical flow estimation simultaneously. For video segmentation, we formulate a principled, multi-scale, spatio-temporal objective function that uses optical flow to propagate information between frames. For optical flow estimation, particularly at object boundaries, we compute the flow independently in the segmented regions and recompose the results. We call the process object flow and demonstrate the effectiveness of jointly optimizing optical flow and video segmentation using an iterative scheme. Experiments on the SegTrack v2 and Youtube-Objects datasets show that the proposed algorithm performs favorably against the other state-of-the-art methods.",Yi-Hsuan Tsai and Ming-Hsuan Yang and Michael J Black,243,11904442160900922772,,,3899-3908,,Video segmentation via object flow,http://openaccess.thecvf.com/content_cvpr_2016/html/Tsai_Video_Segmentation_via_CVPR_2016_paper.html,,2016,/scholar?cites=11904442160900922772,6NjbexEAAAAJ:h6vPvb0CPpsC

1010053,"How the activity of populations of cortical neurons generates coordinated multijoint actions of the arm, wrist, and hand is poorly understood. This study combined multielectrode recording techniques with full arm motion capture to relate neural activity in primary motor cortex (M1) of macaques (Macaca mulatta) to arm, wrist, and hand postures during movement. We find that the firing rate of individual M1 neurons is typically modulated by the kinematics of multiple joints and that small, local ensembles of M1 neurons contain sufficient information to reconstruct 25 measured joint angles (representing an estimated 10 functionally independent degrees of freedom). Beyond showing that the spiking patterns of local M1 ensembles represent a rich set of naturalistic movements involving the entire upper limb, the results also suggest that achieving high-dimensional reach and grasp actions with neuroprosthetic devices may …",Carlos E Vargas-Irwin and Gregory Shakhnarovich and Payman Yadollahpour and John MK Mislow and Michael J Black and John P Donoghue,240,4595501304990479928,Journal of neuroscience,29,9659-9669,Society for Neuroscience,Decoding complete reach and grasp actions from local primary motor cortex populations,https://www.jneurosci.org/content/30/29/9659.short,30,2010,/scholar?cites=4595501304990479928,6NjbexEAAAAJ:ZHo1McVdvXMC

1010054,"Belief propagation (BP) has become widely used for low-level vision problems and various inference techniques have been proposed for loopy graphs. These methods typically rely on ad hoc spatial priors such as the Potts model. In this paper we investigate the use of learned models of image structure, and demonstrate the improvements obtained over previous ad hoc models for the image denoising problem. In particular, we show how both pairwise and higher-order Markov random fields with learned clique potentials capture rich image structures that better represent the properties of natural images. These models are learned using the recently proposed Fields-of-Experts framework. For such models, however, traditional BP is computationally expensive. Consequently we propose some approximation methods that make BP with learned potentials practical. In the case of pairwise models we propose a …",Xiangyang Lan and Stefan Roth and Daniel Huttenlocher and Michael Black,228,1924187312604231048,,,269-282,Springer Berlin/Heidelberg,Efficient belief propagation with learned higher-order markov random fields,https://link.springer.com/chapter/10.1007/11744047_21,,2006,/scholar?cites=1924187312604231048,6NjbexEAAAAJ:7PzlFSSx8tAC

1010055,"The Bayesian estimation of 3D human motion from video sequences is quantitatively evaluated using synchronized, multi-camera, calibrated video and 3D ground truth poses acquired with a commercial motion capture system. While many methods for human pose estimation and tracking have been proposed, to date there has been no quantitative comparison. Our goal is to evaluate how different design choices influence tracking performance. Toward that end, we independently implemented two fairly standard Bayesian person trackers using two variants of particle filtering and propose an evaluation measure appropriate for assessing the quality of probabilistic tracking methods. In the Bayesian framework we compare various image likelihood functions and prior models of human motion that have been proposed in the literature. Our results suggest that in constrained laboratory environments, current methods …",Alexandru O Balan and Leonid Sigal and Michael J Black,222,15682797544105508906,,,349-356,IEEE,A quantitative evaluation of video-based 3D person tracking,https://ieeexplore.ieee.org/abstract/document/1570935/,,2005,/scholar?cites=15682797544105508906,6NjbexEAAAAJ:KlAtU1dfN6UC

1010056,"This review describes the rationale, early stage development, and initial human application of neural interface systems (NISs) for humans with paralysis. NISs are emerging medical devices designed to allow persons with paralysis to operate assistive technologies or to reanimate muscles based upon a command signal that is obtained directly from the brain. Such systems require the development of sensors to detect brain signals, decoders to transform neural activity signals into a useful command, and an interface for the user. We review initial pilot trial results of an NIS that is based on an intracortical microelectrode sensor that derives control signals from the motor cortex. We review recent findings showing, first, that neurons engaged by movement intentions persist in motor cortex years after injury or disease to the motor system, and second, that signals derived from motor cortex can be used by persons with …",John P Donoghue and Arto Nurmikko and Michael Black and Leigh R Hochberg,220,13828891887968218799,The Journal of physiology,3,603-611,Blackwell Publishing Ltd,Assistive technology and robotic control using motor cortex ensemble‐based neural interface systems in humans with tetraplegia,https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.2006.127209,579,2007,/scholar?cites=13828891887968218799,6NjbexEAAAAJ:QIV2ME_5wuYC

1010057,"3D models provide a common ground for different representations of human bodies. In turn, robust 2D estimation has proven to be a powerful tool to obtain 3D fits"" in-the-wild"". However, depending on the level of detail, it can be hard to impossible to acquire labeled data for training 2D estimators on large scale. We propose a hybrid approach to this problem: with an extended version of the recently introduced SMPLify method, we obtain high quality 3D body model fits for multiple human pose datasets. Human annotators solely sort good and bad fits. This procedure leads to an initial dataset, UP-3D, with rich annotations. With a comprehensive set of experiments, we show how this data can be used to train discriminative models that produce results with an unprecedented level of detail: our models predict 31 segments and 91 landmark locations on the body. Using the 91 landmark pose estimator, we present state-of-the art results for 3D human pose and shape estimation using an order of magnitude less training data and without assumptions about gender or pose in the fitting procedure. We show that UP-3D can be enhanced with these improved fits to grow in quantity and quality, which makes the system deployable on large scale. The data, code and models are available for research purposes.",Christoph Lassner and Javier Romero and Martin Kiefel and Federica Bogo and Michael J Black and Peter V Gehler,219,8996340826671872379,,,6050-6059,,Unite the people: Closing the loop between 3d and 2d human representations,http://openaccess.thecvf.com/content_cvpr_2017/html/Lassner_Unite_the_People_CVPR_2017_paper.html,,2017,/scholar?cites=8996340826671872379,6NjbexEAAAAJ:_9cyEV96HHsC

1010058,"To look human, digital full-body avatars need to have soft-tissue deformations like those of real people. We learn a model of soft-tissue deformations from examples using a high-resolution 4D capture system and a method that accurately registers a template mesh to sequences of 3D scans. Using over 40,000 scans of ten subjects, we learn how soft-tissue motion causes mesh triangles to deform relative to a base 3D body model. Our Dyna model uses a low-dimensional linear subspace to approximate soft-tissue deformation and relates the subspace coefficients to the changing pose of the body. Dyna uses a second-order auto-regressive model that predicts soft-tissue deformations based on previous deformations, the velocity and acceleration of the body, and the angular velocities and accelerations of the limbs. Dyna also models how deformations vary with a person's body mass index (BMI), producing different …",Gerard Pons-Moll and Javier Romero and Naureen Mahmood and Michael J Black,212,6443376918706558551,ACM Transactions on Graphics (TOG),4,1-14,ACM,Dyna: A model of dynamic human shape in motion,https://dl.acm.org/doi/abs/10.1145/2766993,34,2015,/scholar?cites=6443376918706558551,6NjbexEAAAAJ:LGA7_l5-FVwC

1010059,"The analysis of action potentials, or ""spikes,"" is central to systems neuroscience research. Spikes are typically identified from raw waveforms manually for off-line analysis or automatically by human-configured algorithms for on-line applications. The variability of manual spike ""sorting"" is studied and its implications for neural prostheses discussed. Waveforms were recorded using a micro-electrode array and were used to construct a statistically similar synthetic dataset. Results showed wide variability in the number of neurons and spikes detected in real data. Additionally, average error rates of 23% false positive and 30% false negative were found for synthetic data.",Frank Wood and Michael J Black and Carlos Vargas-Irwin and Matthew Fellows and John P Donoghue,209,2532118642174499434,IEEE Transactions on Biomedical Engineering,6,912-918,IEEE,On the variability of manual spike sorting,https://ieeexplore.ieee.org/abstract/document/1300782/,51,2004,/scholar?cites=2532118642174499434,6NjbexEAAAAJ:9ZlFYXVOiuMC

1010060,"A system tracks and identifies view-based representations of an object through a sequence of images. As the view of the object changes due to its motion or the motion of its recording device, the object is identified by matching an image region containing the object with a set of basis images represented by an eigenspace. The eigenspace is generated from a training set of images which records different views of the object. The system identifies the object in the image region by simultaneously computing a transformation that aligns the image region with the eigenspace, and computing coefficients of a combination of linear eigenvectors that reconstruct the image region. This identification and tracking system operates when views of the object in the image are deformed under some transformation with respect to the eigenspace. Matching between the image region and the eigenspace is performed using a robust …",,208,17770191904800642621,,,,,Apparatus and method for identifying and tracking objects with view-based representations,https://patents.google.com/patent/US6526156B1/en,,2003,/scholar?cites=17770191904800642621,6NjbexEAAAAJ:k_IJM867U9cC

1010061,"For the creation of the MANO hand model, we first collect a large number of scans of hands in isolation. These scans are obtained with a scanner configured specifically to capture hands with a fixed wrist position. This allows us to capture the nuances of hand deformation. After capturing this data for both right and left hands, we create a single augmented dataset by mirroring the left hand scans to appear as right ones. This approach increases the size of the training data and removes the bias introduced by the handedness of the subjects. In practical terms, it results in a performance improvement as shown in the experiments section. The augmented dataset enables us to train a single consistent hand model for both hands, ie we train the right hand model and generate the left one by mirroring. Model components which depend on the global coordinate frame, like the mesh template T, the shape blend shapes BS and the pose blend shapes BP, require mirroring. The rest of the components (eg the blend weights W and joint regressor J) remain untouched. We define the sagittal plane in SMPL, x, as our mirroring plane. This entails the following mirroring transformation",Javier Romero and Dimitrios Tzionas and Michael J Black,206,9567138932042633150,ACM Transactions on Graphics (ToG),6,245,ACM,Embodied hands: Modeling and capturing hands and bodies together,https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/393/Embodied_Hands_SiggraphAsia2017_suppl.pdf,36,2017,/scholar?cites=9567138932042633150,6NjbexEAAAAJ:25zTQ8aaf3EC

1010062,"This paper describes a new method for estimating optical flow that strikes a balance between the flexibility of local dense computations and the robustness and accuracy of global parameterized flow models. An affine model of image motion is used within local image patches while a spatial smoothness constraint on the affine flow parameters of neighboring patches enforces continuity of the motion. We refer to this as a ""Skin and Bones"" model in which the affine patches can be thought of as rigid ""bones"" connected by a flexible ""skin"". Since local image patches may contain multiple motions we use a layered representation for the affine bones. To regularize this layered motion representation we develop a new framework for regularization with transparency.",Shanon X Ju and Michael J Black and Allan D Jepson,204,14393039387365711256,,,307-314,IEEE,"Skin and bones: Multi-layer, locally affine, optical flow and regularization with transparency",https://ieeexplore.ieee.org/abstract/document/517090/,,1996,/scholar?cites=14393039387365711256,6NjbexEAAAAJ:3fE2CSJIrl8C

1010063,We propose a generalized model of image “appearance change” in which brightness variation over time is represented as a probabilistic mixture of different causes. We define four generative models of appearance change due to (1) object or camera motion; (2) illumination phenomena; (3) specular reflections; and (4) “iconic changes” which are specific to the objects being viewed. These iconic changes include complex occlusion events and changes in the material properties of the objects. We develop a robust statistical framework for recovering these appearance changes in image sequences. This approach generalizes previous work on optical flow to provide a richer description of image events and more reliable estimates of image motion in the presense of shadows and specular reflections.,Michael J Black and David J Fleet and Yaser Yacoob,200,7257715951704639261,Computer Vision and Image Understanding,1,8-31,Academic Press,Robustly estimating changes in image appearance,https://www.sciencedirect.com/science/article/pii/S1077314299908251,78,2000,/scholar?cites=7257715951704639261,6NjbexEAAAAJ:kNdYIx-mwKoC

1010064,"Generative models of 3D human motion are often restricted to a small number of activities and can therefore not generalize well to novel movements or applications. In this work we propose a deep learning framework for human motion capture data that learns a generic representation from a large corpus of motion capture data and generalizes well to new, unseen, motions. Using an encoding-decoding network that learns to predict future 3D poses from the most recent past, we extract a feature representation of human motion. Most work on deep learning for sequence prediction focuses on video and speech. Since skeletal data has a different structure, we present and evaluate different network architectures that make different assumptions about time dependencies and limb correlations. To quantify the learned features, we use the output of different layers for action classification and visualize the receptive fields of the network units. Our method outperforms the recent state of the art in skeletal motion prediction even though these use action specific training data. Our results show that deep feedforward networks, trained from a generic mocap database, can successfully be used for feature extraction from human motion data and that this representation can be used as a foundation for classification and prediction.",Judith Butepage and Michael J Black and Danica Kragic and Hedvig Kjellstrom,197,7856660868149106043,,,6158-6166,,Deep representation learning for human motion prediction and classification,http://openaccess.thecvf.com/content_cvpr_2017/html/Butepage_Deep_Representation_Learning_CVPR_2017_paper.html,,2017,/scholar?cites=7856660868149106043,6NjbexEAAAAJ:7jLzoj1EsW0C

1010065,"We propose a method to estimate the detailed 3D shape of a person from images of that person wearing clothing. The approach exploits a model of human body shapes that is learned from a database of over 2000 range scans. We show that the parameters of this shape model can be recovered independently of body pose. We further propose a generalization of the visual hull to account for the fact that observed silhouettes of clothed people do not provide a tight bound on the true 3D shape. With clothed subjects, different poses provide different constraints on the possible underlying 3D body shape. We consequently combine constraints across pose to more accurately estimate 3D body shape in the presence of occluding clothing. Finally we use the recovered 3D shape to estimate the gender of subjects and then employ gender-specific body models to refine our shape estimates. Results on a novel …",A Balan and M Black,194,6706268975089896402,,,15-29,Springer Berlin/Heidelberg,The naked truth: Estimating body shape under clothing,https://link.springer.com/chapter/10.1007/978-3-540-88688-4_2,,2008,/scholar?cites=6706268975089896402,6NjbexEAAAAJ:RGFaLdJalmkC

1010066,"We propose a Bayesian framework for representing and recognizing local image motion in terms of two basic models: translational motion and motion boundaries. Motion boundaries are represented using a non-linear generative model that explicitly encodes the orientation of the boundary, the velocities on either side, the motion of the occluding edge over time, and the appearance/disappearance of pixels at the boundary. We represent the posterior probability distribution over the model parameters given the image data using discrete samples. This distribution is propagated over time using a particle filtering algorithm. To efficiently represent such a high-dimensional space we initialize samples using the responses of a low-level motion discontinuity detector. The formulation and computational model provide a general probabilistic framework for motion estimation with multiple, non-linear, models.",Michael J Black and David J Fleet,190,12016140948948240171,International Journal of Computer Vision,3,231-245,,Probabilistic Detection and Tracking of Motion Boundaries,https://link.springer.com/article/10.1023/A:1008195307933,38,2000,/scholar?cites=12016140948948240171,6NjbexEAAAAJ:22N0J9dj6kwC

1010067,"Estimation of three-dimensional articulated human pose and motion from images is a central problem in computer vision. Much of the previous work has been limited by the use of crude generative models of humans represented as articulated collections of simple parts such as cylinders. Automatic initialization of such models has proved difficult and most approaches assume that the size and shape of the body parts are known a priori. In this paper we propose a method for automatically recovering a detailed parametric model of non-rigid body shape and pose from monocular imagery. Specifically, we represent the body using a parameterized triangulated mesh model that is learned from a database of human range scans. We demonstrate a discriminative method to directly recover the model parameters from monocular images using a conditional mixture of kernel regressors. This predicted pose and shape are used to initialize a generative model for more detailed pose and shape estimation. The resulting approach allows fully automatic pose and shape recovery from monocular and multi-camera imagery. Experimental results show that our method is capable of robustly recovering articulated pose, shape and biometric measurements (eg height, weight, etc.) in both calibrated and uncalibrated camera environments.",Leonid Sigal and Alexandru Balan and Michael Black,183,6286001722305461401,Advances in neural information processing systems,,1337-1344,,Combined discriminative and generative articulated pose and non-rigid shape estimation,https://papers.nips.cc/paper/2007/file/a1140a3d0df1c81e24ae954d935e8926-Paper.pdf,20,2007,/scholar?cites=6286001722305461401,6NjbexEAAAAJ:J_g5lzvAfSwC

1010068,"This paper address the problems of modeling the appearance of humans and distinguishing human appearance from the appearance of general scenes. We seek a model of appearance and motion that is generic in that it accounts for the ways in which people's appearance varies and, at the same time, is specific enough to be useful for tracking people in natural scenes. Given a 3D model of the person projected into an image we model the likelihood of observing various image cues conditioned on the predicted locations and orientations of the limbs. These cues are taken to be steered filter responses corresponding to edges, ridges, and motion-compensated temporal differences. Motivated by work on the statistics of natural scenes, the statistics of these filter responses for human limbs are learned from training images containing hand-labeled limb regions. Similarly, the statistics of the filter responses in …",Hedvig Sidenbladh and Michael J Black,179,13229547497048663123,International Journal of Computer Vision,1-3,183-209,Kluwer Academic Publishers,Learning the statistics of people in images and video,https://link.springer.com/article/10.1023/A:1023765619733,54,2003,/scholar?cites=13229547497048663123,6NjbexEAAAAJ:YOwf2qJgpHMC

1010069,"A framework for learning parameterized models of optical flow from image sequences is presented. A class of motions is represented by a set of orthogonal basis flow fields that are computed from a training set using principal component analysis. Many complex image motions can be represented by a linear combination of a small number of these basis flows. The learned motion models may be used for optical flow estimation and for model-based recognition. For optical flow estimation we describe a robust, multi-resolution scheme for directly computing the parameters of the learned flow models from image derivatives. As examples we consider learning motion discontinuities, non-rigid motion of human mouths, and articulated human motion.",Michael J Black and Yaser Yacoob and Allan D Jepson and David J Fleet,177,12888906259857365589,,,561-567,IEEE,Learning parameterized models of image motion,https://ieeexplore.ieee.org/abstract/document/609381/,,1997,/scholar?cites=12888906259857365589,6NjbexEAAAAJ:4TOpqqG69KYC

1010070,"We describe a complete system for animating realistic clothing on synthetic bodies of any shape and pose without manual intervention. The key component of the method is a model of clothing called DRAPE (DRessing Any PErson) that is learned from a physics-based simulation of clothing on bodies of different shapes and poses. The DRAPE model has the desirable property of ""factoring"" clothing deformations due to body shape from those due to pose variation. This factorization provides an approximation to the physical clothing deformation and greatly simplifies clothing synthesis. Given a parameterized model of the human body with known shape and pose parameters, we describe an algorithm that dresses the body with a garment that is customized to fit and possesses realistic wrinkles. DRAPE can be used to dress static bodies or animated sequences with a learned model of the cloth dynamics. Since the …",Peng Guan and Loretta Reiss and David A Hirshberg and Alexander Weiss and Michael J Black,175,17709735777277518021,ACM Transactions on Graphics (TOG),4,1-10,ACM,Drape: Dressing any person,https://dl.acm.org/doi/abs/10.1145/2185520.2185531,31,2012,/scholar?cites=17709735777277518021,6NjbexEAAAAJ:-_dYPAW6P2MC

1010071,"The detection and pose estimation of people in images and video is made challenging by the variability of human appearance, the complexity of natural scenes, and the high dimensionality of articulated body models. To cope with these problems we represent the 3D human body as a graphical model in which the relationships between the body parts are represented by conditional probability distributions. We formulate the pose estimation problem as one of probabilistic inference over a graphical model where the random variables correspond to the individual limb parameters (position and orientation). Because the limbs are described by 6-dimensional vectors encoding pose in 3-space, discretization is impractical and the random variables in our model must be continuousvalued. To approximate belief propagation in such a graph we exploit a recently introduced generalization of the particle filter. This framework facilitates the automatic initialization of the body-model from low level cues and is robust to occlusion of body parts and scene clutter.",Leonid Sigal and Michael Isard and Benjamin H Sigelman and Michael J Black,175,5202621230790634180,,,1539--1546,MIT Press,Attractive people: Assembling loose-limbed models using non-parametric belief propagation,https://papers.nips.cc/paper/2003/file/cd10c7f376188a4a2ca3e8fea2c03aeb-Paper.pdf,16,2003,/scholar?cites=5202621230790634180,6NjbexEAAAAJ:qxL8FJ1GzNcC

1010072,"This paper describes a framework for learning probabilistic models of objects and scenes and for exploiting these models for tracking complex, deformable, or articulated objects in image sequences. We focus on the probabilistic tracking of people and learn models of how they appear and move in images. In particular we learn the likelihood of observing various spatial and temporal filter responses corresponding to edges, ridges, and motion differences given a model of the person. Similarly, we learn probability distributions over filter responses for general scenes that define a likelihood of observing the filter responses for arbitrary backgrounds. We then derive a probabilistic model for tracking that exploits the ratio between the likelihood that image pixels corresponding to the foreground (person) were generated by an actual person or by some unknown background. The paper extends previous work on learning …",Hedvig Sidenbladh and Michael J Black,173,8621877582194180886,,,709-716,IEEE,Learning image statistics for Bayesian tracking,https://ieeexplore.ieee.org/abstract/document/937696/,2,2001,/scholar?cites=8621877582194180886,6NjbexEAAAAJ:ULOm3_A8WrAC

1010073,"The direct neural control of external devices such as computer displays or prosthetic limbs requires the accurate decoding of neural activity representing continuous movement. We develop a real-time control system using the spiking activity of approximately 40 neurons recorded with an electrode array implanted in the arm area of primary motor cortex. In contrast to previous work, we develop a control-theoretic approach that explicitly models the motion of the hand and the probabilistic relationship between this motion and the mean firing rates of the cells in 70 § © bins. We focus on a realistic cursor control task in which the subject must move a cursor to “hit” randomly placed targets on a computer monitor. Encoding and decoding of the neural data is achieved with a Kalman filter which has a number of advantages over previous linear filtering techniques. In particular, the Kalman filter reconstructions of hand trajectories in off-line experiments are more accurate than previously reported results and the model provides insights into the nature of the neural coding of movement.",Wei Wu and M Black and Yun Gao and M Serruya and A Shaikhouni and J Donoghue and Elie Bienenstock,171,7410617236474236695,Advances in neural information processing systems,,133-140,,Neural decoding of cursor motion using a Kalman filter,https://papers.nips.cc/paper/2178-neural-decoding-of-cursor-motion-using-a-kalman-filter.pdf,15,2002,/scholar?cites=7410617236474236695,6NjbexEAAAAJ:mB3voiENLucC

1010074,"Marker-based motion capture (mocap) is widely criticized as producing lifeless animations. We argue that important information about body surface motion is present in standard marker sets but is lost in extracting a skeleton. We demonstrate a new approach called MoSh (Motion and Shape capture), that automatically extracts this detail from mocap data. MoSh estimates body shape and pose together using sparse marker data by exploiting a parametric model of the human body. In contrast to previous work, MoSh solves for the marker locations relative to the body and estimates accurate body shape directly from the markers without the use of 3D scans; this effectively turns a mocap system into an approximate body scanner. MoSh is able to capture soft tissue motions directly from markers by allowing body shape to vary over time. We evaluate the effect of different marker sets on pose and shape accuracy and …",Matthew Loper and Naureen Mahmood and Michael J Black,157,13557742074644626610,ACM Transactions on Graphics (TOG),6,1-13,ACM,MoSh: Motion and shape capture from sparse markers,https://dl.acm.org/doi/abs/10.1145/2661229.2661273,33,2014,/scholar?cites=13557742074644626610,6NjbexEAAAAJ:Mb21Z44dZ7IC

1010075,"We formulate the problem of 3D human pose estimation and tracking as one of inference in a graphical model. Unlike traditional kinematic tree representations, our model of the body is a collection of loosely-connected body-parts. In particular, we model the body using an undirected graphical model in which nodes correspond to parts and edges to kinematic, penetration, and temporal constraints imposed by the joints and the world. These constraints are encoded using pair-wise statistical distributions, that are learned from motion-capture training data. Human pose and motion estimation is formulated as inference in this graphical model and is solved using Particle Message Passing (PaMPas). PaMPas is a form of non-parametric belief propagation that uses a variation of particle filtering that can be applied over a general graphical model with loops. The loose-limbed model and decentralized graph …",Leonid Sigal and Michael Isard and Horst Haussecker and Michael J Black,157,11001180239352501178,International journal of computer vision,1,15-48,Springer US,Loose-limbed people: Estimating 3D human pose and motion using non-parametric belief propagation,https://link.springer.com/content/pdf/10.1007/s11263-011-0493-4.pdf,98,2012,/scholar?cites=11001180239352501178,6NjbexEAAAAJ:eMMeJKvmdy0C

1010076,"This paper proposes a solution for the automatic detection and tracking of human motion in image sequences. Due to the complexity of the human body and its motion, automatic detection of 3D human motion remains an open, and important, problem. Existing approaches for automatic detection and tracking focus on 2D cues and typically exploit object appearance (color distribution, shape) or knowledge of a static background. In contrast, we exploit 2D optical flow information which provides rich descriptive cues, while being independent of object and background appearance. To represent the optical flow patterns of people from arbitrary viewpoints, we develop a novel representation of human motion using low-dimensional spatio-temporal models that are learned using motion capture data of human subjects. In addition to human motion (the foreground) we probabilistically model the motion of generic …",Ronan Fablet and Michael Black,153,13556860271195402967,,,476-491,Springer Berlin/Heidelberg,Automatic detection and tracking of human motion with a view-based representation,https://link.springer.com/chapter/10.1007/3-540-47969-4_32,,2002,/scholar?cites=13556860271195402967,6NjbexEAAAAJ:ZeXyd9-uunAC

1010077,"Linear parameterized models of optical flow, particularly affine models, have become widespread in image motion analysis. The linear model coefficients are straightforward to estimate, and they provide reliable estimates of the optical flow of smooth surfaces. Here we explore the use of parameterized motion models that represent much more varied and complex motions. Our goals are threefold: to construct linear bases for complex motion phenomena; to estimate the coefficients of these linear models; and to recognize or classify image motions from the estimated coefficients. We consider two broad classes of motions: i) generic “motion features” such as motion discontinuities and moving bars; and ii) non-rigid, object-specific, motions such as the motion of human mouths. For motion features we construct a basis of steerable flow fields that approximate the motion features. For object-specific motions we construct …",David J Fleet and Michael J Black and Yaser Yacoob and Allan D Jepson,152,15055135305017650977,International Journal of Computer Vision,3,171-193,Kluwer Academic Publishers,Design and use of linear models for image motion analysis,https://link.springer.com/article/10.1023/A:1008156202475,36,2000,/scholar?cites=15055135305017650977,6NjbexEAAAAJ:4DMP91E08xMC

1010078,"The analysis of extra-cellular neural recordings typically begins with careful spike sorting and all analysis of the data then rests on the correctness of the resulting spike trains. In many situations this is unproblematic as experimental and spike sorting procedures often focus on well isolated units. There is evidence in the literature, however, that errors in spike sorting can occur even with carefully collected and selected data. Additionally, chronically implanted electrodes and arrays with fixed electrodes cannot be easily adjusted to provide well isolated units. In these situations, multiple units may be recorded and the assignment of waveforms to units may be ambiguous. At the same time, analysis of such data may be both scientifically important and clinically relevant. In this paper we address this issue using a novel probabilistic model that accounts for several important sources of uncertainty and error in spike sorting …",Frank Wood and Michael J Black,151,12841649248523658297,Journal of neuroscience methods,1,1-12,Elsevier,A nonparametric Bayesian alternative to spike sorting,https://www.sciencedirect.com/science/article/pii/S0165027008002549,173,2008,/scholar?cites=12841649248523658297,6NjbexEAAAAJ:3s1wT3WcHBgC

1010079,"We accurately estimate the 3D geometry and appearance of the human body from a monocular RGB-D sequence of a user moving freely in front of the sensor. Range data in each frame is first brought into alignment with a multi-resolution 3D body model in a coarse-to-fine process. The method then uses geometry and image texture over time to obtain accurate shape, pose, and appearance information despite unconstrained motion, partial views, varying resolution, occlusion, and soft tissue deformation. Our novel body model has variable shape detail, allowing it to capture faces with a high-resolution deformable head model and body shape with lower-resolution. Finally we combine range data from an entire sequence to estimate a high-resolution displacement map that captures fine shape details. We compare our recovered models with high-resolution scans from a professional system and with avatars created by a commercial product. We extract accurate 3D avatars from challenging motion sequences and even capture soft tissue dynamics.",Federica Bogo and Michael J Black and Matthew Loper and Javier Romero,150,4054131937270479223,,,2300-2308,,Detailed full-body reconstructions of moving people from monocular RGB-D sequences,http://openaccess.thecvf.com/content_iccv_2015/html/Bogo_Detailed_Full-Body_Reconstructions_ICCV_2015_paper.html,,2015,/scholar?cites=4054131937270479223,6NjbexEAAAAJ:GdooyxxgJVwC

1010080,"Learned 3D representations of human faces are useful for computer vision problems such as 3D face tracking and reconstruction from images, as well as graphics applications such as character generation and animation. Traditional models learn a latent representation of a face using linear subspaces or higher-order tensor generalizations. Due to this linearity, they can not capture extreme deformations and non-linear expressions. To address this, we introduce a versatile model that learns a non-linear representation of a face using spectral convolutions on a mesh surface. We introduce mesh sampling operations that enable a hierarchical mesh representation that captures non-linear variations in shape and expression at multiple scales within the model. In a variational setting, our model samples diverse realistic 3D faces from a multivariate Gaussian distribution. Our training data consists of 20,466 meshes of extreme expressions captured over 12 different subjects. Despite limited training data, our trained model outperforms state-of-the-art face models with 50% lower reconstruction error, while using 75% fewer parameters. We also show that, replacing the expression space of an existing state-of-the-art face model with our autoencoder, achieves a lower reconstruction error. Our data, model and code are available at http://coma. is. tue. mpg. de/.",Anurag Ranjan and Timo Bolkart and Soubhik Sanyal and Michael J Black,148,7357268074603147679,,,704-720,,Generating 3D faces using convolutional mesh autoencoders,http://openaccess.thecvf.com/content_ECCV_2018/html/Anurag_Ranjan_Generating_3D_Faces_ECCV_2018_paper.html,,2018,/scholar?cites=7357268074603147679,6NjbexEAAAAJ:QoN_6baHBqgC

1010081,"Designing and simulating realistic clothing is challenging. Previous methods addressing the capture of clothing from 3D scans have been limited to single garments and simple motions, lack detail, or require specialized texture patterns. Here we address the problem of capturing regular clothing on fully dressed people in motion. People typically wear multiple pieces of clothing at a time. To estimate the shape of such clothing, track it over time, and render it believably, each garment must be segmented from the others and the body. Our ClothCap approach uses a new multi-part 3D model of clothed bodies, automatically segments each piece of clothing, estimates the minimally clothed body shape and pose under the clothing, and tracks the 3D deformations of the clothing over time. We estimate the garments and their motion from 4D scans; that is, high-resolution 3D scans of the subject in motion at 60 fps. ClothCap …",Gerard Pons-Moll and Sergi Pujades and Sonny Hu and Michael J Black,148,1587162403073867686,ACM Transactions on Graphics (TOG),4,1-15,ACM,ClothCap: Seamless 4D clothing capture and retargeting,https://dl.acm.org/doi/abs/10.1145/3072959.3073711,36,2017,/scholar?cites=1587162403073867686,6NjbexEAAAAJ:qaiyjGHpP8sC

1010082,"The recognition of human gestures in image sequences is an important and challenging problem that enables a host of human-computer interaction applications. This paper describes an incremental recognition strategy that is an extension of the ""Condensation"" algorithm proposed by Isard and Blake (1996). Gestures are modeled as temporal trajectories of some estimated parameter over time (in this case velocity). The condensation algorithm is used to incrementally match the gesture models to the input data. The method is demonstrated with an example of an augmented office white-board in which a user makes simple hand gestures to grab regions of the board, print them, save them, etc.",Michael J Black and Allan D Jepson,144,8618722110414591780,,,16-21,IEEE,Recognizing temporal trajectories using the condensation algorithm,https://ieeexplore.ieee.org/abstract/document/670919/,,1998,/scholar?cites=8618722110414591780,6NjbexEAAAAJ:aqlVkmm33-oC

1010083,"This paper presents a method for incrementally segmenting images over time using both intensity and motion information. This is done by formulating a model of physically significant image resgions using local constraints on intensity and motion and then finding the optimal segmentation over time using an incremental stochastic minimization technique. The result is a robust and dynamic segmentation of the scene over a sequence of images. The approach has a number of benefits. First, discontinuities are extracted and tracked simultaneously. Second, a segmentation is always available and it improves over time. Finally, by combining motion and intensity, the structural properties of discontinuities can be recovered; that is, discontinuities can be classified as surface markings or actual surface boundaries.",Michael Black,142,2042397070492731683,,,485-493,Springer Berlin/Heidelberg,Combining intensity and motion for incremental segmentation and tracking over long image sequences,https://link.springer.com/chapter/10.1007/3-540-55426-2_54,,1992,/scholar?cites=2042397070492731683,6NjbexEAAAAJ:Wp0gIr-vW9MC

1010084,"In this work, we propose a method that combines a single hand-held camera and a set of Inertial Measurement Units (IMUs) attached at the body limbs to estimate accurate 3D poses in the wild. This poses many new challenges: the moving camera, heading drift, cluttered background, occlusions and many people visible in the video. We associate 2D pose detections in each image to the corresponding IMU-equipped persons by solving a novel graph based optimization problem that forces 3D to 2D coherency within a frame and across long range frames. Given associations, we jointly optimize the pose of a statistical body model, the camera pose and heading drift using a continuous optimization framework. We validated our method on the TotalCapture dataset, which provides video and IMU synchronized with ground truth. We obtain an accuracy of 26mm, which makes it accurate enough to serve as a benchmark for image-based 3D pose estimation in the wild. Using our method, we recorded 3D Poses in the Wild (3DPW), a new dataset consisting of more than 51; 000 frames with accurate 3D pose in challenging sequences, including walking in the city, going up-stairs, having coffee or taking the bus. We make the reconstructed 3D poses, video, IMU and 3D models available for research purposes at http://virtualhumans. mpi-inf. mpg. de/3DPW.",Timo von Marcard and Roberto Henschel and Michael J Black and Bodo Rosenhahn and Gerard Pons-Moll,141,3991334045511862131,,,601-617,,Recovering accurate 3d human pose in the wild using imus and a moving camera,http://openaccess.thecvf.com/content_ECCV_2018/html/Timo_von_Marcard_Recovering_Accurate_3D_ECCV_2018_paper.html,,2018,/scholar?cites=3991334045511862131,6NjbexEAAAAJ:BnRbUGEozz8C

1010085,"Existing optical flow methods make generic, spatially homogeneous, assumptions about the spatial structure of the flow. In reality, optical flow varies across an image depending on object class. Simply put, different objects move differently. Here we exploit recent advances in static semantic scene segmentation to segment the image into objects of different types. We define different models of image motion in these regions depending on the type of object. For example, the road motion with homographies, vegetation with spatially smooth flow, and independently moving objects like cars and planes with affine+ deviations. We then pose the flow estimation problem using a novel formulation of localized layers, which addresses limitations of traditional layered models for dealing with complex scene motion. Our semantic flow method achieves the lowest error of any published method in the KITTI-2015 flow benchmark and produces qualitatively better flow and segmentation than recent top methods on a wide range of natural videos.",Laura Sevilla-Lara and Deqing Sun and Varun Jampani and Michael J Black,140,5957770392766384609,,,3889-3898,,Optical flow with semantic segmentation and localized layers,https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Sevilla-Lara_Optical_Flow_With_CVPR_2016_paper.html,,2016,/scholar?cites=5957770392766384609,6NjbexEAAAAJ:c2351ekuFcIC

1010086,"We present methods for learning and tracking human motion in video. We estimate a statistical model of typical activities from a large set of 3D periodic human motion data by segmenting these data automatically into"" cycles"". Then the mean and the principal components of the cycles are computed using a new algorithm that accounts for missing information and enforces smooth transitions between cycles. The learned temporal model provides a prior probability distribution over human motions that can be used in a Bayesian framework for tracking human subjects in complex monocular video sequences and recovering their 3D motion.",Dirk Ormoneit and Hedvig Sidenbladh and Michael J Black and Trevor Hastie,137,5865598144720703581,,,894-900,,Learning and tracking cyclic human motion,https://papers.nips.cc/paper/1938-learning-and-tracking-cyclic-human-motion.pdf,,2001,/scholar?cites=5865598144720703581,6NjbexEAAAAJ:L8Ckcad2t8MC

1010087,"To facilitate the analysis of human actions, interactions and emotions, we compute a 3D model of human body pose, hand pose, and facial expression from a single monocular image. To achieve this, we use thousands of 3D scans to train a new, unified, 3D model of the human body, SMPL-X, that extends SMPL with fully articulated hands and an expressive face. Learning to regress the parameters of SMPL-X directly from images is challenging without paired images and 3D ground truth. Consequently, we follow the approach of SMPLify, which estimates 2D features and then optimizes model parameters to fit the features. We improve on SMPLify in several significant ways:(1) we detect 2D features corresponding to the face, hands, and feet and fit the full SMPL-X model to these;(2) we train a new neural network pose prior using a large MoCap dataset;(3) we define a new interpenetration penalty that is both fast and accurate;(4) we automatically detect gender and the appropriate body models (male, female, or neutral);(5) our PyTorch implementation achieves a speedup of more than 8x over Chumpy. We use the new method, SMPLify-X, to fit SMPL-X to both controlled images and images in the wild. We evaluate 3D accuracy on a new curated dataset comprising 100 images with pseudo ground-truth. This is a step towards automatic expressive human capture from monocular RGB data. The models, code, and data are available for research purposes at https://smpl-x. is. tue. mpg. de.",Georgios Pavlakos and Vasileios Choutas and Nima Ghorbani and Timo Bolkart and Ahmed AA Osman and Dimitrios Tzionas and Michael J Black,135,18089618953278262954,,,10975-10985,,"Expressive body capture: 3d hands, face, and body from a single image",http://openaccess.thecvf.com/content_CVPR_2019/html/Pavlakos_Expressive_Body_Capture_3D_Hands_Face_and_Body_From_a_CVPR_2019_paper.html,,2019,/scholar?cites=18089618953278262954,6NjbexEAAAAJ:6E5OHDUOeTQC

1010088,"Three-dimensional (3D) shape models are powerful because they enable the inference of object shape from incomplete, noisy, or ambiguous 2D or 3D data. For example, realistic parameterized 3D human body models have been used to infer the shape and pose of people from images. To train such models, a corpus of 3D body scans is typically brought into registration by aligning a common 3D human-shaped template to each scan. This is an ill-posed problem that typically involves solving an optimization problem with regularization terms that penalize implausible deformations of the template. When aligning a corpus, however, we can do better than generic regularization. If we have a model of how the template can deform then alignments can be regularized by this model. Constructing a model of deformations, however, requires having a corpus that is already registered. We address this chicken-and …",David A Hirshberg and Matthew Loper and Eric Rachlin and Michael J Black,134,5699426804574183184,,,242-255,"Springer, Berlin, Heidelberg",Coregistration: Simultaneous alignment and modeling of articulated 3D shape,https://link.springer.com/chapter/10.1007/978-3-642-33783-3_18,,2012,/scholar?cites=5699426804574183184,6NjbexEAAAAJ:BUYA1_V_uYcC

1010089,"Page 1. Learning a model of facial shape and expression from 4D scans Tianye Li*, Timo Bolkart*,
Michael J. Black, Hao Li, Javier Romero SIGGRAPH Asia 2017 Note: this slide is a static .pdf
version (no video) For video, please see: https://youtu.be/36rPTkhiJTM Page 2. Realistic Virtual
Character Warner Bros. & Paramount Pictures Page 3. Realistic Virtual Character Warner Bros.
& Paramount Pictures Page 4. Consumer Application Apple 2017 Page 5. Spectrum of Face
Models “Low-end” “High-end” Page 6. Spectrum of Face Models “Low-end” “High-end”
FACS-based blendshapes Page 7. Spectrum of Face Models “Low-end” “High-end” FACS-based
blendshapes Blanz and Vetter 1999 & Basel Face Model [Paysan et al. 2009] Page 8. Spectrum
of Face Models “Low-end” “High-end” FACS-based blendshapes Blanz and Vetter 1999
FaceWarehouse [Cao et al. 2014] & Basel Face Model [Paysan et al. 2009] Page … 
",Tianye Li and Timo Bolkart and Michael J Black and Hao Li and Javier Romero,133,12545908227329232832,ACM Trans. Graph.,6,194:1-194:17,,Learning a model of facial shape and expression from 4D scans.,https://slides.games-cn.org/pdf/GAMES201727%E6%9D%8E%E5%A4%A9%E9%87%8E.pdf,36,2017,/scholar?cites=12545908227329232832,6NjbexEAAAAJ:s9piBQ-TX4wC

1010090,"We present a point-and-click intracortical neural interface system (NIS) that enables humans with tetraplegia to volitionally move a 2-D computer cursor in any desired direction on a computer screen, hold it still, and click on the area of interest. This direct brain-computer interface extracts both discrete (click) and continuous (cursor velocity) signals from a single small population of neurons in human motor cortex. A key component of this system is a multi-state probabilistic decoding algorithm that simultaneously decodes neural spiking activity of a small population of neurons and outputs either a click signal or the velocity of the cursor. The algorithm combines a linear classifier, which determines whether the user is intending to click or move the cursor, with a Kalman filter that translates the neural population activity into cursor velocity. We present a paradigm for training the multi-state decoding algorithm using neural …",Sung-Phil Kim and John D Simeral and Leigh R Hochberg and John P Donoghue and Gerhard M Friehs and Michael J Black,133,1676104322779874712,IEEE transactions on neural systems and rehabilitation engineering,2,193-203,IEEE,Point-and-click cursor control with an intracortical neural interface system by humans with tetraplegia,https://ieeexplore.ieee.org/abstract/document/5703131/,19,2011,/scholar?cites=1676104322779874712,6NjbexEAAAAJ:XiSMed-E-HIC

1010091,"Layered models are a powerful way of describing natural scenes containing smooth surfaces that may overlap and occlude each other. For image motion estimation, such models have a long history but have not achieved the wide use or accuracy of non-layered methods. We present a new probabilistic model of optical flow in layers that addresses many of the shortcomings of previous approaches. In particular, we define a probabilistic graphical model that explicitly captures: 1) occlusions and disocclusions; 2) depth ordering of the layers; 3) temporal consistency of the layer segmentation. Additionally the optical flow in each layer is modeled by a combination of a parametric model and a smooth deviation based on an MRF with a robust spatial prior; the resulting model allows roughness in layers. Finally, a key contribution is the formulation of the layers using an image-dependent hidden field prior based on recent models for static scene segmentation. The method achieves state-of-the-art results on the Middlebury benchmark and produces meaningful scene segmentations as well as detected occlusion regions.",Deqing Sun and Erik B Sudderth and Michael J Black,132,18338961038216206734,,,2226-2234,,"Layered image motion with explicit occlusions, temporal consistency, and depth ordering",https://papers.nips.cc/paper/4030-layered-image-motion-with-explicit-occlusions-temporal-consistency-and-depth-ordering,,2010,/scholar?cites=18338961038216206734,6NjbexEAAAAJ:vRqMK49ujn8C

1010092,"We propose a hierarchical process for inferring the 3D pose of a person from monocular images. First we infer a learned view-based 2D body model from a single image using non-parametric belief propagation. This approach integrates information from bottom-up body-part proposal processes and deals with self-occlusion to compute distributions over limb poses. Then, we exploit a learned Mixture of Experts model to infer a distribution of 3D poses conditioned on 2D poses. This approach is more general than recent work on inferring 3D pose directly from silhouettes since the 2D body model provides a richer representation that includes the 2D joint angles and the poses of limbs that may be unobserved in the silhouette. We demonstrate the method in a laboratory setting where we evaluate the accuracy of the 3D poses against ground truth data. We also estimate 3D body pose in a monocular image …",Leonid Sigal and Michael J Black,132,16074281044317741323,,,185-195,"Springer, Berlin, Heidelberg",Predicting 3d people from 2d pictures,https://link.springer.com/chapter/10.1007/11789239_19,,2006,/scholar?cites=16074281044317741323,6NjbexEAAAAJ:-f6ydRqryjwC

1010093,"Layered models provide a compelling approach for estimating image motion and segmenting moving scenes. Previous methods, however, have failed to capture the structure of complex scenes, provide precise object boundaries, effectively estimate the number of layers in a scene, or robustly determine the depth order of the layers. Furthermore, previous methods have focused on optical flow between pairs of frames rather than longer sequences. We show that image sequences with more frames are needed to resolve ambiguities in depth ordering at occlusion boundaries; temporal layer constancy makes this feasible. Our generative model of image sequences is rich but difficult to optimize with traditional gradient descent methods. We propose a novel discrete approximation of the continuous objective in terms of a sequence of depth-ordered MRFs and extend graph-cut optimization methods with new “moves …",Deqing Sun and Erik B Sudderth and Michael J Black,125,13393523068486220466,,,1768-1775,IEEE,Layered segmentation and optical flow estimation over time,https://ieeexplore.ieee.org/abstract/document/6247873/,,2012,/scholar?cites=13393523068486220466,6NjbexEAAAAJ:_Re3VWB3Y0AC

1010094,"We address the elusive goal of estimating optical flow both accurately and efficiently by adopting a sparse-to-dense approach. Given a set of sparse matches, we regress to dense optical flow using a learned set of full-frame basis flow fields. We learn the principal components of natural flow fields using flow computed from four Hollywood movies. Optical flow fields are then compactly approximated as a weighted sum of the basis flow fields. Our new PCA-Flow algorithm robustly estimates these weights from sparse feature matches. The method runs in under 200ms/frame on the MPI-Sintel dataset using a single CPU and is more accurate and significantly faster than popular methods such as LDOF and Classic+ NL. For some applications, however, the results are too smooth. Consequently, we develop a novel sparse layered flow method in which each layer is represented by PCA-Flow. Unlike existing layered methods, estimation is fast because it uses only sparse matches. We combine information from different layers into a dense flow field using an image-aware MRF. The resulting PCA-Layers method runs in 3.2 s/frame, is significantly more accurate than PCA-Flow, and achieves state-of-the-art performance in occluded regions on MPI-Sintel.",Jonas Wulff and Michael J Black,122,14292319850490054558,,,120-130,,Efficient sparse-to-dense optical flow estimation using a learned basis and layers,http://openaccess.thecvf.com/content_cvpr_2015/html/Wulff_Efficient_Sparse-to-Dense_Optical_2015_CVPR_paper.html,,2015,/scholar?cites=14292319850490054558,6NjbexEAAAAJ:0oeUc68sgesC

1010095,"We address the unsupervised learning of several interconnected problems in low-level vision: single view depth prediction, camera motion estimation, optical flow, and segmentation of a video into the static scene and moving regions. Our key insight is that these four fundamental vision problems are coupled through geometric constraints. Consequently, learning to solve them together simplifies the problem because the solutions can reinforce each other. We go beyond previous work by exploiting geometry more explicitly and segmenting the scene into static and moving regions. To that end, we introduce Competitive Collaboration, a framework that facilitates the coordinated training of multiple specialized neural networks to solve complex problems. Competitive Collaboration works much like expectation-maximization, but with neural networks that act as both competitors to explain pixels that correspond to static or moving regions, and as collaborators through a moderator that assigns pixels to be either static or independently moving. Our novel method integrates all these problems in a common framework and simultaneously reasons about the segmentation of the scene into moving objects and the static background, the camera motion, depth of the static scene structure, and the optical flow of moving objects. Our model is trained without any supervision and achieves state-of-the-art performance among joint unsupervised methods on all sub-problems.",Anurag Ranjan and Varun Jampani and Lukas Balles and Kihwan Kim and Deqing Sun and Jonas Wulff and Michael J Black,120,8899288224036536376,,,12240-12249,,"Competitive Collaboration: Joint Unsupervised Learning of Depth, Camera Motion, Optical Flow and Motion Segmentation",http://openaccess.thecvf.com/content_CVPR_2019/html/Ranjan_Competitive_Collaboration_Joint_Unsupervised_Learning_of_Depth_Camera_Motion_Optical_CVPR_2019_paper.html,,2019,/scholar?cites=8899288224036536376,6NjbexEAAAAJ:mYLs_rVKHI4C

1010096,"While the ready availability of 3D scan data has influenced research throughout computer vision, less attention has focused on 4D data; that is 3D scans of moving non-rigid objects, captured over time. To be useful for vision research, such 4D scans need to be registered, or aligned, to a common topology. Consequently, extending mesh registration methods to 4D is important. Unfortunately, no ground-truth datasets are available for quantitative evaluation and comparison of 4D registration methods. To address this we create a novel dataset of high-resolution 4D scans of human subjects in motion, captured at 60 fps. We propose a new mesh registration method that uses both 3D geometry and texture information to register all scans in a sequence to a common reference topology. The approach exploits consistency in texture over both short and long time intervals and deals with temporal offsets between shape and texture capture. We show how using geometry alone results in significant errors in alignment when the motions are fast and non-rigid. We evaluate the accuracy of our registration and provide a dataset of 40,000 raw and aligned meshes. Dynamic FAUST extends the popular FAUST dataset to dynamic 4D data, and is available for research purposes at http://dfaust. is. tue. mpg. de.",Federica Bogo and Javier Romero and Gerard Pons-Moll and Michael J Black,117,10005402680584463684,,,6233-6242,,Dynamic FAUST: Registering human bodies in motion,http://openaccess.thecvf.com/content_cvpr_2017/html/Bogo_Dynamic_FAUST_Registering_CVPR_2017_paper.html,,2017,/scholar?cites=10005402680584463684,6NjbexEAAAAJ:Jxy3h8XkNu0C

1010097,"Model-based human pose estimation is currently approached through two different paradigms. Optimization-based methods fit a parametric body model to 2D observations in an iterative manner, leading to accurate image-model alignments, but are often slow and sensitive to the initialization. In contrast, regression-based methods, that use a deep network to directly estimate the model parameters from pixels, tend to provide reasonable, but not pixel accurate, results while requiring huge amounts of supervision. In this work, instead of investigating which approach is better, our key insight is that the two paradigms can form a strong collaboration. A reasonable, directly regressed estimate from the network can initialize the iterative optimization making the fitting faster and more accurate. Similarly, a pixel accurate fit from iterative optimization can act as strong supervision for the network. This is the core of our proposed approach SPIN (SMPL oPtimization IN the loop). The deep network initializes an iterative optimization routine that fits the body model to 2D joints within the training loop, and the fitted estimate is subsequently used to supervise the network. Our approach is self-improving by nature, since better network estimates can lead the optimization to better solutions, while more accurate optimization fits provide better supervision for the network. We demonstrate the effectiveness of our approach in different settings, where 3D ground truth is scarce, or not available, and we consistently outperform the state-of-the-art model-based pose estimation approaches by significant margins. The project website with videos, results, and code can be found at …",Nikos Kolotouros and Georgios Pavlakos and Kostas Black and Michael J. and Daniilidis,116,3402119084543021754,International Conference on Computer Vision,2,3,,Learning to reconstruct 3D human pose and shape via model-fitting in the loop,http://openaccess.thecvf.com/content_ICCV_2019/html/Kolotouros_Learning_to_Reconstruct_3D_Human_Pose_and_Shape_via_Model-Fitting_ICCV_2019_paper.html,1,2019,/scholar?cites=3402119084543021754,6NjbexEAAAAJ:vptNTMqK6uYC

1010098,"We address the problem of estimating human pose and body shape from 3D scans over time. Reliable estimation of 3D body shape is necessary for many applications including virtual try-on, health monitoring, and avatar creation for virtual reality. Scanning bodies in minimal clothing, however, presents a practical barrier to these applications. We address this problem by estimating body shape under clothing from a sequence of 3D scans. Previous methods that have exploited body models produce smooth shapes lacking personalized details. We contribute a new approach to recover a personalized shape of the person. The estimated shape deviates from a parametric model to fit the 3D scans. We demonstrate the method using high quality 4D data as well as sequences of visual hulls extracted from multi-view images. We also make available BUFF, a new 4D dataset that enables quantitative evaluation (http://buff. is. tue. mpg. de). Our method outperforms the state of the art in both pose estimation and shape estimation, qualitatively and quantitatively.",Chao Zhang and Sergi Pujades and Michael J Black and Gerard Pons-Moll,113,15213240969419514022,,,4191-4200,,"Detailed, accurate, human shape estimation from clothed 3D scan sequences",http://openaccess.thecvf.com/content_cvpr_2017/html/Zhang_Detailed_Accurate_Human_CVPR_2017_paper.html,,2017,/scholar?cites=15213240969419514022,6NjbexEAAAAJ:9Df4XUWggEMC

1010099,"A method and apparatus analyzes and annotates a technical talk typically illustrated with overhead slides, wherein the slides are recorded in a video sequence. The video sequence is condensed and digested into key video frames adaptable for annotation to time and audio sequence. The system comprises a recorder for recording a technical talk as a sequential set of video image frames. A stabilizing processor segregates the video image frames into a plurality of associated subsets each corresponding to a distinct slide displayed at the talk and for median filtering of the subsets for generating a key frame representative of each of the subsets. A comparator compares the key frame with the associated subsets to identify differences between the key frame and the associates subset which comprise nuisances and affordances. A gesture recognizer locates, tracks and recognizes gestures occurring in the subset as …",,113,6695796166909554477,,,,,Method and apparatus for generating a condensed version of a video sequence including desired affordances,https://patents.google.com/patent/US6560281B1/en,,2003,/scholar?cites=6695796166909554477,6NjbexEAAAAJ:GnPB-g6toBAC

1010100,"Statistical learning and probabilistic inference techniques are used to infer the hand position of a subject from multi-electrode recordings of neural activity in motor cortex. First, an array of electrodes provides training data of neural firing conditioned on hand kinematics. We learn a nonparametric representation of this firing activity using a Bayesian model and rigorously compare it with previous models using cross-validation. Second, we infer a posterior probability distribution over hand motion conditioned on a sequence of neural test data using Bayesian inference. The learned firing models of multiple cells are used to define a non-Gaussian likelihood term which is combined with a prior probability for the kinematics. A particle filtering method is used to represent, update, and propagate the posterior distribution over time. The approach is compared with traditional linear filtering methods; the results suggest that it may be appropriate for neural prosthetic applications.",Yun Gao and Michael Black and Elie Bienenstock and Shy Shoham and John Donoghue,112,2199326043260876681,Advances in neural information processing systems,,213-220,,Probabilistic inference of hand motion from neural activity in motor cortex,https://papers.nips.cc/paper/2001/file/06964dce9addb1c5cb5d6e3d9838f733-Paper.pdf,14,2001,/scholar?cites=2199326043260876681,6NjbexEAAAAJ:qUcmZB5y_30C

1010101,"We address the problem of making human motion capture in the wild more practical by using a small set of inertial sensors attached to the body. Since the problem is heavily under‐constrained, previous methods either use a large number of sensors, which is intrusive, or they require additional video input. We take a different approach and constrain the problem by: (i) making use of a realistic statistical body model that includes anthropometric constraints and (ii) using a joint optimization framework to fit the model to orientation and acceleration measurements over multiple frames. The resulting tracker Sparse Inertial Poser (SIP) enables motion capture using only 6 sensors (attached to the wrists, lower legs, back and head) and works for arbitrary human motions. Experiments on the recently released TNT15 dataset show that, using the same number of sensors, SIP achieves higher accuracy than the dataset …",Timo von Marcard and Bodo Rosenhahn and Michael J Black and Gerard Pons‐Moll,110,11065955911209965273,Computer Graphics Forum,2,349-360,,Sparse inertial poser: Automatic 3d human pose estimation from sparse imus,https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13131,36,2017,/scholar?cites=11065955911209965273,6NjbexEAAAAJ:T5V60G5X4B8C

1010102,"The detection and tracking of three-dimensional human body models has progressed rapidly but successful approaches typically rely on accurate foreground silhouettes obtained using background segmentation. There are many practical applications where such information is imprecise. Here we develop a new image likelihood function based on the visual appearance of the subject being tracked. We propose a robust, adaptive, appearance model based on the Wandering-Stable-Lost framework extended to the case of articulated body parts. The method models appearance using a mixture model that includes an adaptive template, frame-to-frame matching and an outlier process. We employ an annealed particle filtering algorithm for inference and take advantage of the 3D body model to predict selfocclusion and improve pose estimation accuracy. Quantitative tracking results are presented for a walking …",Alexandru O Balan and Michael J Black,109,4403156636902610760,,,758-765,IEEE,An adaptive appearance model approach for model-based articulated object tracking,https://ieeexplore.ieee.org/abstract/document/1640830/,1,2006,/scholar?cites=4403156636902610760,6NjbexEAAAAJ:BqipwSGYUEgC

1010103,"This paper presents an automatic system for analyzing and annotating video sequences of technical talks. Our method uses a robust motion estimation technique to detect key frames and segment the video sequence into subsequences containing a single overhead slide. The subsequences are stabilized to remove motion that occurs when the speaker adjusts their slides. Any changes remaining between frames in the stabilized sequences may be due to speaker gestures such as pointing or writing, and we use active contours to automatically track these potential gestures. Given the constrained domain, we define a simple set of actions that can be recognized based on the active contour shape and motion. The recognized actions provide an annotation of the sequence that can be used to access a condensed version of the talk from a Web page.",Shanon X Ju and Michael J Black and Scott Minneman and Don Kimber,109,3189296647859505959,IEEE Transactions on Circuits and Systems for Video Technology,5,686-696,IEEE,Summarization of videotaped presentations: automatic analysis of motion and gesture,https://ieeexplore.ieee.org/abstract/document/718513/,8,1998,/scholar?cites=3189296647859505959,6NjbexEAAAAJ:hC7cP41nSMkC

1010104,"Edges are viewed as statistical outliers with respect to local image gradient magnitudes. Within local image regions we compute a robust statistical measure of the gradient variation and use this in an anisotropic diffusion framework to determine a spatially varying “edge- stopping” parameter σ. We show how to determine this parameter for two edge-stopping functions described in the literature (Perona-Malik and the Tukey biweight). Smoothing of the image is related the local texture and in regions of low texture, small gradient values may be treated as edges whereas in regions of high texture, large gradient magni- tudes are necessary before an edge is preserved. Intuitively these results have similarities with human perceptual phenomena such as masking and “popout”. Results are shown on a variety of standard images.",Michael J Black and Guillermo Sapiro,108,6840431233256756913,,,259-270,"Springer, Berlin, Heidelberg",Edges as outliers: Anisotropic smoothing using local image statistics,https://link.springer.com/chapter/10.1007/3-540-48236-9_23,,1999,/scholar?cites=6840431233256756913,6NjbexEAAAAJ:TQgYirikUcIC

1010105,"Image ""appearance"" may change over time due to a variety of causes such as: 1) object or camera motion; 2) generic photometric events including variations in illumination (e.g. shadows) and specular reflections; and 3) ""iconic changes"" which are specific to the objects being viewed and include complex occlusion events and changes in the material properties of the objects. We propose a general framework for representing and recovering these ""appearance changes"" in an image sequence as a ""mixture"" of different causes. The approach generalizes previous work on optical flow to provide a richer description of image events and more reliable estimates of image motion.",Michael J Black and David J Fleet and Yaser Yacoob,103,14738956681373513951,,,660-667,IEEE,A framework for modeling appearance change in image sequences,https://ieeexplore.ieee.org/abstract/document/710788/,,1998,/scholar?cites=14738956681373513951,6NjbexEAAAAJ:RHpTSmoSYBkC

1010106,"We propose a new 3D model of the human body that is both realistic and part-based. The body is represented by a graphical model in which nodes of the graph correspond to body parts that can independently translate and rotate in 3D and deform to represent different body shapes and to capture pose-dependent shape variations. Pairwise potentials define a"" stitching cost"" for pulling the limbs apart, giving rise to the Stitched Puppet (SP) model. Unlike existing realistic 3D body models, the distributed representation facilitates inference by allowing the model to more effectively explore the space of poses, much like existing 2D pictorial structures models. We infer pose and body shape using a form of particle-based max-product belief propagation. This gives SP the realism of recent 3D body models with the computational advantages of part-based models. We apply SP to two challenging problems involving estimating human shape and pose from 3D data. The first is the FAUST mesh alignment challenge, where ours is the first method to successfully align all 3D meshes with no pose prior. The second involves estimating pose and shape from crude visual hull representations of complex body movements.",Silvia Zuffi and Michael J Black,102,4225203851727441401,,,3537-3546,,The stitched puppet: A graphical model of 3d human shape and pose,https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Zuffi_The_Stitched_Puppet_2015_CVPR_paper.html,,2015,/scholar?cites=4225203851727441401,6NjbexEAAAAJ:ZJWHNt7Cjk4C

1010107,"In scenes containing specular objects, the image motion observed by a moving camera may be an intermixed combination of optical flow resulting from diffuse reflectance (diffuse flow) and specular reflection (specular flow). Here, with few assumptions, we formalize the notion of specular flow, show how it relates to the 3D structure of the world, and develop an algorithm for estimating scene structure from 2D image motion. Unlike previous work on isolated specular highlights we use two image frames and estimate the semi-dense flow arising from the specular reflections of textured scenes. We parametrically model the image motion of a quadratic surface patch viewed from a moving camera. The flow is modeled as a probabilistic mixture of diffuse and specular components and the 3D shape is recovered using an Expectation-Maximization algorithm. Rather than treating specular reflections as noise to be removed or …",Stefan Roth and Michael J Black,99,14104759836722495105,,,1869-1876,IEEE,Specular flow and the recovery of surface structure,https://ieeexplore.ieee.org/abstract/document/1640981/,2,2006,/scholar?cites=14104759836722495105,6NjbexEAAAAJ:vV6vV6tmYwMC

1010108,"This paper develops a control-theoretic approach to the problem of decoding neural activity in motor cortex. Our goal is to infer the position and velocity of a subject's hand from the neural spiking activity of 25 cells simultaneously recorded in primary motor cortex. We propose to model the encoding and decoding of the neural data using a Kalman filter. Towards that end we specify a measurement model that assumes the firing rate of a cell within 50ms is a stochastic linear function of position, velocity, and acceleration of the hand. This model is learned from training data along with a system model that encodes how the hand moves. Experimental results show that the reconstructed trajectories are superior to those obtained by linear filtering. Additionally, the Kalman filter provides insight into the neural encoding of hand motion. For example, analysis of the measurement model suggests that, while the neural firing is closely related to the position and velocity of the hand, the acceleration is redundant. Furthermore, the Kalman filter framework is exploited to recover the optimal lag time between hand movement and neural firing.",Wei Wu and MJ Black and Yun Gao and Elie Bienenstock and Mijail Serruya and JP Donoghue,97,16125846136341773612,SAB’02-workshop on motor control in humans and robots: On the interplay of real brains and artificial devices,,66-73,,Inferring hand motion from multi-cell recordings in motor cortex using a Kalman filter,http://www.dam.brown.edu/people/elie/papers/Wu%20et%20al%20SAB%202002.pdf,,2002,/scholar?cites=16125846136341773612,6NjbexEAAAAJ:NMxIlDl6LWMC

1010109,"This chapter focuses on the development of neuromotor prostheses (NMP) for humans. NMPs are devices for the central nervous system (CNS) that can couple motor areas to effectors and ultimately return feedback as a closed loop system. NMPs are now being developed to provide a replacement output for lost functions, such as hand or leg movement or speech. In essence, they represent a physical repair where biological ones are inadequate or unavailable. NMPs have the potential to restore movement when central motor control structures remain intact, but their access to the periphery is blocked. Any traumatic injury or disease that disrupts the corticospinal pathway, their connections or their axons, or the muscles themselves can disrupt voluntary movement. The recent accomplishments in recording and decoding and the base of animal data from multiple laboratories suggest that NMPs …",John P Donoghue and Arto Nurmikko and Gerhard Friehs and Michael Black,95,733753376995595241,,,592-606,Elsevier,Development of neuromotor prostheses for humans,https://www.sciencedirect.com/science/article/pii/S1567424X0970399X,57,2004,/scholar?cites=733753376995595241,6NjbexEAAAAJ:r0BpntZqJG4C

1010110,"Recently, we proposed a Kalman filter method to model the probabilistic relationship between neural firing in motor cortex and hand kinematics. In this paper, we demonstrate on-line, closed-loop, neural control of cursor motion using the Kalman filter. In this task a monkey moves a cursor on a computer monitor using either a manipulandum or their neural activity recorded with a chronically implanted micro-electrode array. A number of advantages of the Kalman filter were explored during the on-line tasks and we found that the Kalman filter had superior performance to previously reported linear regression methods. While the results suggest the applicability of the Kalman filter for neural prosthesis applications, we observed the decoded cursor position was noisier under brain control as compared with manual control using the manipulandum. To smooth the cursor motion without decreasing accuracy we propose a …",W Wu and A Shaikhouni and JR Donoghue and MJ Black,92,13922372688915762387,,,4126-4129,IEEE,Closed-loop neural control of cursor motion using a Kalman filter,https://ieeexplore.ieee.org/abstract/document/1404151/,2,2004,/scholar?cites=13922372688915762387,6NjbexEAAAAJ:JV2RwH3_ST0C

1010111,"This paper defines a temporal continuity constraint that expresses assumptions about the evolution of 2D image velocity, or optical flow, over a sequence of images. Temporal continuity is exploited to develop an incremental minimization framework that extends the minimization of a non-convex objective function over time. Within this framework this paper describes an incremental continuation method for recursive non-linear estimation that robustly and adaptively recovers optical flow with motion discontinuities over an image sequence.",Michael Black,91,10727617050858203905,,,138-145,Springer Berlin/Heidelberg,Recursive non-linear estimation of discontinuous flow fields,https://link.springer.com/chapter/10.1007/3-540-57956-7_15,,1994,/scholar?cites=10727617050858203905,6NjbexEAAAAJ:IWHjjKOFINEC

1010112,"Three-dimensional object shape is commonly represented in terms of deformations of a triangular mesh from an exemplar shape. Existing models, however, are based on a Euclidean representation of shape deformations. In contrast, we argue that shape has a manifold structure: For example, summing the shape deformations for two people does not necessarily yield a deformation corresponding to a valid human shape, nor does the Euclidean difference of these two deformations provide a meaningful measure of shape dissimilarity. Consequently, we define a novel manifold for shape representation, with emphasis on body shapes, using a new Lie group of deformations. This has several advantages. First we define triangle deformations exactly, removing non-physical deformations and redundant degrees of freedom common to previous methods. Second, the Riemannian structure of Lie Bodies enables …",Oren Freifeld and Michael J. Black,89,13344778328444548531,,,1-14,Springer-Verlag,Lie Bodies: A Manifold Representation of 3D Human Shape,https://link.springer.com/chapter/10.1007/978-3-642-33718-5_1,,2012,/scholar?cites=13344778328444548531,6NjbexEAAAAJ:S16KYo8Pm5AC

1010113,"A spatio-temporal representation for complex optical flow events is developed that generalizes traditional parameterized motion models (e.g. affine). These generative spatio-temporal models may be non-linear or stochastic and are event-specific in that they characterize a particular type of object motion (e.g. sitting or walking). Within a Bayesian framework we seek the appropriate model, phase, rate, spatial position, and scale to account for the image variation. The posterior distribution over this parameter space conditioned on image measurements is typically non-Gaussian. The distribution is represented using factored sampling and is predicted and updated over time using the condensation algorithm. The resulting framework automatically detects, localizes, and recognizes motion events.",Michael J Black,88,2794079517606031687,,,326-332,IEEE,Explaining optical flow events with parameterized spatio-temporal models,https://ieeexplore.ieee.org/abstract/document/786959/,1,1999,/scholar?cites=2794079517606031687,6NjbexEAAAAJ:_Qo2XoVZTnwC

1010114,"This paper describes a framework for constructing a linear subspace model of image appearance for complex articulated 3D figures such as humans and other animals. A commercial motion capture system provides 3D data that is aligned with images of subjects performing various activities. Portions of a limb's image appearance are seen from multiple views and for multiple subjects. From these partial views, weighted principal component analysis is used to construct a linear subspace representation of the ""unwrapped"" image appearance of each limb. The linear subspaces provide a generative model of the object appearance that is exploited in a Bayesian particle filtering tracking system. Results of tracking single limbs and walking humans are presented.",Hedvig Sidenbladh and Fernando De la Torre and Michael J Black,86,2877544122668198456,,,368-375,IEEE,A framework for modeling the appearance of 3D articulated figures,https://ieeexplore.ieee.org/abstract/document/840661/,,2000,/scholar?cites=2877544122668198456,6NjbexEAAAAJ:HDshCWvjkbEC

1010115,"Recently, the assumed goal of computer vision, reconstructing a representation of the scene, has been critcized as unproductive and impractical. Critics have suggested that the reconstructive approach should be supplanted by a new purposive approach that emphasizes functionality and task driven perception at the cost of general vision. In response to these arguments, we claim that the recovery paradigm central to the reconstructive approach is viable, and, moreover, provides a promising frameworkfor understanding and modeling general purpose vision in humans and machines. An examination of the goals ofvision from an evolutionary perspec-tive and a case study involving the recovery of optic flow support this hypothesis. In particular, while we acknowledge that there are instances where the purposive approach may be appropriate, these are insufficient for implementing the wide range of visual tasks …",Michael J Tarr and Michael J Black,84,9881285367620899843,CVGIP Image Understanding,1,65-73,Academic Press,A computational and evolutionary perspective on the role of representation in vision,http://cs.brown.edu/people/mjblack/Papers/cviu.60.1.1994a.pdf,60,1994,/scholar?cites=9881285367620899843,6NjbexEAAAAJ:eJXPG6dFmWUC

1010116,"Most of the top performing action recognition methods use optical flow as a “black box” input. Here we take a deeper look at the combination of flow and action recognition, and investigate why optical flow is helpful, what makes a flow method good for action recognition, and how we can make it better. In particular, we investigate the impact of different flow algorithms and input transformations to better understand how these affect a state-of-the-art action recognition method. Furthermore, we fine tune two neural-network flow methods end-to-end on the most widely used action recognition dataset (UCF101). Based on these experiments, we make the following five observations: (1) optical flow is useful for action recognition because it is invariant to appearance, (2) optical flow methods are optimized to minimize end-point-error (EPE), but the EPE of current methods is not well correlated with action recognition …",Laura Sevilla-Lara and Yiyi Liao and Fatma Güney and Varun Jampani and Andreas Geiger and Michael J Black,82,4235031893857448008,,,281-297,"Springer, Cham",On the integration of optical flow and action recognition,https://link.springer.com/chapter/10.1007/978-3-030-12939-2_20,,2018,/scholar?cites=4235031893857448008,6NjbexEAAAAJ:Q7hiZQKJ-pAC

1010117,We present a robust automatic method for modeling cyclic 3D human motion such as walking using motion-capture data. The pose of the body is represented by a time-series of joint angles which are automatically segmented into a sequence of motion cycles. The mean and the principal components of these cycles are computed using a new algorithm that enforces smooth transitions between the cycles by operating in the Fourier domain. Key to this method is its ability to automatically deal with noise and missing data. A learned walking model is then exploited for Bayesian tracking of 3D human motion.,Dirk Ormoneit and Michael J Black and Trevor Hastie and Hedvig Kjellström,81,4889798515608408945,Image and Vision Computing,14,1264-1276,Elsevier,Representing cyclic human motion using functional analysis,https://www.sciencedirect.com/science/article/pii/S0262885605001526,23,2005,/scholar?cites=4889798515608408945,6NjbexEAAAAJ:RYcK_YlVTxYC

1010118,"This paper overviews the PLAYBOT project, a long-term, large-scale research program whose goal is to provide a directable robot which may enable physically disabled children to access and manipulate toys. This domain is the first test domain, but there is nothing inherent in the design of PLAYBOT that prohibits its extension to other tasks. The research is guided by several important goals: vision is the primary sensor; vision is task directed; the robot must be able to visually search its environment; object and event recognition are basic capabilities; environments must be natural and dynamic; users and environments are assumed to be unpredictable; task direction and reactivity must be smoothly integrated; and safety is of high importance. The emphasis of the research has been on vision for the robot this is the most challenging research aspect and the major bottleneck to the development of intelligent robots …",John K Tsotsos and Gilbert Verghese and S Dickinson and M Jenkin and A Jepson and E Milios and Fernando Nuflo and Suzanne Stevenson and M Black and Dimitri Metaxas and S Culhane and Y Ye and R Mann,79,2447794975468031717,Image and Vision Computing,4,275-292,Elsevier,Playbot a visually-guided robot for physically disabled children,https://www.sciencedirect.com/science/article/pii/S0262885697000887,16,1998,/scholar?cites=2447794975468031717,6NjbexEAAAAJ:M3NEmzRMIkIC

1010119,"Body image disturbance (BID) is a core symptom of anorexia nervosa (AN), but as yet distinctive features of BID are unknown. The present study aimed at disentangling perceptual and attitudinal components of BID in AN.We investigated n = 24 women with AN and n = 24 controls. Based on a three-dimensional (3D) body scan, we created realistic virtual 3D bodies (avatars) for each participant that were varied through a range of ±20% of the participants’ weights. Avatars were presented in a virtual reality mirror scenario. Using different psychophysical tasks, participants identified and adjusted their actual and their desired body weight. To test for general perceptual biases in estimating body weight, a second experiment investigated perception of weight and shape matched avatars with another identity …",SC Mölbert and A Thaler and BJ Mohler and S Streuber and J Romero and MJ Black and S Zipfel and H-O Karnath and KE Giel,78,10215311395707505487,Psychological medicine,4,642-653,Cambridge University Press,Assessing body image in anorexia nervosa using biometric self-avatars in virtual reality: Attitudinal components rather than visual body size estimation are distorted,https://www.cambridge.org/core/journals/psychological-medicine/article/assessing-body-image-in-anorexia-nervosa-using-biometric-selfavatars-in-virtual-reality-attitudinal-components-rather-than-visual-body-size-estimation-are-distorted/A111D545D17E2F260D62434C254F3951,48,2018,/scholar?cites=10215311395707505487,6NjbexEAAAAJ:CqsiOOvXZmUC

1010120,"Existing markerless motion capture methods often assume known backgrounds, static cameras, and sequence specific motion priors, limiting their application scenarios. Here we present a fully automatic method that, given multi-view videos, estimates 3D human pose and body shape. We take the recently proposed SMPLify method \cite{bogo2016keep} as the base method and extend it in several ways. First we fit a 3D human body model to 2D features detected in multi-view images. Second, we use a CNN method to segment the person in each image and fit the 3D body model to the contours, further improving accuracy. Third we utilize a generic and robust DCT temporal prior to handle the left and right side swapping issue sometimes introduced by the 2D pose estimator. Validation on standard benchmarks shows our results are comparable to the state of the art and also provide a realistic 3D shape avatar. We …",Yinghao Huang and Federica Bogo and Christoph Lassner and Angjoo Kanazawa and Peter V. Gehler and Ijaz Akhter and Michael J. Black,78,9136266831623540571,,,421-430,IEEE,Towards accurate marker-less human shape and pose estimation over time,https://ieeexplore.ieee.org/abstract/document/8374596/,,2017,/scholar?cites=9136266831623540571,6NjbexEAAAAJ:B4wWq2ztVNgC

1010121,"Layered models allow scene segmentation and motion estimation to be formulated together and to inform one another. Traditional layered motion methods, however, employ fairly weak models of scene structure, relying on locally connected Ising/Potts models which have limited ability to capture long-range correlations in natural scenes. To address this, we formulate a fully-connected layered model that enables global reasoning about the complicated segmentations of real objects. Optimization with fully-connected graphical models is challenging, and our inference algorithm leverages recent work on efficient mean field updates for fully-connected conditional random fields. These methods can be implemented efficiently using high-dimensional Gaussian filtering. We combine these ideas with a layered flow model, and find that the long-range connections greatly improve segmentation into figure-ground layers when compared with locally connected MRF models. Experiments on several benchmark datasets show that the method can recover fine structures and large occlusion regions, with good flow accuracy and much lower computational cost than previous locally-connected layered models.",Deqing Sun and Jonas Wulff and Erik B Sudderth and Hanspeter Pfister and Michael J Black,78,11408668883679811563,,,2451-2458,,A fully-connected layered model of foreground and background flow,http://openaccess.thecvf.com/content_cvpr_2013/html/Sun_A_Fully-Connected_Layered_2013_CVPR_paper.html,,2013,/scholar?cites=11408668883679811563,6NjbexEAAAAJ:M7yex6snE4oC

1010122,"This paper unifies ""line-process"" approaches for regularization with discontinuities and robust estimation techniques. We generalize the notion of a ""line process"" to that of an analog ""outlier process"" and show that a problem formulated in terms of outlier processes can be viewed in terms of robust statistics. We also characterize a class of robust statistical problems for which an equivalent outlier-process formulation exists and give a straightforward method for converting a robust estimation problem into an outlier-process formulation. This outlier-processes approach provides a general framework which subsumes the traditional line-process approaches as well as a wide class of robust estimation problems. Examples in image reconstruction and optical flow are used to illustrate the approach.< >",Michael J Black and Anand Rangarajan,76,9541487740551978415,CVPR,,1-8,,The outlier process: Unifying line processes and robust statistics,https://ieeexplore.ieee.org/abstract/document/323805/,94,1994,/scholar?cites=9541487740551978415,6NjbexEAAAAJ:j3f4tGmQtD8C

1010123,"In contrast to traditional Markov random field (MRF) models, we develop a steerable random field (SRF) in which the field potentials are defined in terms of filter responses that are steered to the local image structure. In particular, we use the structure tensor to obtain derivative responses that are either aligned with, or orthogonal to, the predominant local image structure, and analyze the statistics of these steered filter responses in natural images. Clique potentials are defined over steered filter responses using a Gaussian scale mixture model and are learned from training data. The SRF model connects random field models with anisotropic regularization and provides a statistical motivation for the latter. We demonstrate that steering the random field to the local image structure improves image denoising and inpainting performance compared with traditional pairwise MRFs.",Stefan Roth and Michael J Black,75,14383855938325813164,,,1-8,IEEE,Steerable random fields,https://ieeexplore.ieee.org/abstract/document/4408981/,,2007,/scholar?cites=14383855938325813164,6NjbexEAAAAJ:g5m5HwL7SMYC

1010124,"There has been significant work on learning realistic, articulated, 3D models of the human body. In contrast, there are few such models of animals, despite many applications. The main challenge is that animals are much less cooperative than humans. The best human body models are learned from thousands of 3D scans of people in specific poses, which is infeasible with live animals. Consequently, we learn our model from a small set of 3D scans of toy figurines in arbitrary poses. We employ a novel part-based shape model to compute an initial registration to the scans. We then normalize their pose, learn a statistical shape model, and refine the registrations and the model together. In this way, we accurately align animal scans from different quadruped families with very different shapes and poses. With the registration to a common template we learn a shape space representing animals including lions, cats, dogs, horses, cows and hippos. Animal shapes can be sampled from the model, posed, animated, and fit to data. We demonstrate generalization by fitting it to images of real animals including species not seen in training.",Silvia Zuffi and Angjoo Kanazawa and David W Jacobs and Michael J Black,73,11055077264697512314,,,6365-6373,,3D menagerie: Modeling the 3D shape and pose of animals,http://openaccess.thecvf.com/content_cvpr_2017/html/Zuffi_3D_Menagerie_Modeling_CVPR_2017_paper.html,,2017,/scholar?cites=11055077264697512314,6NjbexEAAAAJ:rv4tAfkFLVgC

1010125,"The optical flow of natural scenes is a combination of the motion of the observer and the independent motion of objects. Existing algorithms typically focus on either recovering motion and structure under the assumption of a purely static world or optical flow for general unconstrained scenes. We combine these approaches in an optical flow algorithm that estimates an explicit segmentation of moving objects from appearance and physical constraints. In static regions we take advantage of strong constraints to jointly estimate the camera motion and the 3D structure of the scene over multiple frames. This allows us to also regularize the structure instead of the motion. Our formulation uses a Plane+ Parallax framework, which works even under small baselines, and reduces the motion estimation to a one-dimensional search problem, resulting in more accurate estimation. In moving regions the flow is treated as unconstrained, and computed with an existing optical flow method. The resulting Mostly-Rigid Flow (MR-Flow) method achieves state-of-the-art results on both the MPI-Sintel and KITTI-2015 benchmarks.",Jonas Wulff and Laura Sevilla-Lara and Michael J Black,72,10436260802448551219,,,4671-4680,,Optical flow in mostly rigid scenes,http://openaccess.thecvf.com/content_cvpr_2017/html/Wulff_Optical_Flow_in_CVPR_2017_paper.html,,2017,/scholar?cites=10436260802448551219,6NjbexEAAAAJ:1In3SbHwanAC

1010126,"We describe a 2.5D layered representation for visual motion analysis. The representation provides a global interpretation of image motion in terms of several spatially localized foreground regions along with a background region. Each of these regions comprises a parametric shape model and a parametric motion model. The representation also contains depth ordering so visibility and occlusion are rightly included in the estimation of the model parameters. Finally, because the number of objects, their positions, shapes and sizes, and their relative depths are all unknown, initial models are drawn from a proposal distribution, and then compared using a penalized likelihood criterion. This allows us to automatically initialize new models, and to compare different depth orderings.",Allan Jepson and David Fleet and Michael Black,72,4462943333466758269,,,692-706,Springer Berlin/Heidelberg,A layered motion representation with occlusion and compact spatial support,https://link.springer.com/chapter/10.1007/3-540-47969-4_46,,2002,/scholar?cites=4462943333466758269,6NjbexEAAAAJ:hMod-77fHWUC

1010127,"Learning optical flow with neural networks is hampered by the need for obtaining training data with associated ground truth. Unsupervised learning is a promising direction, yet the performance of current unsupervised methods is still limited. In particular, the lack of proper occlusion handling in commonly used data terms constitutes a major source of error. While most optical flow methods process pairs of consecutive frames, more advanced occlusion reasoning can be realized when considering multiple frames. In this paper, we propose a framework for unsupervised learning of optical flow and occlusions over multiple frames. More specifically, we exploit the minimal configuration of three frames to strengthen the photometric loss and explicitly reason about occlusions. We demonstrate that our multi-frame, occlusion-sensitive formulation outperforms existing unsupervised two-frame methods and even produces results on par with some fully supervised methods.",Joel Janai and Fatma Guney and Anurag Ranjan and Michael Black and Andreas Geiger,70,13556771837119193254,,,690-706,,Unsupervised learning of multi-frame optical flow with occlusions,http://openaccess.thecvf.com/content_ECCV_2018/html/Joel_Janai_Unsupervised_Learning_of_ECCV_2018_paper.html,,2018,/scholar?cites=13556771837119193254,6NjbexEAAAAJ:jG_sDXCMgAMC

1010128,"Strong lighting is common in natural scenes yet is often viewed as a nuisance for object pose estimation and tracking. In human shape and pose estimation, cast shadows can be confused with foreground structure while self shadowing and shading variation on the body cause the appearance of the person to change with pose. Rather than attempt to minimize the effects of lighting and shadows, we show that strong lighting in a scene actually makes pose and shape estimation more robust. Additionally, by recovering multiple body poses we are able to automatically estimate the lighting in the scene and the albedo of the body. Our approach makes use of a detailed 3D body model, the parameters of which are directly recovered from image data. We provide a thorough exploration of human pose estimation under strong lighting conditions and show: 1. the estimation of the light source from cast shadows; 2. the …",Alexandru O Balan and Michael J Black and Horst Haussecker and Leonid Sigal,70,13023407183706695127,,,1-8,IEEE,"Shining a light on human pose: On shadows, shading and the estimation of pose and shape",https://ieeexplore.ieee.org/abstract/document/4409005/,,2007,/scholar?cites=13023407183706695127,6NjbexEAAAAJ:lSLTfruPkqcC

1010129,"In this work, we address the detection of vehicles in a video stream obtained from a moving airborne platform. We propose a Bayesian framework for estimating dense optical flow over time that explicitly estimates a persistent model of background appearance. The approach assumes that the scene can be described by background and occlusion layers, estimated within an expectation-maximization framework. The mathematical formulation of the paper is an extension of the work in (H. Yalcin et al., 2005) where motion and appearance models for foreground and background layers are estimated simultaneously in a Bayesian framework.",Hulya Yalcin and Martial Hebert and Robert Collins and Michael J Black,70,7617652850826784729,,,1202 vol. 2,IEEE,A flow-based approach to vehicle detection and background mosaicking in airborne video,https://ieeexplore.ieee.org/abstract/document/1467601/,2,2005,/scholar?cites=7617652850826784729,6NjbexEAAAAJ:4OULZ7Gr8RgC

1010130,"Large datasets are the cornerstone of recent advances in computer vision using deep learning. In contrast, existing human motion capture (mocap) datasets are small and the motions limited, hampering progress on learning models of human motion. While there are many different datasets available, they each use a different parameterization of the body, making it difficult to integrate them into a single meta dataset. To address this, we introduce AMASS, a large and varied database of human motion that unifies 15 different optical marker-based mocap datasets by representing them within a common framework and parameterization. We achieve this using a new method, MoSh++, that converts mocap data into realistic 3D human meshes represented by a rigged body model. Here we use SMPL [Loper et al., 2015], which is widely used and provides a standard skeletal representation as well as a fully rigged surface mesh. The method works for arbitrary marker sets, while recovering soft-tissue dynamics and realistic hand motion. We evaluate MoSh++ and tune its hyperparameters using a new dataset of 4D body scans that are jointly recorded with markerbased mocap. The consistent representation of AMASS makes it readily useful for animation, visualization, and generating training data for deep learning. Our dataset is significantly richer than previous human motion collections, having more than 40 hours of motion data, spanning over 300 subjects, more than 11000 motions, and will be publicly available to the research community.",Naureen Mahmood and Nima Ghorbani and Nikolaus F Troje and Gerard Pons-Moll and Michael J Black,68,8155628217260683640,,,5442-5451,,AMASS: Archive of motion capture as surface shapes,http://openaccess.thecvf.com/content_ICCV_2019/html/Mahmood_AMASS_Archive_of_Motion_Capture_As_Surface_Shapes_ICCV_2019_paper.html,,2019,/scholar?cites=8155628217260683640,6NjbexEAAAAJ:iRaVAuoZnuIC

1010131,"We present an automatic system for analyzing and annotating video sequences of technical talks. Our method uses a robust motion estimation technique to detect key frames and segment the video sequence into subsequences containing a single overhead slide. The subsequences are stabilized to remove motion that occurs when the speaker adjusts their slides. Any changes remaining between frames in the stabilized sequences may be due to speaker gestures such as pointing or writing and we use active contours to automatically track these potential gestures. Given the constrained domain we define a simple ""vocabulary"" of actions which can easily be recognized based on the active contour shape and motion. The recognized actions provide a rich annotation of the sequence that can be used to access a condensed version of the talk from a web page.",Shanon X Ju and Michael J Black and Scott Minneman and Don Kimber,68,7215879634111657745,,,595-601,IEEE,Analysis of gesture and action in technical talks for video indexing,https://ieeexplore.ieee.org/abstract/document/609386/,,1997,/scholar?cites=7215879634111657745,6NjbexEAAAAJ:YFjsv_pBGBYC

1010132,We propose a model for the incremental estimation of visual motion fields from image sequences. Our model exploits three standard constraints on image motion within an optimization framework: i) Data Conservation: the intensity structure of a surface patch changes gradually over time; ii),Michael J Black and P Anandan,68,16755895047676977159,,,33-37,,A model for the detection of motion over time.,http://cs.brown.edu/research/pubs/pdfs/1990/Black-1990-MDM.pdf,,1990,/scholar?cites=16755895047676977159,6NjbexEAAAAJ:blknAaTinKkC

1010133,"Estimating hand-object manipulations is essential for in-terpreting and imitating human actions. Previous work has made significant progress towards reconstruction of hand poses and object shapes in isolation. Yet, reconstructing hands and objects during manipulation is a more challeng-ing task due to significant occlusions of both the hand and object. While presenting challenges, manipulations may also simplify the problem since the physics of contact re-stricts the space of valid hand-object configurations. For example, during manipulation, the hand and object should be in contact but not interpenetrate. In this work, we regu-larize the joint reconstruction of hands and objects with ma-nipulation constraints. We present an end-to-end learnable model that exploits a novel contact loss that favors phys-ically plausible hand-object constellations. Our approach improves grasp quality metrics over baselines, using RGB images as input. To train and evaluate the model, we also propose a new large-scale synthetic dataset, ObMan, with hand-object manipulations. We demonstrate the transfer-ability of ObMan-trained models to real data.",Yana Hasson and Gul Varol and Dimitrios Tzionas and Igor Kalevatykh and Michael J Black and Ivan Laptev and Cordelia Schmid,66,11047420660130299556,,,11807-11816,,Learning joint reconstruction of hands and manipulated objects,http://openaccess.thecvf.com/content_CVPR_2019/html/Hasson_Learning_Joint_Reconstruction_of_Hands_and_Manipulated_Objects_CVPR_2019_paper.html,,2019,/scholar?cites=11047420660130299556,6NjbexEAAAAJ:nZtlP1Cc3DIC

1010134,"Existing methods for recognition of object instances and categories based on quantized local features can perform poorly when local features exist on transparent surfaces, such as glass or plastic objects. There are characteristic patterns to the local appearance of transparent objects, but they may not be well captured by distances to individual examples or by a local pattern codebook obtained by vector quantization. The appearance of a transparent patch is determined in part by the refraction of a background pattern through a transparent medium: the energy from the background usually dominates the patch appearance. We model transparent local patch appearance using an additive model of latent factors: background factors due to scene content, and factors which capture a local edge energy distribution characteristic of the refraction. We implement our method using a novel LDA-SIFT formulation which performs LDA prior to any vector quantization step; we discover latent topics which are characteristic of particular transparent patches and quantize the SIFT space into transparent visual words according to the latent topic dimensions. No knowledge of the background scene is required at test time; we show examples recognizing transparent glasses in a domestic environment.",Mario Fritz and Gary Bradski and Sergey Karayev and Trevor Darrell and Michael Black,65,11268443319058601489,Advances in Neural Information Processing Systems,,558-566,,An additive latent feature model for transparent object recognition,http://papers.nips.cc/paper/3808-an-additive-latent-feature-model-for-transparent-object-recognition,22,2009,/scholar?cites=11268443319058601489,6NjbexEAAAAJ:nb7KW1ujOQ8C

1010135,"Many models have been proposed for the motor cortical encoding of arm motion. In particular, recent work has shown that simple linear models can be used to approximate the firing rates of a population of cells in primary motor cortex as a function of the position, velocity, and acceleration of the hand. Here we perform a systematic study of these linear models and of various non-linear generalizations. Specifically we consider linear Gaussian models, Generalized Linear Models (GLM), and Generalized Additive Models (GAM) of neural encoding. We evaluate their ability to represent the relationship between hand motion and neural activity, by looking at the likelihood of observed patterns of neural firing in a test data set and by evaluating the decoding performance of the different models (i.e. in terms of the error in reconstructing hand position from firing rates). To provide a level playing field for evaluating the …",Yun Gao and Michael J Black and Elie Bienenstock and Wei Wu and John P Donoghue,65,7834061104157972222,,,189-192,IEEE,A quantitative comparison of linear and non-linear models of motor cortical activity for the encoding and decoding of arm motions,https://ieeexplore.ieee.org/abstract/document/1196789/,,2003,/scholar?cites=7834061104157972222,6NjbexEAAAAJ:ns9cj8rnVeAC

1010136,"We propose a Bayesian framework for representing and recognizing local image motion in terms of two primitive models: translation and motion discontinuity. Motion discontinuities are represented using a nonlinear generative model that explicitly encodes the orientation of the boundary, the velocities on either side, the motion of the occluding edge over time, and the appearance/disappearance of pixels at the boundary. We represent the posterior distribution over the model parameters given the image data using discrete samples. This distribution is propagated over time using the Condensation algorithm. To efficiently represent such a high-dimensional space we initialize samples using the responses of a low-level motion discontinuity detector.",Michael J Black and David J Fleet,65,5650705633313765778,,,551-558,IEEE,Probabilistic detection and tracking of motion discontinuities,https://ieeexplore.ieee.org/abstract/document/791271/,1,1999,/scholar?cites=5650705633313765778,6NjbexEAAAAJ:TFP_iSt0sucC

1010137,"Many sensing techniques and image processing applications are characterized by noisy, or corrupted, image data. Anisotropic diffusion is a popular, and theoretically well understood, technique for denoising such images. Diffusion approaches however require the selection of an ""edge stopping"" function, the definition of which is typically ad hoc. We exploit and extend recent work on the statistics of natural images to define principled edge stopping functions for different types of imagery. We consider a variety of anisotropic diffusion schemes and note that they compute spatial derivatives at fixed scales from which we estimate the appropriate algorithm-specific image statistics. Going beyond traditional work on image statistics, we also model the statistics of the eigenvalues of the local structure tensor. Novel edge-stopping functions are derived from these image statistics giving a principled way of formulating …",Hanno Scharr and Michael J Black and Horst W Haussecker,64,14145930856787367159,,,840,IEEE,Image statistics and anisotropic diffusion,https://ieeexplore.ieee.org/abstract/document/1238435/,,2003,/scholar?cites=14145930856787367159,6NjbexEAAAAJ:35N4QoGY0k4C

1010138,Pictorial Structures (PS) define a probabilistic model of 2D articulated objects in images. Typical PS models assume an object can be represented by a set of rigid parts connected with pairwise constraints that define the prior probability of part configurations. These models are widely used to represent non-rigid articulated objects such as humans and animals despite the fact that such objects have parts that deform non-rigidly. Here we define a new Deformable Structures (DS) model that is a natural extension of previous PS models and that captures the non-rigid shape deformation of the parts. Each part in a DS model is represented by a low-dimensional shape deformation space and pairwise potentials between parts capture how the shape varies with pose and the shape of neighboring parts. A key advantage of such a model is that it more accurately models object boundaries. This enables image likelihood …,Silvia Zuffi and Oren Freifeld and Michael J Black,62,4692016675591924709,,,3546-3553,IEEE,From pictorial structures to deformable structures,https://ieeexplore.ieee.org/abstract/document/6248098/,,2012,/scholar?cites=4692016675591924709,6NjbexEAAAAJ:ZfRJV9d4-WMC

1010139,"We address the problem of upper-body human pose estimation in uncontrolled monocular video sequences, without manual initialization. Most current methods focus on isolated video frames and often fail to correctly localize arms and hands. Inferring pose over a video sequence is advantageous because poses of people in adjacent frames exhibit properties of smooth variation due to the nature of human and camera motion. To exploit this, previous methods have used prior knowledge about distinctive actions or generic temporal priors combined with static image likelihoods to track people in motion. Here we take a different approach based on a simple observation: Information about how a person moves from frame to frame is present in the optical flow field. We develop an approach for tracking articulated motions that"" links"" articulated shape models of people in adjacent frames through the dense optical flow. Key to this approach is a 2D shape model of the body that we use to compute how the body moves over time. The resulting"" flowing puppets"" provide a way of integrating image evidence across frames to improve pose inference. We apply our method on a challenging dataset of TV video sequences and show state-of-the-art performance.",Silvia Zuffi and Javier Romero and Cordelia Schmid and Michael J Black,61,9135069567909583028,,,3312-3319,,Estimating human pose with flowing puppets,http://openaccess.thecvf.com/content_iccv_2013/html/Zuffi_Estimating_Human_Pose_2013_ICCV_paper.html,,2013,/scholar?cites=9135069567909583028,6NjbexEAAAAJ:86PQX7AUzd4C

1010140,"Multi-metric learning techniques learn local metric tensors in different parts of a feature space. With such an approach, even simple classifiers can be competitive with the state-of-the-art because the distance measure locally adapts to the structure of the data. The learned distance measure is, however, non-metric, which has prevented multi-metric learning from generalizing to tasks such as dimensionality reduction and regression in a principled way. We prove that, with appropriate changes, multi-metric learning corresponds to learning the structure of a Riemannian manifold. We then show that this structure gives us a principled way to perform dimensionality reduction and regression according to the learned metrics. Algorithmically, we provide the first practical algorithm for computing geodesics according to the learned metrics, as well as algorithms for computing exponential and logarithmic maps on the Riemannian manifold. Together, these tools let many Euclidean algorithms take advantage of multi-metric learning. We illustrate the approach on regression and dimensionality reduction tasks that involve predicting measurements of the human body from shape data.",Søren Hauberg and Oren Freifeld and Michael Black,61,8378354246660382202,Advances in Neural Information Processing Systems,,2024-2032,,A geometric take on metric learning,http://papers.nips.cc/paper/4539-a-geometric-take-on-metric-learning,25,2012,/scholar?cites=8378354246660382202,6NjbexEAAAAJ:KUbvn5osdkgC

1010141,"Detection, tracking, segmentation and pose estimation of people in monocular images are widely studied. Two-dimensional models of the human body are extensively used, however, they are typically fairly crude, representing the body either as a rough outline or in terms of articulated geometric primitives. We describe a new 2D model of the human body contour that combines an underlying naked body with a low-dimensional clothing model. The naked body is represented as a Contour Person that can take on a wide variety of poses and body shapes. Clothing is represented as a deformation from the underlying body contour. This deformation is learned from training examples using principal component analysis to produce eigen clothing. We find that the statistics of clothing deformations are skewed and we model the a priori probability of these deformations using a Beta distribution. The resulting …",Peng Guan and Oren Freifeld and Michael J Black,61,4107665469897534465,,,285-298,"Springer, Berlin, Heidelberg",A 2D human body model dressed in eigen clothing,https://link.springer.com/chapter/10.1007/978-3-642-15549-9_21,,2010,/scholar?cites=4107665469897534465,6NjbexEAAAAJ:B3FOqHPlNUQC

1010142,"Data driven models of human poses and soft-tissue deformations can produce very realistic results, but they only model the visible surface of the human body and cannot create skin deformation due to interactions with the environment. Physical simulations can generalize to external forces, but their parameters are difficult to control. In this paper, we present a layered volumetric human body model learned from data. Our model is composed of a data-driven inner layer and a physics-based external layer. The inner layer is driven with a volumetric statistical body model (VSMPL). The soft tissue layer consists of a tetrahedral mesh that is driven using the finite element method (FEM). Model parameters, namely the segmentation of the body into layers and the soft tissue elasticity, are learned directly from 4D registrations of humans exhibiting soft tissue deformations. The learned two layer model is a realistic full-body …",Meekyoung Kim and Gerard Pons-Moll and Sergi Pujades and Seungbae Bang and Jinwook Kim and Michael J Black and Sung-Hee Lee,59,17348033613774760759,ACM Transactions on Graphics (TOG),4,1-12,ACM,Data-driven physics for human soft tissue animation,https://dl.acm.org/doi/abs/10.1145/3072959.3073685,36,2017,/scholar?cites=17348033613774760759,6NjbexEAAAAJ:x9X1S-hd97YC

1010143,"We define a new “contour person” model of the human body that has the expressive power of a detailed 3D model and the computational benefits of a simple 2D part-based model. The contour person (CP) model is learned from a 3D SCAPE model of the human body that captures natural shape and pose variations; the projected contours of this model, along with their segmentation into parts forms the training set. The CP model factors deformations of the body into three components: shape variation, viewpoint change and part rotation. This latter model also incorporates a learned non-rigid deformation model. The result is a 2D articulated model that is compact to represent, simple to compute with and more expressive than previous models. We demonstrate the value of such a model in 2D pose estimation and segmentation. Given an initial pose from a standard pictorial-structures method, we refine the pose and …",Oren Freifeld and Alexander Weiss and Silvia Zuffi and Michael J Black,59,12521156880418000497,,,639-646,IEEE,Contour people: A parameterized model of 2D articulated human shape,https://ieeexplore.ieee.org/abstract/document/5540154/,,2010,/scholar?cites=12521156880418000497,6NjbexEAAAAJ:738O_yMBCRsC

1010144,"Principal component analysis (PCA) has been successfully applied to construct linear models of shape, graylevel, and motion in images. In particular, PCA has been widely used to model the variation in the appearance of people’s faces. We extend previous work on facial modeling for tracking faces in video sequences as they undergo significant changes due to facial expressions. Here we consider person-specific facial appearance models (PSFAM), which use modular PCA to model complex intra-person appearance changes. Such models require aligned visual training data; in previous work, this has involved a time consuming and error-prone hand alignment and cropping process. Instead, the main contribution of this paper is to introduce parameterized component analysis to learn a subspace that is invariant to affine (or higher order) geometric transformations. The automatic learning of a PSFAM given a …",Fernando De la Torre and Michael J Black,59,13752048159495337151,Computer Vision and Image Understanding,1-2,53-71,Academic Press,Robust parameterized component analysis: theory and applications to 2d facial appearance models,https://www.sciencedirect.com/science/article/pii/S1077314203000766,91,2003,/scholar?cites=13752048159495337151,6NjbexEAAAAJ:O3NaXMp0MMsC

1010145,"Estimation of articulated human pose from images or video has been a long standing goal of computer vision. Applications for such technology are prevalent across scientific and consumer domains. Despite over a decade of active research, and hundreds of papers, robust solutions to this problem are still unattainable in general unconstrained scenarios. We believe, that progress requires an understanding of the current state of the art and where current methods fail. This necessitates a comprehensive evaluation of current approaches on the same data and with the same metrics. This special pair of issues contain 9 papers that span, and are representative of, recent developments in the field. Among these papers are those that explore algorithmic choices within more traditional methods (eg, Bayesian Filtering), as well as those that explore new technologies and representations. The topics span kinematic and …",Leonid Sigal and Michael J Black,58,11271107368223972725,International Journal of Computer Vision,1-2,1,Springer US,Guest editorial: state of the art in image-and video-based human pose and motion estimation,https://link.springer.com/content/pdf/10.1007/s11263-009-0293-2.pdf,87,2010,/scholar?cites=11271107368223972725,6NjbexEAAAAJ:a0OBvERweLwC

1010146,"While various automated spike sorting techniques have been developed, their impact on neural decoding has not been investigated. In this paper we extend previous Gaussian mixture models and expectation maximization (EM) techniques for automatic spike sorting. We suggest that good initialization of EM is critical and can be achieved via spectral clustering. To account for noise we extend the mixture model to include a uniform outlier process. Automatically determining the number of neurons recorded per electrode is a challenging problem which we solve using a greedy optimization algorithm that selects models with different numbers of neurons according to their decoding accuracy. We focus on data recorded from motor cortex and evaluate performance with respect to the decoding of hand kinematics from firing rates. We found that spike trains obtained by our automated technique result in more accurate …",E Wood and M Fellows and JR Donoghue and MJ Black,58,2974556974763808676,,,4009-4012,IEEE,Automatic spike sorting for neural decoding,https://ieeexplore.ieee.org/abstract/document/1404120/,2,2004,/scholar?cites=2974556974763808676,6NjbexEAAAAJ:fPk4N6BV_jEC

1010147,"Videos contain complex spatially-varying motion blur due to the combination of object motion, camera motion, and depth variation with finite shutter speeds. Existing methods to estimate optical flow, deblur the images, and segment the scene fail in such cases. In particular, boundaries between differently moving objects cause problems, because here the blurred images are a combination of the blurred appearances of multiple surfaces. We address this with a novel layered model of scenes in motion. From a motion-blurred video sequence, we jointly estimate the layer segmentation and each layer’s appearance and motion. Since the blur is a function of the layer motion and segmentation, it is completely determined by our generative model. Given a video, we formulate the optimization problem as minimizing the pixel error between the blurred frames and images synthesized from the model, and solve it …",Jonas Wulff and Michael Julian Black,56,6866699904548837394,,,236-252,"Springer, Cham",Modeling blurred video with layers,https://link.springer.com/chapter/10.1007/978-3-319-10599-4_16,,2014,/scholar?cites=6866699904548837394,6NjbexEAAAAJ:JQG40wivBEIC

1010148,"Thalamic neurons respond to visual scenes by generating synchronous spike trains on the timescale of 10–20 ms that are very effective at driving cortical targets. Here we demonstrate that this synchronous activity contains unexpectedly rich information about fundamental properties of visual stimuli. We report that the occurrence of synchronous firing of cat thalamic cells with highly overlapping receptive fields is strongly sensitive to the orientation and the direction of motion of the visual stimulus. We show that this stimulus selectivity is robust, remaining relatively unchanged under different contrasts and temporal frequencies (stimulus velocities). A computational analysis based on an integrate-and-fire model of the direct thalamic input to a layer 4 cortical cell reveals a strong correlation between the degree of thalamic synchrony and the nonlinear relationship between cortical membrane potential and the resultant …",Garrett B Stanley and Jianzhong Jin and Yushi Wang and Gaëlle Desbordes and Qi Wang and Michael J Black and Jose-Manuel Alonso,55,14390386122614862870,Journal of Neuroscience,26,9073-9088,Society for Neuroscience,Visual orientation and directional selectivity through thalamic synchrony,https://www.jneurosci.org/content/32/26/9073.short,32,2012,/scholar?cites=14390386122614862870,6NjbexEAAAAJ:tzM49s52ZIMC

1010149,"Variational Autoencoders (VAEs) provide a theoretically-backed and popular framework for deep generative models. However, learning a VAE from data poses still unanswered theoretical questions and considerable practical challenges. In this work, we propose an alternative framework for generative modeling that is simpler, easier to train, and deterministic, yet has many of the advantages of the VAE. We observe that sampling a stochastic encoder in a Gaussian VAE can be interpreted as simply injecting noise into the input of a deterministic decoder. We investigate how substituting this kind of stochasticity, with other explicit and implicit regularization schemes, can lead to an equally smooth and meaningful latent space without having to force it to conform to an arbitrarily chosen prior. To retrieve a generative mechanism to sample new data points, we introduce an ex-post density estimation step that can be readily applied to the proposed framework as well as existing VAEs, improving their sample quality. We show, in a rigorous empirical study, that the proposed regularized deterministic autoencoders are able to generate samples that are comparable to, or better than, those of VAEs and more powerful alternatives when applied to images as well as to structured data such as molecules.",Partha Ghosh and Mehdi SM Sajjadi and Antonio Vergari and Michael Black and Bernhard Schölkopf,54,10583740506297544895,arXiv preprint arXiv:1903.12436,,,,From variational to deterministic autoencoders,https://arxiv.org/abs/1903.12436,,2019,/scholar?cites=10583740506297544895,6NjbexEAAAAJ:W6h41lW4BooC

1010150,"With the MPI-Sintel Flow dataset, we introduce a naturalistic dataset for optical flow evaluation derived from the open source CGI movie Sintel. In contrast to the well-known Middlebury dataset, the MPI-Sintel Flow dataset contains longer and more varied sequences with image degradations such as motion blur, defocus blur, and atmospheric effects. Animators use a variety of techniques that produce pleasing images but make the raw animation data inappropriate for computer vision applications if used “out of the box”. Several changes to the rendering software and animation files were necessary in order to produce data for flow evaluation and similar changes are likely for future efforts to construct a scientific dataset from an animated film. Here we distill our experience with Sintel into a set of best practices for using computer animation to generate scientific data for vision research.",Jonas Wulff and Daniel J Butler and Garrett B Stanley and Michael J Black,53,17250056090732159822,,,168-177,"Springer, Berlin, Heidelberg",Lessons and insights from creating a synthetic optical flow benchmark,https://link.springer.com/chapter/10.1007/978-3-642-33868-7_17,,2012,/scholar?cites=17250056090732159822,6NjbexEAAAAJ:XD-gHx7UXLsC

1010151,"This paper presents a novel probabilistic foundation for volumetric 3D reconstruction. We formulate the problem as inference in a Markov random field, which accurately captures the dependencies between the occupancy and appearance of each voxel, given all input images. Our main contribution is an approximate highly parallelized discrete-continuous inference algorithm to compute the marginal distributions of each voxel's occupancy and appearance. In contrast to the MAP solution, marginals encode the underlying uncertainty and ambiguity in the reconstruction. Moreover, the proposed algorithm allows for a Bayes optimal prediction with respect to a natural reconstruction loss. We compare our method to two state-of-the-art volumetric reconstruction algorithms on three challenging aerial datasets with LIDAR ground truth. Our experiments demonstrate that the proposed algorithm compares favorably in terms of …",Ali Osman Ulusoy and Andreas Geiger and Michael J Black,52,9638130118079380015,,,10-18,IEEE,Towards probabilistic volumetric reconstruction using ray potentials,https://ieeexplore.ieee.org/abstract/document/7335464/,,2015,/scholar?cites=9638130118079380015,6NjbexEAAAAJ:NAGhd4NKCV8C

1010152,"As the collection of large datasets becomes increasingly automated, the occurrence of outliers will increase--"" big data"" implies"" big outliers''. While principal component analysis (PCA) is often used to reduce the size of data, and scalable solutions exist, it is well-known that outliers can arbitrarily corrupt the results. Unfortunately, state-of-the-art approaches for robust PCA do not scale beyond small-to-medium sized datasets. To address this, we introduce the Grassmann Average (GA), which expresses dimensionality reduction as an average of the subspaces spanned by the data. Because averages can be efficiently computed, we immediately gain scalability. GA is inherently more robust than PCA, but we show that they coincide for Gaussian data. We exploit that averages can be made robust to formulate the Robust Grassmann Average (RGA) as a form of robust PCA. Robustness can be with respect to vectors (subspaces) or elements of vectors; we focus on the latter and use a trimmed average. The resulting Trimmed Grassmann Average (TGA) is particularly appropriate for computer vision because it is robust to pixel outliers. The algorithm has low computational complexity and minimal memory requirements, making it scalable to"" big noisy data."" We demonstrate TGA for background modeling, video restoration, and shadow removal. We show scalability by performing robust PCA on the entire Star Wars IV movie.",Soren Hauberg and Aasa Feragen and Michael J Black,51,13553228480401993075,,,3810-3817,,Grassmann averages for scalable robust PCA,http://openaccess.thecvf.com/content_cvpr_2014/html/Hauberg_Grassmann_Averages_for_2014_CVPR_paper.html,,2014,/scholar?cites=13553228480401993075,6NjbexEAAAAJ:oea97a5D_h0C

1010153,"CiNii 国立情報学研究所 学術情報ナビゲータ[サイニィ]. メニュー 検索 … 
",MJ Black,50,9444387880333392773,"Int. Workshop on Automatic Face and Gesture-Recognition, Zurich",,12-17,,Recognizing facial expressions under rigid and non-rigid facial motions,https://ci.nii.ac.jp/naid/20000430123/,,1995,/scholar?cites=9444387880333392773,6NjbexEAAAAJ:iH-uZ7U-co4C

1010154,"We demonstrate a novel deep neural network capable of reconstructing human full body pose in real-time from 6 Inertial Measurement Units (IMUs) worn on the user's body. In doing so, we address several difficult challenges. First, the problem is severely under-constrained as multiple pose parameters produce the same IMU orientations. Second, capturing IMU data in conjunction with ground-truth poses is expensive and difficult to do in many target application scenarios (e.g., outdoors). Third, modeling temporal dependencies through non-linear optimization has proven effective in prior work but makes real-time prediction infeasible. To address this important limitation, we learn the temporal pose priors using deep learning. To learn from sufficient data, we synthesize IMU data from motion capture datasets. A bi-directional RNN architecture leverages past and future information that is available at training time. At …",Yinghao Huang and Manuel Kaufmann and Emre Aksan and Michael J Black and Otmar Hilliges and Gerard Pons-Moll,49,5529599269243203263,ACM Transactions on Graphics (TOG),6,1-15,ACM,Deep inertial poser: learning to reconstruct human pose from sparse inertial measurements in real time,https://dl.acm.org/doi/abs/10.1145/3272127.3275108,37,2018,/scholar?cites=5529599269243203263,6NjbexEAAAAJ:QXQxek9En5IC

1010155,"In this paper we provide an overview of recent research conducted at the University of Maryland's Computer Vision Laboratory on problems related to surveillance of human activities. Our research is motivated by considerations of a ground-based mobile surveillance system that monitors an extended area for human activity. During motion, the surveillance system must detect other moving objects and identify them as humans, animals, vehicles. When one or more persons are detected, their movements need to be analyzed to recognize the activities that they are involved in. Ideally, the surveillance system would be able to accomplish this even while continuing to move; alternatively, the system could stop and stare at that part of the scene containing people. In Section 1 we describe a novel approach to the problem of detecting independently moving objects from a moving ground camera, and illustrate the approach …",Larry Davis and Sandor Fejes and David Harwood and Yaser Yacoob and Ismail Hariatoglu and Michael J Black,49,3386636974269529898,,,267-274,"Springer, Berlin, Heidelberg",Visual surveillance of human activity,https://link.springer.com/content/pdf/10.1007/3-540-63931-4_226.pdf,,1998,/scholar?cites=3386636974269529898,6NjbexEAAAAJ:2P1L_qKh6hAC

1010156,"In this work we present and apply infinite Gaussian mixture modeling, a non-parametric Bayesian method, to the problem of spike sorting. As this approach is Bayesian, it allows us to integrate prior knowledge about the problem in a principled way. Because it is non-parametric we are able to avoid model selection, a difficult problem that most current spike sorting methods do not address. We compare this approach to using penalized log likelihood to select the best from multiple finite mixture models trained by expectation maximization. We show favorable offline sorting results on real data and discuss ways to extend our model to online applications",Frank Wood and Sharon Goldwater and Michael J Black,48,12765296263574633791,,,1165-1168,IEEE,A non-parametric Bayesian approach to spike sorting,https://ieeexplore.ieee.org/abstract/document/4461964/,,2006,/scholar?cites=12765296263574633791,6NjbexEAAAAJ:pyW8ca7W8N0C

1010157,"Objective. Motor neuroscience and brain–machine interface (BMI) design is based on examining how the brain controls voluntary movement, typically by recording neural activity and behavior from animal models. Recording technologies used with these animal models have traditionally limited the range of behaviors that can be studied, and thus the generality of science and engineering research. We aim to design a freely-moving animal model using neural and behavioral recording technologies that do not constrain movement. Approach. We have established a freely-moving rhesus monkey model employing technology that transmits neural activity from an intracortical array using a head-mounted device and records behavior through computer vision using markerless motion capture. We demonstrate the flexibility and utility of this new monkey model, including the first recordings from motor cortex while rhesus …",Justin D Foster and Paul Nuyujukian and Oren Freifeld and Hua Gao and Ross Walker and Stephen I Ryu and Teresa H Meng and Boris Murmann and Michael J Black and Krishna V Shenoy,47,5696175917610642581,Journal of neural engineering,4,046020,IOP Publishing,A freely-moving monkey treadmill model,https://iopscience.iop.org/article/10.1088/1741-2560/11/4/046020/meta,11,2014,/scholar?cites=5696175917610642581,6NjbexEAAAAJ:1zNUifcpCKoC

1010158,"While the problem of tracking 3D human motion has been widely studied, most approaches have assumed that the person is isolated and not interacting with the environment. Environmental constraints, however, can greatly constrain and simplify the tracking problem. The most studied constraints involve gravity and contact with the ground plane. We go further to consider interaction with objects in the environment. In many cases, tracking rigid environmental objects is simpler than tracking high-dimensional human motion. When a human is in contact with objects in the world, their poses constrain the pose of body, essentially removing degrees of freedom. Thus what would appear to be a harder problem, combining object and human tracking, is actually simpler. We use a standard formulation of the body tracking problem but add an explicit model of contact with objects. We find that constraints from the world make it …",Hedvig Kjellström and Danica Kragić and Michael J Black,47,13139180310393567055,,,747-754,IEEE,Tracking people interacting with objects,https://ieeexplore.ieee.org/abstract/document/5540140/,,2010,/scholar?cites=13139180310393567055,6NjbexEAAAAJ:CHSYGLWDkRkC

1010159,"Bayesian methods for visual tracking model the likelihood of image measurements conditioned on a tracking hypothesis. Image measurements may, for example, correspond to various filter responses at multiple scales and orientations. Most tracking approaches exploit ad hoc likelihood models while those that exploit more rigorous, learned, models often make unrealistic assumptions about the underlying probabilistic model. Such assumptions cause problems for Bayesian inference when an unsound likelihood is combined with an a priori probability distribution. Errors in modeling the likelihood can lead to brittle tracking results, particularly when using non-parametric inference techniques such as particle filtering. We show how assumptions of conditional independence of filter responses are violated in common tracking scenarios, lead to incorrect likelihood models, and cause problems for Bayesian inference. We address the problem of modeling more principled likelihoods using Gibbs learning. The learned models are compared with naıve Bayes methods which assume conditional independence of the filter responses. We show how these Gibbs models can be used as an effective image likelihood, and demonstrate them in the context of particle filter-based human tracking.",Stefan Roth and Leonid Sigal and Michael Black,45,2333832520092395716,IEEE Computer Society Conference on Computer Vision and Pattern Recognition,,I-886,IEEE Computer Society; 1999,Gibbs likelihoods for bayesian tracking,https://download.visinf.tu-darmstadt.de/papers/2004-cvpr-roth-gibbs_likelihoods_tracking-preprint.pdf,1,2004,/scholar?cites=2333832520092395716,6NjbexEAAAAJ:70eg2SAEIzsC

1010160,"Existing optical flow datasets are limited in size and variability due to the difficulty of capturing dense ground truth. In this paper, we tackle this problem by tracking pixels through densely sampled space-time volumes recorded with a high-speed video camera. Our model exploits the linearity of small motions and reasons about occlusions from multiple frames. Using our technique, we are able to establish accurate reference flow fields outside the laboratory in natural environments. Besides, we show how our predictions can be used to augment the input images with realistic motion blur. We demonstrate the quality of the produced flow fields on synthetic and real-world datasets. Finally, we collect a novel challenging optical flow dataset by applying our technique on data from a high-speed camera and analyze the performance of the state-of-the-art in optical flow under various levels of motion blur.",Joel Janai and Fatma Guney and Jonas Wulff and Michael J Black and Andreas Geiger,43,288366238493764555,,,3597-3607,,Slow flow: Exploiting high-speed cameras for accurate and diverse optical flow reference data,http://openaccess.thecvf.com/content_cvpr_2017/html/Janai_Slow_Flow_Exploiting_CVPR_2017_paper.html,,2017,/scholar?cites=288366238493764555,6NjbexEAAAAJ:fiDIZbHD5NAC

1010161,"Realistic, metrically accurate, 3D human avatars are useful for games, shopping, virtual reality, and health applications. Such avatars are not in wide use because solutions for creating them from high-end scanners, low-cost range cameras, and tailoring measurements all have limitations. Here we propose a simple solution and show that it is surprisingly accurate. We use crowdsourcing to generate attribute ratings of 3D body shapes corresponding to standard linguistic descriptions of 3D shape. We then learn a linear function relating these ratings to 3D human shape parameters. Given an image of a new body, we again turn to the crowd for ratings of the body shape. The collection of linguistic ratings of a photograph provides remarkably strong constraints on the metric 3D shape. We call the process crowdshaping and show that our Body Talk system produces shapes that are perceptually indistinguishable from …",Stephan Streuber and M Alejandra Quiros-Ramirez and Matthew Q Hill and Carina A Hahn and Silvia Zuffi and Alice O'Toole and Michael J Black,43,2731031100104423336,ACM Transactions on Graphics (TOG),4,1-14,ACM,Body talk: Crowdshaping realistic 3D avatars with words,https://dl.acm.org/doi/abs/10.1145/2897824.2925981,35,2016,/scholar?cites=2731031100104423336,6NjbexEAAAAJ:xO3Y8ErbwlsC

1010162,,Fernando De la Torre and Michael Black,43,16461624352508873274,,,653-669,Springer Berlin/Heidelberg,Robust parameterized component analysis,,,2006,/scholar?cites=16461624352508873274,6NjbexEAAAAJ:_Ybze24A_UAC

1010163,"The estimation of 3D face shape from a single image must be robust to variations in lighting, head pose, expression, facial hair, makeup, and occlusions. Robustness requires a large training set of in-the-wild images, which by construction, lack ground truth 3D shape. To train a network without any 2D-to-3D supervision, we present RingNet, which learns to compute 3D face shape from a single image. Our key observation is that an individual's face shape is constant across images, regardless of expression, pose, lighting, etc. RingNet leverages multiple images of a person and automatically detected 2D face features. It uses a novel loss that encourages the face shape to be similar when the identity is the same and different for different people. We achieve invariance to expression by representing the face using the FLAME model. Once trained, our method takes a single image and outputs the parameters of FLAME, which can be readily animated. Additionally we create a new database of faces"" not quite in-the-wild""(NoW) with 3D head scans and high-resolution images of the subjects in a wide variety of conditions. We evaluate publicly available methods and find that RingNet is more accurate than methods that use 3D supervision. The dataset, model, and results are available for research purposes at http://ringnet. is. tuebingen. mpg. de.",Soubhik Sanyal and Timo Bolkart and Haiwen Feng and Michael J Black,40,6222276537193580371,,,7763-7772,,Learning to regress 3d face shape and expression from an image without 3d supervision,http://openaccess.thecvf.com/content_CVPR_2019/html/Sanyal_Learning_to_Regress_3D_Face_Shape_and_Expression_From_an_CVPR_2019_paper.html,,2019,/scholar?cites=6222276537193580371,6NjbexEAAAAJ:yifHVNw3tWEC

1010164,"Modeling how the human body deforms during breathing is important for the realistic animation of lifelike 3D avatars. We learn a model of body shape deformations due to breathing for different breathing types and provide simple animation controls to render lifelike breathing regardless of body shape. We capture and align high-resolution 3D scans of 58 human subjects. We compute deviations from each subject's mean shape during breathing, and study the statistics of such shape changes for different genders, body shapes, and breathing types. We use the volume of the registered scans as a proxy for lung volume and learn a novel non-linear model relating volume and breathing type to 3D shape deformations and pose changes. We then augment a SCAPE body model so that body shape is determined by identity, pose, and the parameters of the breathing model. These parameters provide an intuitive interface …",Aggeliki Tsoli and Naureen Mahmood and Michael J Black,40,7370931852104271740,ACM Transactions on graphics (TOG),4,1-11,ACM,"Breathing life into shape: Capturing, modeling and animating 3D human breathing",https://dl.acm.org/doi/abs/10.1145/2601097.2601225,33,2014,/scholar?cites=7370931852104271740,6NjbexEAAAAJ:hImZayhCRfQC

1010165,"Basic neural prosthetic control of a computer cursor has been recently demonstrated by Hochberg et al. (2006) using the BrainGate system (Cyberkinetics Neurotechnology Systems, Inc.). While these results demonstrate the feasibility of intracortically-driven prostheses for humans with paralysis, a practical cursor-based computer interface requires more precise cursor control and the ability to ""click"" on areas of interest. Here we present the first practical point and click device that decodes both continuous states (e.g. cursor kinematics) and discrete states (e.g. click states) from a single neural population in human motor cortex. We describe a probabilistic multi-state decoder and the necessary training paradigms that enable point and click cursor control by a human with tetraplegia using an implanted microelectrode array. We present results from multiple recording sessions and quantify the point and click performance",Sung-Phil Kim and John D Simeral and Leigh R Hochberg and John P Donoghue and Gerhard M Friehs and Michael J Black,40,12716983026722282169,,,486-489,IEEE,Multi-state decoding of point-and-click control signals from motor cortical activity in a human with tetraplegia,https://ieeexplore.ieee.org/abstract/document/4227320/,,2007,/scholar?cites=12716983026722282169,6NjbexEAAAAJ:SeFeTyx0c_EC

1010166,"Human motion is fundamental to understanding behavior. Despite progress on single-image 3D pose and shape estimation, existing video-based state-of-the-art methods fail to produce accurate and natural motion sequences due to a lack of ground-truth 3D motion data for training. To address this problem, we propose"" Video Inference for Body Pose and Shape Estimation""(VIBE), which makes use of an existing large-scale motion capture dataset (AMASS) together with unpaired, in-the-wild, 2D keypoint annotations. Our key novelty is an adversarial learning framework that leverages AMASS to discriminate between real human motions and those produced by our temporal pose and shape regression networks. We define a novel temporal network architecture with a self-attention mechanism and show that adversarial training, at the sequence level, produces kinematically plausible motion sequences without in-the-wild ground-truth 3D labels. We perform extensive experimentation to analyze the importance of motion and demonstrate the effectiveness of VIBE on challenging 3D pose estimation datasets, achieving state-of-the-art performance. Code and pretrained models are available at https://github. com/mkocabas/VIBE",Muhammed Kocabas and Nikos Athanasiou and Michael J Black,39,17176071884903916917,,,5253-5263,,VIBE: Video inference for human body pose and shape estimation,http://openaccess.thecvf.com/content_CVPR_2020/html/Kocabas_VIBE_Video_Inference_for_Human_Body_Pose_and_Shape_Estimation_CVPR_2020_paper.html,,2020,/scholar?cites=17176071884903916917,6NjbexEAAAAJ:uh8FjILnQOkC

1010167,"The goal of this research was to investigate women's sensitivity to changes in their perceived weight by altering the body mass index (BMI) of the participants' personalized avatars displayed on a large-screen immersive display. We created the personalized avatars with a full-body 3D scanner that records the participants' body geometry and texture. We altered the weight of the personalized avatars to produce changes in BMI while keeping height, arm length, and inseam fixed and exploited the correlation between body geometry and anthropometric measurements encapsulated in a statistical body shape model created from thousands of body scans. In a 2 × 2 psychophysical experiment, we investigated the relative importance of visual cues, namely shape (own shape vs. an average female body shape with equivalent height and BMI to the participant) and texture (own photo-realistic texture or checkerboard …",Ivelina V Piryankova and Jeanine K Stefanucci and Javier Romero and Stephan De La Rosa and Michael J Black and Betty J Mohler,39,6327539664223166886,ACM Transactions on Applied Perception (TAP),3,1-18,ACM,Can I recognize my body's weight? The influence of shape and texture on the perception of self,https://dl.acm.org/doi/abs/10.1145/2641568,11,2014,/scholar?cites=6327539664223166886,6NjbexEAAAAJ:RXC-vbXDMdwC

1010168,"We present a method for simultaneously learning linear models of multiple high dimensional data sets and the dependencies between them. For example, we learn asymmetrically coupled linear models for the faces of two different people and show how these models can be used to animate one face given a video sequence of the other. We pose the problem as a form of Asymmetric Coupled Component Analysis (ACCA) in which we simultaneously learn the subspaces for reducing the dimensionality of each dataset while coupling the parameters of the low dimensional representations. Additionally, a dynamic form of ACCA is proposed, that extends this work to model temporal dependencies in the data sets. To account for outliers and missing data, we formulate the problem in a statistically robust estimation framework. We review connections with previous work and illustrate the method with examples of …",Fernando De la Torre and Michael J Black,39,5178171078192048113,,,II-II,IEEE,Dynamic coupled component analysis,https://ieeexplore.ieee.org/abstract/document/991024/,2,2001,/scholar?cites=5178171078192048113,6NjbexEAAAAJ:NaGl4SEjCO4C

1010169,"Animals are widespread in nature and the analysis of their shape and motion is important in many fields and industries. Modeling 3D animal shape, however, is difficult because the 3D scanning methods used to capture human shape are not applicable to wild animals or natural settings. Consequently, we propose a method to capture the detailed 3D shape of animals from images alone. The articulated and deformable nature of animals makes this problem extremely challenging, particularly in unconstrained environments with moving and uncalibrated cameras. To make this possible, we use a strong prior model of articulated animal shape that we fit to the image data. We then deform the animal shape in a canonical reference pose such that it matches image evidence when articulated and projected into multiple images. Our method extracts significantly more 3D shape detail than previous methods and is able to model new species, including the shape of an extinct animal, using only a few video frames. Additionally, the projected 3D shapes are accurate enough to facilitate the extraction of a realistic texture map from multiple frames.",Silvia Zuffi and Angjoo Kanazawa and Michael J Black,38,17564552368013852995,,,3955-3963,,"Lions and tigers and bears: Capturing non-rigid, 3d, articulated shape from images",http://openaccess.thecvf.com/content_cvpr_2018/html/Zuffi_Lions_and_Tigers_CVPR_2018_paper.html,,2018,/scholar?cites=17564552368013852995,6NjbexEAAAAJ:VTkKiNFP83YC

1010170,,J Yang and K Yu and Y Gong and T Huang,38,15880838510441421764,"2009 IEEE Conference On. Miami, FL: IEEE",,1794-1801,,Computer vision and pattern recognition (CVPR),http://scholar.google.com/scholar?cluster=15880838510441421764&hl=en&oi=scholarr,,2009,/scholar?cites=15880838510441421764,6NjbexEAAAAJ:Cv-mv52rCCkC

1010171,"The paper presents a review of our neural prosthesis research program and provides a brief introduction to the field. We focus on four key problems: sensing, neural encoding, neural decoding, and interface design. We explore these problems and present our current solutions which have led to the direct cortical control of unconstrained 2D cursor movement.",Michael J Black and Elie Bienenstock and John P Donoghue and Mijail Serruya and Wei Wu and Yun Gao,38,6958256977568630035,,,580-583,IEEE,Connecting brains with machines: the neural control of 2D cursor movement,https://ieeexplore.ieee.org/abstract/document/1196893/,,2003,/scholar?cites=6958256977568630035,6NjbexEAAAAJ:pqnbT2bcN3wC

1010172,"An image segmentation system segments images into component elements by modelling the image as a series of combined layers. The brightness of pixels within each layer is modelled as a parametric function of pixel position. Weights are assigned to each pixel position within each layer and describe how the layers are combined to form a recovered image. By modelling the image as a compilation of layers having different brightness functions, the system segments elements within an image, including text, when the image is corrupted by noise and when elements are combined, such as text and graphics. Enhanced image compression is obtained by modelling the image in multiple layers.",,38,286474546587269125,,,,,Image segmentation using robust mixture models,https://patents.google.com/patent/US5802203A/en,,1998,/scholar?cites=286474546587269125,6NjbexEAAAAJ:rO6llkc54NcC

1010173,"Large motions remain a challenge for current optical flow algorithms. Traditionally, large motions are addressed using multi-resolution representations like Gaussian pyramids. To deal with large displacements, many pyramid levels are needed and, if an object is small, it may be invisible at the highest levels. To address this we decompose images using a channel representation (CR) and replace the standard brightness constancy assumption with a descriptor constancy assumption. CRs can be seen as an over-segmentation of the scene into layers based on some image feature. If the appearance of a foreground object differs from the background then its descriptor will be different and they will be represented in different layers. We create a pyramid by smoothing these layers, without mixing foreground and background or losing small objects. Our method estimates more accurate flow than the baseline on …",Laura Sevilla-Lara and Deqing Sun and Erik G Learned-Miller and Michael J Black,35,5550500847096883487,,,423-438,"Springer, Cham",Optical flow estimation with channel constancy,https://link.springer.com/chapter/10.1007/978-3-319-10590-1_28,,2014,/scholar?cites=5550500847096883487,6NjbexEAAAAJ:MOUuoOoUJb4C

1010174,"Audio-driven 3D facial animation has been widely explored, but achieving realistic, human-like performance is still unsolved. This is due to the lack of available 3D datasets, models, and standard evaluation metrics. To address this, we introduce a unique 4D face dataset with about 29 minutes of 4D scans captured at 60 fps and synchronized audio from 12 speakers. We then train a neural network on our dataset that factors identity from facial motion. The learned model, VOCA (Voice Operated Character Animation) takes any speech signal as input--even speech in languages other than English--and realistically animates a wide range of adult faces. Conditioning on subject labels during training allows the model to learn a variety of realistic speaking styles. VOCA also provides animator controls to alter speaking style, identity-dependent facial shape, and pose (ie head, jaw, and eyeball rotations) during animation. To our knowledge, VOCA is the only realistic 3D facial animation model that is readily applicable to unseen subjects without retargeting. This makes VOCA suitable for tasks like in-game video, virtual reality avatars, or any scenario in which the speaker, speech, or language is not known in advance. We make the dataset and model available for research purposes at http://voca. is. tue. mpg. de.",Daniel Cudeiro and Timo Bolkart and Cassidy Laidlaw and Anurag Ranjan and Michael J Black,34,12568957979354957566,,,10101-10111,,"Capture, learning, and synthesis of 3d speaking styles",http://openaccess.thecvf.com/content_CVPR_2019/html/Cudeiro_Capture_Learning_and_Synthesis_of_3D_Speaking_Styles_CVPR_2019_paper.html,,2019,/scholar?cites=12568957979354957566,6NjbexEAAAAJ:2mus-XyGPC0C

1010175,"Neural activity in ventral premotor cortex (PMv) has been associated with the process of matching perceived objects with the motor commands needed to grasp them. It remains unclear how PMv networks can flexibly link percepts of objects affording multiple grasp options into a final desired hand action. Here, we use a relational encoding approach to track the functional state of PMv neuronal ensembles in macaque monkeys through the process of passive viewing, grip planning, and grasping movement execution. We used objects affording multiple possible grip strategies. The task included separate instructed delay periods for object presentation and grip instruction. This approach allowed us to distinguish responses elicited by the visual presentation of the objects from those associated with selecting a given motor plan for grasping. We show that PMv continuously incorporates information related to object shape …",Carlos E Vargas-Irwin and Lachlan Franquemont and Michael J Black and John P Donoghue,33,7528039790340707614,Journal of Neuroscience,30,10888-10897,Society for Neuroscience,Linking objects to actions: encoding of target object and grasping strategy in primate ventral premotor cortex,https://www.jneurosci.org/content/35/30/10888?utm_source=TrendMD&utm_medium=cpc&utm_campaign=JNeurosci_TrendMD_1,35,2015,/scholar?cites=7528039790340707614,6NjbexEAAAAJ:6DS7WFnF4J4C

1010176,"We formulate the estimation of dense depth maps from video sequences as a problem of intrinsic image estimation. Our approach synergistically integrates the estimation of multiple intrinsic images including depth, albedo, shading, optical flow, and surface contours. We build upon an example-based framework for depth estimation that uses label transfer from a database of RGB and depth pairs. We combine this with a method that extracts consistent albedo and shading from video. In contrast to raw RGB values, albedo and shading provide a richer, more physical, foundation for depth transfer. Additionally we train a new contour detector to predict surface boundaries from albedo, shading, and pixel values and use this to improve the estimation of depth boundaries. We also integrate sparse structure from motion with our method to improve the metric accuracy of the estimated depth maps. We evaluate our Intrinsic Depth method quantitatively by estimating depth from videos in the NYU RGB-D and SUN3D datasets. We find that combining the estimation of multiple intrinsic images improves depth estimation relative to the baseline method.",Naejin Kong and Michael J Black,33,2958950625397273015,,,3514-3522,,Intrinsic depth: Improving depth transfer with intrinsic images,http://openaccess.thecvf.com/content_iccv_2015/html/Kong_Intrinsic_Depth_Improving_ICCV_2015_paper.html,,2015,/scholar?cites=2958950625397273015,6NjbexEAAAAJ:6w2ZCmoKEM0C

1010177,"This paper describes our efforts to develop a “Digital Office” in which we augment a physical office setting with cameras and other electronic devices. Our goal is to bring the worlds of electronic and physical documents closer together and to facilitate the interaction of humans with all kinds of documents. In the “Digital Office” we extend the traditional notion of “scanning” documents to include the capture of whiteboards, books, desktops, and the human office workers themselves. In particular, we give an overview of three systems in which video cameras unobtrusively observe and capture whiteboards and human gestures, papers on the desktop, and the motion of a user’s face which is used to control the display of electronic documents in a browser. Each of these systems combines the features and affordances of both physical and electronic documents, and together they begin to illuminate the intelligent office environment of the future.",Michael Black and François Bérard and Allan Jepson and William Newman and Eric Saund and Gudrun Socher and Michael Taylor,33,11107538919700935318,AAAI Spring Symposium on Intelligent Environments,,1-6,,The digital office: Overview,http://www.csri.utoronto.ca/~jepson/papers/BlackEtAlAAAI1998.pdf,,1998,/scholar?cites=11107538919700935318,6NjbexEAAAAJ:M05iB0D1s5AC

1010178,"We address the unsupervised learning of several interconnected problems in lowlevel vision: single view depth prediction, camera motion estimation, optical flow and segmentation of a video into the static scene and moving regions. Our key insight is that these four fundamental vision problems are coupled and, consequently, learning to solve them together simplifies the problem because the solutions can reinforce each other by exploiting known geometric constraints. In order to model geometric constraints, we introduce Adversarial Collaboration, a framework that facilitates competition and collaboration between neural networks. We go beyond previous work by exploiting geometry more explicitly and segmenting the scene into static and moving regions. Adversarial Collaboration works much like expectation-maximization but with neural networks that act as adversaries, competing to explain pixels that correspond to static or moving regions, and as collaborators through a moderator that assigns pixels to be either static or independently moving. Our novel method integrates all these problems in a common framework and simultaneously reasons about the segmentation of the scene into moving objects and the static background, the camera motion, depth of the static scene structure, and the optical flow of moving objects. Our model is trained without any supervision and achieves state of the art results amongst unsupervised methods.",Anurag Ranjan and Varun Jampani and Kihwan Kim and Deqing Sun and Jonas Wulff and Michael J Black,32,12151339221762611338,arXiv preprint arXiv:1805.09806,6,,,"Adversarial collaboration: Joint unsupervised learning of depth, camera motion, optical flow and motion segmentation",http://scholar.google.com/scholar?cluster=12151339221762611338&hl=en&oi=scholarr,2,2018,/scholar?cites=12151339221762611338,6NjbexEAAAAJ:yIkSIh5mphAC

1010179,"Previous literature suggests that a disturbed ability to accurately identify own body size may contribute to overweight. Here, we investigated the influence of personal body size, indexed by body mass index (BMI), on body size estimation in a non-clinical population of females varying in BMI. We attempted to disentangle general biases in body size estimates and attitudinal influences by manipulating whether participants believed the body stimuli (personalized avatars with realistic weight variations) represented their own body or that of another person. Our results show that the accuracy of own body size estimation is predicted by personal BMI, such that participants with lower BMI underestimated their body size and participants with higher BMI overestimated their body size. Further, participants with higher BMI were less likely to notice the same percentage of weight gain than participants with lower BMI. Importantly, these results were only apparent when participants were judging a virtual body that was their own identity (Experiment 1), but not when they estimated the size of a body with another identity and the same underlying body shape (Experiment 2a). The different influences of BMI on accuracy of body size estimation and sensitivity to weight change for self and other identity suggests that effects of BMI on visual body size estimation are self-specific and not generalizable to other bodies.",Anne Thaler and Michael N Geuss and Simone C Mölbert and Katrin E Giel and Stephan Streuber and Javier Romero and Michael J Black and Betty J Mohler,31,13184832849705504012,PloS one,2,e0192152,Public Library of Science,Body size estimation of self and others in females varying in BMI,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0192152,13,2018,/scholar?cites=13184832849705504012,6NjbexEAAAAJ:FVakaZBJmp0C

1010180,"Intrinsic images such as albedo and shading are valuable for later stages of visual processing. Previous methods for extracting albedo and shading use either single images or images together with depth data. Instead, we define intrinsic video estimation as the problem of extracting temporally coherent albedo and shading from video alone. Our approach exploits the assumption that albedo is constant over time while shading changes slowly. Optical flow aids in the accurate estimation of intrinsic video by providing temporal continuity as well as putative surface boundaries. Additionally, we find that the estimated albedo sequence can be used to improve optical flow accuracy in sequences with changing illumination. The approach makes only weak assumptions about the scene and we show that it substantially outperforms existing single-frame intrinsic image methods. We evaluate this quantitatively on …",Naejin Kong and Peter V Gehler and Michael J Black,31,13721509147059387345,,,360-375,"Springer, Cham",Intrinsic video,https://link.springer.com/chapter/10.1007/978-3-319-10605-2_24,,2014,/scholar?cites=13721509147059387345,6NjbexEAAAAJ:qE25ZKhNtbAC

1010181,"Extracting anthropometric or tailoring measurements from 3D human body scans is important for applications such as virtual try-on, custom clothing, and online sizing. Existing commercial solutions identify anatomical landmarks on high-resolution 3D scans and then compute distances or circumferences on the scan. Landmark detection is sensitive to acquisition noise (e.g. holes) and these methods require subjects to adopt a specific pose. In contrast, we propose a solution we call model-based anthropometry. We fit a deformable 3D body model to scan data in one or more poses; this model-based fitting is robust to scan noise. This brings the scan into registration with a database of registered body scans. Then, we extract features from the registered model (rather than from the scan); these include, limb lengths, circumferences, and statistical features of global shape. Finally, we learn a mapping from these features …",Aggeliki Tsoli and Matthew Loper and Michael J Black,31,5214103086911038600,,,83-90,IEEE,Model-based anthropometry: Predicting measurements from 3D human scans in multiple poses,https://ieeexplore.ieee.org/abstract/document/6836115/,,2014,/scholar?cites=5214103086911038600,6NjbexEAAAAJ:Z8CpXElfgm4C

1010182,"This paper presents a new model for optical flow based on the motion of planar regions plus local deformations. The approach exploits brightness information to organize and constrain the interpretation of the motion by using segmented regions of piecewise smooth brightness to hypothesize planar regions in the scene. Parametric flow models are fitted to these regions an a two step process which first computes a coarse fit and then refines it using a generalization of the standard area-based regression approaches. Since the assumption of planarity is likely to be violated, we allow local deformations from the planar assumption. This parametric+deformation model exploits the strong constraints of parametric approaches while retaining the adaptive nature of regularization approaches.< >",RJ Black and Allan Jepson,31,6580922900465470915,,,220-227,IEEE,Estimating multiple independent motions in segmented images using parametric models with local deformations,https://ieeexplore.ieee.org/abstract/document/346232/,,1994,/scholar?cites=6580922900465470915,6NjbexEAAAAJ:n5u26LFhhPsC

1010183,"We present a method for the modeling and tracking of human motion using a sequence of 2D video images. Our analysis is divided in two parts: statistical learning and Bayesian tracking. First, we estimate a statistical model of typical activities from a large set of 3D human motion data. For this purpose, the human body is represented as a set of articulated cylinders and the evolution of a particular joint angle is described by a time-series. Specifically, we consider periodic motion such as “walking” in this work, and we develop a new set of tools that allows for the automatic segmentation of the training data into a sequence of identical “motion cycles”. Then we compute the mean and the principal components of these cycles using a new algorithm to account for missing information and to enforce smooth transitions between different cycles. The learned temporal model provides a prior probability distribution over human motions which is used for tracking. We adopt a Bayesian perspective and approximate the posterior distribution of the body parameters using a particle filter. The resulting algorithm is able to track human subjects in monocular video sequences and to recover their 3D motion in complex unknown environments.",Dirk Ormoneit and Hedvig Sidenbladh and Michael J Black and Trevor Hastie and David J Fleet,30,4728472854698690583,"IEEE Workshop on Human Modeling, Analysis and Synthesis",,,,Learning and tracking human motion using functional analysis,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.21.1054&rep=rep1&type=pdf,2,2000,/scholar?cites=4728472854698690583,6NjbexEAAAAJ:yD5IFk8b50cC

1010184,"Multicamera tracking of humans and animals in outdoor environments is a relevant and challenging problem. Our approach to it involves a team of cooperating microaerial vehicles (MAVs) with on-board cameras only. Deep neural networks (DNNs) often fail at detecting small-scale objects or those that are far away from the camera, which are typical characteristics of a scenario with aerial robots. Thus, the core problem addressed in this letter is how to achieve on-board, online, continuous, and accurate vision-based detections using DNNs for visual person tracking through MAVs. Our solution leverages cooperation among multiple MAVs and active selection of most informative regions of image. We demonstrate the efficiency of our approach through simulations with up to 16 robots and real-robot experiments involving two aerial robots tracking a person, while maintaining an active perception-driven formation. ROS …",Eric Price and Guilherme Lawless and Roman Ludwig and Igor Martinovic and Heinrich H Bülthoff and Michael J Black and Aamir Ahmad,28,10907802793044317787,IEEE Robotics and Automation Letters,4,3193-3200,IEEE,Deep neural network-based cooperative visual tracking through multiple micro aerial vehicles,https://ieeexplore.ieee.org/abstract/document/8394622/,3,2018,/scholar?cites=10907802793044317787,6NjbexEAAAAJ:pOP5Rf-i_loC

1010185,"The estimation and detection of occlusion boundaries and moving bars are important and challenging problems in image sequence analysis. Here, we model such motion features as linear combinations of steerable basis flow fields. These models constrain the interpretation of image motion, and are used in the same way as translational or affine motion models. We estimate the subspace coefficients of the motion feature models directly from spatiotemporal image derivatives using a robust regression method. From the subspace coefficients we detect the presence of a motion feature and solve for the orientation of the feature and the relative velocities of the surfaces. Our method does not require the prior computation of optical flow and recovers accurate estimates of orientation and velocity.",David J Fleet and Michael J Black and Allan D Jepson,28,7314177360128035033,,,274-281,IEEE,Motion feature detection using steerable flow fields,https://ieeexplore.ieee.org/abstract/document/698620/,,1998,/scholar?cites=7314177360128035033,6NjbexEAAAAJ:u_35RYKgDlwC

1010186,"The tracking and recognition of human motion is a challenging problem with diverse applications in virtual reality, medicine, teleoperations, animation, and human-computer interaction to name a few. The study of human motion has a long history with the use of images for analyzing animate motion beginning with the improvements in photography and the development of motion-pictures in the late nineteenth century. Scientists and artists such as Marey [12] and Muybridge [26] were early explorers of human and animal motion in images and image sequences. Today, commercial motion-capture systems can be used to accurately record the 3D movements of an instrumented person, but the motion analysis and motion recognition of an arbitrary person in a video sequence remains an unsolved problem. In this chapter we describe the representation and recognition of human motion using parameterized …",Michael J Black and Yaser Yacoob and Shanon X Ju,28,15996122056404392724,,,245-269,"Springer, Dordrecht",Recognizing human motion using parameterized models of optical flow,https://link.springer.com/chapter/10.1007/978-94-015-8935-2_11,,1997,/scholar?cites=15996122056404392724,6NjbexEAAAAJ:MLfJN-KU85MC

1010187,"Surface discontinuities are detected in a sequence of images by exploiting physical constraints at early stages in the processing of visual motion. To achieve accurate early discontinuity detection we exploit five physical constraints on the presence of discontinuities: i) the shape of the sum of squared differences (SSD) error surface in the presence of surface discontinuities; ii) the change in the shape of the SSD surface due to relative surface motion; iii) distribution of optic ﬂow in a neighborhood of a discontinuity; iv) spatial consistency of discontinuities; v) temporal consistency of discontinuities. The constraints are described, and experimental results on sequences of real and synthetic images are presented. The work has applications in the recovery of environmental structure from motion and in the generation of dense optic ﬂow ﬁelds.",Michael J Black and Padmanabhan Anandan,28,11817163184282107980,,,1060-1066,,Constraints for the Early Detection of Discontinuity from Motion.,https://www.researchgate.net/profile/Michael_Black6/publication/2540101_Constraints_for_the_Early_Detection_of_Discontinuity_from_Motion/links/09e4151389d4e985ef000000.pdf,,1990,/scholar?cites=11817163184282107980,6NjbexEAAAAJ:HoB7MX3m0LUC

1010188,"The direct neural control of external prosthetic devices such as robot hands requires the accurate decoding of neural activity representing continuous movement. This requirement becomes formidable when multiple degrees of freedom (DoFs) are to be controlled as in the case of the fingers of a robotic hand. In this paper a methodology is proposed for estimating grasp aperture using the spiking activity of multiple neurons recorded with an electrode array implanted in the arm/hand area of primary motor cortex (Ml). Grasp aperture provides a reasonable approximation to the hand configuration during grasping tasks, while it offers a large reduction in the number of DoFs that must be estimated. A family of state space models with hidden variables is used to decode each finger grasp aperture with respect to the thumb from a population of motor-cortical neurons. The firing rates of multiple neurons in Ml were found to be …",Panagiotis K Artemiadis and Gregory Shakhnarovich and Carlos Vargas-Irwin and John P Donoghue and Michael J Black,27,5193431842850727773,,,518-521,IEEE,Decoding grasp aperture from motor-cortical population activity,https://ieeexplore.ieee.org/abstract/document/4227328/,,2007,/scholar?cites=5193431842850727773,6NjbexEAAAAJ:1sJd4Hv_s6UC

1010189,,Michael J Black and Yaser Yacoob,27,12276421273891354379,,,,"Computer Vision Laboratory, Center for Automation Research, University of Maryland","Tracking and recognizing facial expressions in image sequences, using local parameterized models of image motion",http://scholar.google.com/scholar?cluster=12276421273891354379&hl=en&oi=scholarr,,1995,/scholar?cites=12276421273891354379,6NjbexEAAAAJ:WQTnNU6cpycC

1010190,"We present the first method to perform automatic 3D pose, shape and texture capture of animals from images acquired in-the-wild. In particular, we focus on the problem of capturing 3D information about Grevy's zebras from a collection of images. The Grevy's zebra is one of the most endangered species in Africa, with only a few thousand individuals left. Capturing the shape and pose of these animals can provide biologists and conservationists with information about animal health and behavior. In contrast to research on human pose, shape and texture estimation, training data for endangered species is limited, the animals are in complex natural scenes with occlusion, they are naturally camouflaged, travel in herds, and look similar to each other. To overcome these challenges, we integrate the recent SMAL animal model into a network-based regression pipeline, which we train end-to-end on synthetically …",Silvia Zuffi and Angjoo Kanazawa and Tanya Berger-Wolf and Michael Black,26,18446621965724317298,,,5358-5367,IEEE,"Three-D Safari: Learning to Estimate Zebra Pose, Shape, and Texture from Images “In the Wild”",https://ieeexplore.ieee.org/abstract/document/9010937/,,2019,/scholar?cites=18446621965724317298,6NjbexEAAAAJ:f8T_-ThkUo0C

1010191,"In this paper, we propose a non-local structured prior for volumetric multi-view 3D reconstruction. Towards this goal, we present a novel Markov random field model based on ray potentials in which assumptions about large 3D surface patches such as planarity or Manhattan world constraints can be efficiently encoded as probabilistic priors. We further derive an inference algorithm that reasons jointly about voxels, pixels and image segments, and estimates marginal distributions of appearance, occupancy, depth, normals and planarity. Key to tractable inference is a novel hybrid representation that spans both voxel and pixel space and that integrates non-local information from 2D image segmentations in a principled way. We compare our non-local prior to commonly employed local smoothness assumptions and a variety of state-of-the-art volumetric reconstruction baselines on challenging outdoor scenes with textureless and reflective surfaces. Our experiments indicate that regularizing over larger distances has the potential to resolve ambiguities where local regularizers fail.",Ali Osman Ulusoy and Michael J Black and Andreas Geiger,25,11335957390530892734,,,3280-3289,,"Patches, planes and probabilities: A non-local prior for volumetric 3d reconstruction",http://openaccess.thecvf.com/content_cvpr_2016/html/Ulusoy_Patches_Planes_and_CVPR_2016_paper.html,,2016,/scholar?cites=11335957390530892734,6NjbexEAAAAJ:4x91efyQ1HQC

1010192,Increased emphasis on circuit level activity in the brain makes it necessary to have methods to visualize and evaluate large-scale ensemble activity beyond that revealed by raster-histograms or pairwise correlations. We present a method to evaluate the relative similarity of neural spiking patterns by combining spike train distance metrics with dimensionality reduction. Spike train distance metrics provide an estimate of similarity between activity patterns at multiple temporal resolutions. Vectors of pair-wise distances are used to represent the intrinsic relationships between multiple activity patterns at the level of single units or neuronal ensembles. Dimensionality reduction is then used to project the data into concise representations suitable for clustering analysis as well as exploratory visualization. Algorithm performance and robustness are evaluated using multielectrode ensemble activity data recorded in behaving …,Carlos E Vargas-Irwin and David M Brandman and Jonas B Zimmermann and John P Donoghue and Michael J Black,25,16557887466432399420,Neural computation,1,1-31,MIT Press,Spike train SIMilarity Space (SSIMS): a framework for single neuron and ensemble data analysis,https://www.mitpressjournals.org/doi/abs/10.1162/NECO_a_00684,27,2015,/scholar?cites=16557887466432399420,6NjbexEAAAAJ:MOFHY6MwG3AC

1010193,"We develop a method for discovering the parts of an articulated object from aligned meshes capturing various three-dimensional (3D) poses. We adapt the distance dependent Chinese restaurant process (ddCRP) to allow nonparametric discovery of a potentially unbounded number of parts, while simultaneously guaranteeing a spatially connected segmentation. To allow analysis of datasets in which object instances have varying shapes, we model part variability across poses via affine transformations. By placing a matrix normal-inverse-Wishart prior on these affine transformations, we develop a ddCRP Gibbs sampler which tractably marginalizes over transformation uncertainty. Analyzing a dataset of humans captured in dozens of poses, we infer parts which provide quantitatively better motion predictions than conventional clustering methods.",Soumya Ghosh and Matthew Loper and Erik Sudderth and Michael Black,25,9609917685091258180,Advances in Neural Information Processing Systems,,1997-2005,,From deformations to parts: Motion-based segmentation of 3D objects,http://papers.nips.cc/paper/4749-from-deformations-to-parts-motion-based-segmentation-of-3d-objects,25,2012,/scholar?cites=9609917685091258180,6NjbexEAAAAJ:TIZ-Mc8IlK0C

1010194,"Recent methods for motor cortical decoding have demonstrated relatively accurate reconstructions of hand trajectory from small populations of neurons in primary motor cortex. Decoding results are often reported only for periods when the subject is attending to the task. In a neural prosthetic interface, however, the subject must be able to switch between controlling a device or performing other mental functions. In this work we demonstrate a method for detecting whether or not a subject is attending to a motor control task. Using the firing activity of the same neural population used for decoding hand kinematics we demonstrate that a Fisher linear discriminant performs well in classifying the attentional state of a monkey. We use the output of this classifier to augment a hidden state in a first order Markov model and use particle filtering to recursively infer hand kinematics and attentional state conditioned on neural firing …",Frank Wood and Prabhat and John P Donoghue and Michael J Black,24,2974594080505304658,,,1544--1547,IEEE,Inferring Attentional State and Kinematics from Motor Cortical Firing Rates,https://ieeexplore.ieee.org/abstract/document/1616364/,,2005,/scholar?cites=2974594080505304658,6NjbexEAAAAJ:Tiz5es2fbqcC

1010195,"A method and system to decode neural activity in the motor cortex to infer at least the position and velocity of a subject's hand from neural spiking activity of some number of nerve cells. In one embodiment the method includes simultaneously recording electrical activity of the nerve cells in the primary motor cortex to obtain neural data; and modeling the encoding and decoding of the neural data using a Kalman filter, where a measurement model assumes a cell firing rate to be a stochastic linear function of at least the position and velocity of the hand, and where the measurement model is learned from training data in conjunction with a system model that encodes a manner in which the hand moves. In another embodiment the method includes using the neural data to generate training data of neural firing activity conditioned on hand kinematics; learning a non-parametric representation of the firing activity using a …",,24,12916340814947191061,,,,,Method and system for inferring hand motion from multi-cell recordings in the motor cortex using a kalman filter or a bayesian model,https://patents.google.com/patent/US20040073414A1/en,,2004,/scholar?cites=12916340814947191061,6NjbexEAAAAJ:5awf1xo2G04C

1010196,"To understand and analyze human behavior, we need to capture humans moving in, and interacting with, the world. Most existing methods perform 3D human pose estimation without explicitly considering the scene. We observe however that the world constrains the body and vice-versa. To motivate this, we show that current 3D human pose estimation methods produce results that are not consistent with the 3D scene. Our key contribution is to exploit static 3D scene structure to better estimate human pose from monocular images. The method enforces Proximal Relationships with Object eXclusion and is called PROX. To test this, we collect a new dataset composed of 12 different 3D scenes and RGB sequences of 20 subjects moving in and interacting with the scenes. We represent human pose using the 3D human body model SMPL-X and extend SMPLify-X to estimate body pose using scene constraints. We make use of the 3D scene information by formulating two main constraints. The inter-penetration constraint penalizes intersection between the body model and the surrounding 3D scene. The contact constraint encourages specific parts of the body to be in contact with scene surfaces if they are close enough in distance and orientation. For quantitative evaluation we capture a separate dataset with 180 RGB frames in which the ground-truth body pose is estimated using a motion capture system. We show quantitatively that introducing scene constraints significantly reduces 3D joint error and vertex error. Our code and data are available for research at https://prox. is. tue. mpg. de.",Mohamed Hassan and Vasileios Choutas and Dimitrios Tzionas and Michael J Black,23,17709453170239610944,arXiv preprint arXiv:1908.06963,,,,Resolving 3D Human Pose Ambiguities with 3D Scene Constraints,http://openaccess.thecvf.com/content_ICCV_2019/html/Hassan_Resolving_3D_Human_Pose_Ambiguities_With_3D_Scene_Constraints_ICCV_2019_paper.html,,2019,/scholar?cites=17709453170239610944,6NjbexEAAAAJ:lIaPce-xyHYC

1010197,"Occlusion boundaries contain rich perceptual information about the underlying scene structure. They also provide important cues in many visual perception tasks such as scene understanding, object recognition, and segmentation. In this paper, we improve occlusion boundary detection via enhanced exploration of contextual information (eg, local structural boundary patterns, observations from surrounding regions, and temporal context), and in doing so develop a novel approach based on convolutional neural networks (CNNs) and conditional random fields (CRFs). Experimental results demonstrate that our detector significantly outperforms the state-of-the-art (eg, improving the F-measure from 0.62 to 0.71 on the commonly used CMU benchmark). Last but not least, we empirically assess the roles of several important components of the proposed detector, so as to validate the rationale behind this approach.",Huan Fu and Chaohui Wang and Dacheng Tao and Michael J Black,23,4345732813383956717,,,241-250,,Occlusion boundary detection via deep exploration of context,https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Fu_Occlusion_Boundary_Detection_CVPR_2016_paper.html,,2016,/scholar?cites=4345732813383956717,6NjbexEAAAAJ:_E0j-SBEHDwC

1010198,"In large datasets, manual data verification is impossible, and we must expect the number of outliers to increase with data size. While principal component analysis (PCA) can reduce data size, and scalable solutions exist, it is well-known that outliers can arbitrarily corrupt the results. Unfortunately, state-of-the-art approaches for robust PCA are not scalable. We note that in a zero-mean dataset, each observation spans a one-dimensional subspace, giving a point on the Grassmann manifold. We show that the average subspace corresponds to the leading principal component for Gaussian data. We provide a simple algorithm for computing this Grassmann Average (GA), and show that the subspace estimate is less sensitive to outliers than PCA for general distributions. Because averages can be efficiently computed, we immediately gain scalability. We exploit robust averaging to formulate the Robust Grassmann …",Søren Hauberg and Aasa Feragen and Raffi Enficiaud and Michael J Black,23,250782865732964885,IEEE transactions on pattern analysis and machine intelligence,11,2298-2311,IEEE,Scalable robust principal component analysis using grassmann averages,https://ieeexplore.ieee.org/abstract/document/7364267/,38,2015,/scholar?cites=250782865732964885,6NjbexEAAAAJ:yxAilOxaV9sC

1010199,"Segmenting image sequences into meaningful layers is fundamental to many applications such as surveillance, tracking, and video summarization. Background subtraction techniques are popular for their simplicity and, while they provide a dense (pixelwise) estimate of foreground/background, they typically ignore image motion which can provide a rich source of information about scene structure. Conversely, layered motion estimation techniques typically ignore the temporal persistence of image appearance and provide parametric (rather than dense) estimates of optical flow. Recent work adaptively combines motion and appearance estimation in a mixture model framework to achieve robust tracking. Here we extend mixture model approaches to cope with dense motion and appearance estimation. We develop a unified Bayesian framework to simultaneously estimate the appearance of multiple image layers and …",Hulya Yalcin and Michael J Black and Ronan Fablet,23,14864670941440319531,,,165-165,IEEE,The dense estimation of motion and appearance in layers,https://ieeexplore.ieee.org/abstract/document/1384964/,,2004,/scholar?cites=14864670941440319531,6NjbexEAAAAJ:_xSYboBqXhAC

1010200,"Deep neural nets achieve state-of-the-art performance on the problem of optical flow estimation. Since optical flow is used in several safety-critical applications like self-driving cars, it is important to gain insights into the robustness of those techniques. Recently, it has been shown that adversarial attacks easily fool deep neural networks to misclassify objects. The robustness of optical flow networks to adversarial attacks, however, has not been studied so far. In this paper, we extend adversarial patch attacks to optical flow networks and show that such attacks can compromise their performance. We show that corrupting a small patch of less than 1% of the image size can significantly affect optical flow estimates. Our attacks lead to noisy flow estimates that extend significantly beyond the region of the attack, in many cases even completely erasing the motion of objects in the scene. While networks using an encoder-decoder architecture are very sensitive to these attacks, we found that networks using a spatial pyramid architecture are less affected. We analyse the success and failure of attacking both architectures by visualizing their feature maps and comparing them to classical optical flow techniques which are robust to these attacks. We also demonstrate that such attacks are practical by placing a printed pattern into real scenes.",Anurag Ranjan and Joel Janai and Andreas Geiger and Michael J Black,22,3858126776175776291,,,2404-2413,,Attacking optical flow,http://openaccess.thecvf.com/content_ICCV_2019/html/Ranjan_Attacking_Optical_Flow_ICCV_2019_paper.html,,2019,/scholar?cites=3858126776175776291,6NjbexEAAAAJ:SAguW2jnL4UC

1010201,"Infant motion analysis enables early detection of neurodevelopmental disorders like cerebral palsy (CP). Diagnosis, however, is challenging, requiring expert human judgement. An automated solution would be beneficial but requires the accurate capture of 3D full-body movements. To that end, we develop a non-intrusive, low-cost, lightweight acquisition system that captures the shape and motion of infants. Going beyond work on modeling adult body shape, we learn a 3D Skinned Multi-Infant Linear body model (SMIL) from noisy, low-quality, and incomplete RGB-D data. SMIL is publicly available for research purposes at                      http://s.fhg.de/smil                                        . We demonstrate the capture of shape and motion with 37 infants in a clinical environment. Quantitative experiments show that SMIL faithfully represents the data and properly factorizes the shape and pose of the infants. With a case …",Nikolas Hesse and Sergi Pujades and Javier Romero and Michael J Black and Christoph Bodensteiner and Michael Arens and Ulrich G Hofmann and Uta Tacke and Mijna Hadders-Algra and Raphael Weinberger and Wolfgang Müller-Felber and A Sebastian Schroeder,22,16098926133005645537,,,792-800,"Springer, Cham",Learning an Infant Body Model from RGB-D Data for Accurate Full Body Motion Analysis,https://link.springer.com/chapter/10.1007/978-3-030-00928-1_89,,2018,/scholar?cites=16098926133005645537,6NjbexEAAAAJ:HV_RJt6Pqn0C

1010202,"Systems, methods, and computer-readable storage media for simulating realistic clothing. The system generates a clothing deformation model for a clothing type, wherein the clothing deformation model factors a change of clothing shape due to rigid limb rotation, pose-independent body shape, and pose-dependent deformations. Next, the system generates a custom-shaped garment for a given body by mapping, via the clothing deformation model, body shape parameters to clothing shape parameters. The system then automatically dresses the given body with the custom-shaped garment.",,22,1862442080900989374,,,,,System and method for simulating realistic clothing,https://patents.google.com/patent/US9679409B2/en,,2017,/scholar?cites=1862442080900989374,6NjbexEAAAAJ:foJkpVhfThEC

1010203,"In applications of graphical models arising in domains such as computer vision and signal processing, we often seek the most likely configurations of high-dimensional, continuous variables. We develop a particle-based max-product algorithm which maintains a diverse set of posterior mode hypotheses, and is robust to initialization. At each iteration, the set of hypotheses at each node is augmented via stochastic proposals, and then reduced via an efficient selection algorithm. The integer program underlying our optimization-based particle selection minimizes errors in subsequent max-product message updates. This objective automatically encourages diversity in the maintained hypotheses, without requiring tuning of application-specific distances among hypotheses. By avoiding the stochastic resampling steps underlying particle sum-product algorithms, we also avoid common degeneracies where particles collapse onto a single hypothesis. Our approach significantly outperforms previous particle-based algorithms in experiments focusing on the estimation of human pose from single images.",Jason Pacheco and Silvia Zuffi and Michael Black and Erik Sudderth,22,17209612021463934617,,,1152-1160,,Preserving modes and messages via diverse particle selection,http://www.jmlr.org/proceedings/papers/v32/pacheco14.pdf,,2014,/scholar?cites=17209612021463934617,6NjbexEAAAAJ:P6jpBLdrFncC

1010204,"We consider the intersection of two research fields: transfer learning and statistics on manifolds. In particular, we consider, for manifold-valued data, transfer learning of tangent-space models such as Gaussians distributions, PCA, regression, or classifiers. Though one would hope to simply use ordinary Rn-transfer learning ideas, the manifold structure prevents it. We overcome this by basing our method on inner-product-preserving parallel transport, a well-known tool widely used in other problems of statistics on manifolds in computer vision. At first, this straight-forward idea seems to suffer from an obvious shortcoming: Transporting large datasets is prohibitively expensive, hindering scalability. Fortunately, with our approach, we never transport data. Rather, we show how the statistical models themselves can be transported, and prove that for the tangent-space models above, the transport"" commutes"" with learning. Consequently, our compact framework, applicable to a large class of manifolds, is not restricted by the size of either the training or test sets. We demonstrate the approach by transferring PCA and logistic-regression models of real-world data involving 3D shapes and image descriptors.",Oren Freifeld and Soren Hauberg and Michael J Black,22,10403178299009702476,,,1378-1385,,Model transport: Towards scalable transfer learning on manifolds,https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Freifeld_Model_Transport_Towards_2014_CVPR_paper.html,,2014,/scholar?cites=10403178299009702476,6NjbexEAAAAJ:Lr5Uwm59ZTwC

1010205,"Neural prosthetic technology has moved from the laboratory to clinical settings with human trials. The motor cortical control of devices in such settings raises important questions about the design of computational interfaces that produce stable and reliable control over a wide range of operating conditions. In particular, non-stationarity of the neural code across different behavioral conditions or attentional states becomes a potential issue. Non-stationarity has been previously observed in animals where the encoding model representing the mathematical relationship between neural population activity and behavioral variables such as hand motion changes over time. If such an encoding model is formed and learned during a particular training period, decoding performance (neural control) with the model may not be consistent during successive periods even when the same task is repeated. It is critical in both …",Sung-Phil Kim and Frank Wood and Matthew Fellows and John P Donoghue and Michael J Black,22,11848586895773939134,,,811-816,IEEE,Statistical analysis of the non-stationarity of neural population codes,https://ieeexplore.ieee.org/abstract/document/1639190/,,2006,/scholar?cites=11848586895773939134,6NjbexEAAAAJ:SP6oXDckpogC

1010206,"We present a switching Kalman filter model (SKFM) for the real-time inference of hand kinematics from a population of motor cortical neurons. First we model the probability of the firing rates of the population at a particular time instant as a Gaussian mixture where the mean of each Gaussian is some linear function of the hand kinematics. This mixture contains a ""hidden state"", or weight, that assigns a probability to each linear, Gaussian, term in the mixture. We then model the evolution of this hidden state over time as a Markov chain. The expectation-maximization (EM) algorithm is used to fit this mixture model to training data that consists of measured hand kinematics (position, velocity, acceleration) and the firing rates of 42 units recorded with a chronically implanted multi-electrode array. Decoding of neural data from a separate test set is achieved using the switching Kaiman filter (SKF) algorithm. Quantitative …",Wei Wu and Michael J Black and David Mumford and Yun Gao and Elie Bienenstock and John P Donoghue,22,17257386153063673300,,,2083-2086,IEEE,A switching Kalman filter model for the motor cortical coding of hand motion,https://ieeexplore.ieee.org/abstract/document/1280147/,3,2003,/scholar?cites=17257386153063673300,6NjbexEAAAAJ:b0M2c_1WBrUC

1010207,"Dense 3D reconstruction from RGB images is a highly ill-posed problem due to occlusions, textureless or reflective surfaces, as well as other challenges. We propose object-level shape priors to address these ambiguities. Towards this goal, we formulate a probabilistic model that integrates multi-view image evidence with 3D shape information from multiple objects. Inference in this model yields a dense 3D reconstruction of the scene as well as the existence and precise 3D pose of the objects in it. Our approach is able to recover fine details not captured in the input shapes while defaulting to the input models in occluded regions where image evidence is weak. Due to its probabilistic nature, the approach is able to cope with the approximate geometry of the 3D models as well as input shapes that are not present in the scene. We evaluate the approach quantitatively on several challenging indoor and outdoor datasets.",Ali Osman Ulusoy and Michael J Black and Andreas Geiger,21,8849766798594501054,,,4531-4540,IEEE,Semantic multi-view stereo: Jointly estimating objects and voxels,https://ieeexplore.ieee.org/abstract/document/8099965/,,2017,/scholar?cites=8849766798594501054,6NjbexEAAAAJ:oyQIn_cjXD4C

1010208,"A novel “contour person”(CP) model of the human body is proposed that has the expressive power of a detailed 3D model and the computational benefits of a simple 20 part-based model. The CP model is learned from a 3D model of the human body that captures natural shape and pose variations. The CP model factors deformations of the body into three components: shape variation, viewpoint change and pose variation. The CP model can be “dressed” with a low-dimensional clothing model. The clothing is represented as a deformation from the underlying CP representation. This deformation is learned from training examples using principal component analysis to produce so-called eigen-clothing. The coefficients of the eigen-clothing can be used to recognize different categories of clothing on dressed people. The parameters of the estimated 20 body can be used to discriminatively predict 3D body shape using …",,21,3143581003261495846,,,,,Parameterized model of 2D articulated human shape,https://patents.google.com/patent/US9292967B2/en,,2016,/scholar?cites=3143581003261495846,6NjbexEAAAAJ:kuK5TVdYjLIC

1010209,"Intracortical brain-computer interfaces (iBCIs) decode intended movement from neural activity for the control of external devices such as a robotic arm. Standard approaches include a calibration phase to estimate decoding parameters. During iBCI operation, the statistical properties of the neural activity can depart from those observed during calibration, sometimes hindering a user's ability to control the iBCI. To address this problem, we adaptively correct the offset terms within a Kalman filter decoder via penalized maximum likelihood estimation. The approach can handle rapid shifts in neural signal behavior (on the order of seconds) and requires no knowledge of the intended movement. The algorithm, called multiple offset correction algorithm (MOCA), was tested using simulated neural activity and evaluated retrospectively using data collected from two people with tetraplegia operating an iBCI. In 19 clinical …",Mark L Homer and Janos A Perge and Michael J Black and Matthew T Harrison and Sydney S Cash and Leigh R Hochberg,21,989923282991761934,IEEE Transactions on Neural Systems and Rehabilitation Engineering,2,239-248,IEEE,Adaptive offset correction for intracortical brain–computer interfaces,https://ieeexplore.ieee.org/abstract/document/6651795/,22,2013,/scholar?cites=989923282991761934,6NjbexEAAAAJ:rmuvC79q63oC

1010210,"We present a probabilistic framework for component-based automatic detection and tracking of objects in video. We represent objects as spatio-temporal two-layer graphical models, where each node corresponds to an object or component of an object at a given time, and the edges correspond to learned spatial and temporal constraints. Object detection and tracking is formulated as inference over a directed loopy graph, and is solved with non-parametric belief propagation. This type of object model allows object-detection to make use of temporal consistency (over an arbitrarily sized temporal window), and facilitates robust tracking of the object. The two layer structure of the graphical model allows inference over the entire object as well as individual components. AdaBoost detectors are used to define the likelihood and form proposal distributions for components. Proposal distributions provide ‘bottom-up …",Leonid Sigal and Ying Zhu and Dorin Comaniciu and Michael Black,21,15379746983052895803,,,223-234,"Springer, Berlin, Heidelberg",Tracking complex objects using graphical object models,https://link.springer.com/chapter/10.1007/978-3-540-69866-1_17,,2004,/scholar?cites=15379746983052895803,6NjbexEAAAAJ:P5F9QuxV20EC

1010211,"In this paper, we integrate space carving and eigen detection methods to develop a bottom-up 3D human limb detector. We model the body in terms of its constituent body parts; here we focus on the head, lower arms, upper arms and calves. For each body part, we build a multi-view eigen model that combines image views from multiple calibrated cameras. This approach is much more constraining than the conventional multiple single-view eigen models and provides coarse 3D pose information. We use ideas from space carving using multiple silhouette images to constrain the volume of our search for the body part locations. We have applied the method to detect the body parts of a subject in long test sequences. The approach provides bottom-up in-formation that supports the automatic initialization of a full 3D human body model.",Sidharth Bhatia and Leonid Sigal and Michael Isard and Michael J Black,21,14640261385097211123,,,17-17,IEEE,3d human limb detection using space carving and multi-view eigen models,https://ieeexplore.ieee.org/abstract/document/1384806/,,2004,/scholar?cites=14640261385097211123,6NjbexEAAAAJ:f2IySw72cVMC

1010212,"This chapter addresses an open problem in visual motion analysis, the estimation of image motion in the vicinity of occlusion boundaries. With a Bayesian formulation, local image motion is explained in terms of multiple, competing, nonlinear models, including models for smooth (translational) motion and for motion boundaries. The generative model for motion boundaries explicitly encodes the orientation of the boundary, the velocities on either side, the motion of the occluding edge over time, and the appearance/disappearance of pixels at the boundary. We formulate the posterior probability distribution over the models and model parameters, conditioned on the image sequence. Approximate inference is achieved with a combination of tools: A Bayesian filter provides for online computation; factored sampling allows us to represent multimodal non-",David J Fleet and Michael J Black and Oscar Nestares,21,14351581157877601829,Exploring Artificial Intelligence in the New Millennium,,139,Morgan Kaufmann,Bayesian inference of visual motion boundaries,http://books.google.com/books?hl=en&lr=&id=3c9w6XEUxIMC&oi=fnd&pg=PA139&dq=info:JdZ7cAYPK8cJ:scholar.google.com&ots=ZESluzo3FJ&sig=FN68ltFRcWBYZqJOkpeGDcqD2zQ,,2003,/scholar?cites=14351581157877601829,6NjbexEAAAAJ:dfsIfKJdRG4C

1010213,"This work addresses the task of multi-person tracking in crowded street scenes, where long-term occlusions pose a major challenge. One popular way to address this challenge is to re-identify people before and after occlusions using Convolutional Neural Networks (CNNs). To achieve good performance, CNNs require a large amount of training data, which is not available for multi-person tracking scenarios. Instead of annotating large training sequences, we introduce a customized multi-person tracker that automatically adapts its person re-identification CNNs to capture the discriminative appearance patterns in a test sequence. We show that a few high-quality training examples that are automatically mined from the test sequence can be used to fine-tune pre-trained CNNs, thereby teaching them to recognize the uniqueness of people’s appearance in the test sequence. To that end, we introduce a …",Liqian Ma and Siyu Tang and Michael J Black and Luc Van Gool,20,9586045515912857183,,,612-628,"Springer, Cham",Customized multi-person tracker,https://link.springer.com/chapter/10.1007/978-3-030-20890-5_39,,2018,/scholar?cites=9586045515912857183,6NjbexEAAAAJ:kMrClmKSQGwC

1010214,"The optical flow of humans is well known to be useful for the analysis of human action. Given this, we devise an optical flow algorithm specifically for human motion and show that it is superior to generic flow methods. Designing a method by hand is impractical, so we develop a new training database of image sequences with ground truth optical flow. For this we use a 3D model of the human body and motion capture data to synthesize realistic flow fields. We then train a convolutional neural network to estimate human flow fields from pairs of images. Since many applications in human motion analysis depend on speed, and we anticipate mobile applications, we base our method on SpyNet with several modifications. We demonstrate that our trained network is more accurate than a wide range of top methods on held-out test data and that it generalizes well to real image sequences. When combined with a person detector/tracker, the approach provides a full solution to the problem of 2D human flow estimation. Both the code and the dataset are available for research.",Anurag Ranjan and Javier Romero and Michael J Black,20,5279385659963879332,arXiv preprint arXiv:1806.05666,,,,Learning Human Optical Flow,https://arxiv.org/abs/1806.05666,,2018,/scholar?cites=5279385659963879332,6NjbexEAAAAJ:9tletLqOvukC

1010215,"UNLIKE HUMAN LIMBs, TRADITIONAL, Pas-svE PRosesEs have practically no abil-ity to respond to anything but the most basic aspects of our movement intentions. In addition, traditional prostheses cannot communicate sensory information to the brain. Biohybrid limb research seeks to restore sensory and motor signals meant for natural limb function by creating an interface that provides two-way communication between the prosthetic limb and the nervous system. The goal of our research is to create a biohybrid interface that communicates directly with the ner-vous system.NeuRoworon Pnosmieses (NMPs) In the human nervous system, sen-sory and motor information are repre-sented in parterns of electrical impulses (neuronal action potentials), often called spikes. Research into these parterns has paved the way for the development of closed-loop neuromotor prostheses (NMPs), which have the potential to en-",John P Donoghue and Leigh R Hochberg and Arto V Nurmikko and Michael J Black and JD Simeral and Gerhard Friehs,20,17684006719100739885,MEDICINE AND HEALTH RHODE ISLAND,1,12,,Neuromotor prosthesis development,https://www.researchgate.net/profile/Michael_Black6/publication/6344455_Neuromotor_prosthesis_development/links/02bfe512da8042e083000000/Neuromotor-prosthesis-development.pdf,90,2007,/scholar?cites=17684006719100739885,6NjbexEAAAAJ:p2g8aNsByqUC

1010216,"We develop a Bayesian model of digitized archival films and use this for denoising, or more specifically de-graining, individual frames. In contrast to previous approaches our model uses a learned spatial prior and a unique likelihood term that models the physics that generates the image grain. The spatial prior is represented by a high-order Markov random field based on the recently proposed field-of-experts framework. We propose a new model of the image grain in archival films based on an inhomogeneous beta distribution in which the variance is a function of image luminance. We train this noise model for a particular film and perform de-graining using a diffusion method. Quantitative results show improved signal-to-noise ratio relative to the standard ad hoc Gaussian noise model.",Teodor Mihai Moldovan and Stefan Roth and Michael J Black,20,6701898177268797224,,,2641-2644,IEEE,Denoising archival films using a learned Bayesian model,https://ieeexplore.ieee.org/abstract/document/4107111/,,2006,/scholar?cites=6701898177268797224,6NjbexEAAAAJ:NhqRSupF_l8C

1010217,"This paper examines the problem of estimating surface shape from texture in situations in which there are multiple textures present due to texture discontinuities, occlusion, and pseudo-transparency (for example looking through a picket fence at a textured surface). Previous shape-from-texture methods that use changes in the spatial frequency representation of neighboring image patches assume that only a single texture is present in each of the patches. The authors extend these approaches to situations in which multiple textures may be present. The authors provide a theoretical analysis of the multiple texture problem and the effect of the texture discontinuities, occlusion, etc. on the spatial frequency representation. The authors also present an algorithm, using robust mixture models, for recovering multiple surface shapes from occluded textures. The method performs well on real and synthetic images with results …",Michael J Black and Ruth Rosenholtz,20,2865783170592006581,,,485-490,IEEE,Robust estimation of multiple surface shapes from occluded textures,https://ieeexplore.ieee.org/abstract/document/477048/,,1995,/scholar?cites=2865783170592006581,6NjbexEAAAAJ:cFHS6HbyZ2cC

1010218,"Three-dimensional human body models are widely used in the analysis of human pose and motion. Existing models, however, are learned from minimally-clothed 3D scans and thus do not generalize to the complexity of dressed people in common images and videos. Additionally, current models lack the expressive power needed to represent the complex non-linear geometry of pose-dependent clothing shapes. To address this, we learn a generative 3D mesh model of clothed people from 3D scans with varying pose and clothing. Specifically, we train a conditional Mesh-VAE-GAN to learn the clothing deformation from the SMPL body model, making clothing an additional term in SMPL. Our model is conditioned on both pose and clothing type, giving the ability to draw samples of clothing to dress different body shapes in a variety of styles and poses. To preserve wrinkle detail, our Mesh-VAE-GAN extends patchwise discriminators to 3D meshes. Our model, named CAPE, represents global shape and fine local structure, effectively extending the SMPL body model to clothing. To our knowledge, this is the first generative model that directly dresses 3D human body meshes and generalizes to different poses. The model, code and data are available for research purposes at https://cape. is. tue. mpg. de.",Qianli Ma and Jinlong Yang and Anurag Ranjan and Sergi Pujades and Gerard Pons-Moll and Siyu Tang and Michael J Black,19,1344377148672721303,,,6469-6478,,Learning to dress 3d people in generative clothing,http://openaccess.thecvf.com/content_CVPR_2020/html/Ma_Learning_to_Dress_3D_People_in_Generative_Clothing_CVPR_2020_paper.html,,2020,/scholar?cites=1344377148672721303,6NjbexEAAAAJ:5kgRglCLipYC

1010219,"We estimate 2D human pose from video using only optical flow. The key insight is that dense optical flow can provide information about 2D body pose. Like range data, flow is largely invariant to appearance but unlike depth it can be directly computed from monocular video. We demonstrate that body parts can be detected from dense flow using the same random forest approach used by the Microsoft Kinect. Unlike range data, however, when people stop moving, there is no optical flow and they effectively disappear. To address this, our FlowCap method uses a Kalman filter to propagate body part positions and velocities over time and a regression method to predict 2D body pose from part centers. No range sensor is required and FlowCap estimates 2D human pose from monocular video sources containing human motion. Such sources include hand-held phone cameras and archival television video. We …",Javier Romero and Matthew Loper and Michael J Black,19,9534829611401416593,,,412-423,"Springer, Cham",FlowCap: 2D human pose from optical flow,https://link.springer.com/chapter/10.1007/978-3-319-24947-6_34,,2015,/scholar?cites=9534829611401416593,6NjbexEAAAAJ:z5I2ou_Dk_MC

1010220,"Relations between anisotropic diffusion and robust statistics are described in this paper. We show that anisotropic diffusion can be seen as a robust estimation procedure that estimates a piecewise smooth image from a noisy input image. The “edge-stopping” function in the anisotropic diffusion equation is closely related to the error norm and influence function in the robust estimation framework. This connection leads to a new “edge-stopping” function based on Tukey's biweight robust estimator, that preserves sharper boundaries than previous formulations and improves the automatic stopping of the diffusion. The robust statistical interpretation also provides a means for detecting the boundaries (edges) between the piecewise smooth regions in the image. Finally, connections between robust estimation and line processing provide a framework to introduce spatial coherence in anisotropic diffusion flows.",Michael J Black and Guillermo Sapiro and David Marimont and David Heeger,17,13913523606131029163,,,323-326,"Springer, Berlin, Heidelberg","Robust anisotropic diffusion: Connections between robust statistics, line processing, and anisotropic diffusion",https://link.springer.com/chapter/10.1007/3-540-63167-4_63,,1997,/scholar?cites=13913523606131029163,6NjbexEAAAAJ:bFI3QPDXJZMC

1010221,"We consider the estimation of local grey-level image structure in terms of a layered representation. This type of representation has recently been successfully used to segment various objects from clutter using either optical ow or stereo disparity information. We argue that the same type of representation is useful for grey-level data in that it allows for the estimation of properties for each of several di erent components without prior segmentation. Our emphasis in this paper is on the process used to extract such a layered representation from a given image. In particular, we consider a variant of the EM-algorithm for the estimation of the layered model, and consider a novel technique for choosing the number of layers to use. We brie y consider the use of a simple version of this approach for image segmentation, and suggest two potential applications to the ARK project.Category: Image representation.",Allan Jepson and Michael Black,17,1935206817499363356,"PRECARN ARK Project Technical Report ARK96-PUB-54, University of Toronto, Toronto, Ontario, Canda",,,,Mixture models for image representation,http://cs.brown.edu/people/mjblack/Papers/mixImage.pdf,,1996,/scholar?cites=1935206817499363356,6NjbexEAAAAJ:D03iK_w7-QYC

1010222,"Susceptibility of deep neural networks to adversarial attacks poses a major theoretical and practical challenge. All efforts to harden classifiers against such attacks have seen limited success till now. Two distinct categories of samples against which deep neural networks are vulnerable,“adversarial samples” and “fooling samples”, have been tackled separately so far due to the difficulty posed when considered together. In this work, we show how one can defend against them both under a unified framework. Our model has the form of a variational autoencoder with a Gaussian mixture prior on the latent variable, such that each mixture component corresponds to a single class. We show how selective classification can be performed using this model, thereby causing the adversarial objective to entail a conflict. The proposed method leads to the rejection of adversarial samples instead of misclassification, while maintaining high precision and recall on test data. It also inherently provides a way of learning a selective classifier in a semi-supervised scenario, which can similarly resist adversarial attacks. We further show how one can reclassify the detected adversarial samples by iterative optimization. 1",Partha Ghosh and Arpan Losalka and Michael J Black,16,16277125668592564494,Proceedings of the AAAI Conference on Artificial Intelligence,,541-548,,Resisting adversarial attacks using gaussian mixture variational autoencoders,https://www.aaai.org/ojs/index.php/AAAI/article/view/3828,33,2019,/scholar?cites=16277125668592564494,6NjbexEAAAAJ:rzkGdFpNPO0C

1010223,"Creating metrically accurate avatars is important for many applications such as virtual clothing try-on, ergonomics, medicine, immersive social media, telepresence, and gaming. Creating avatars that precisely represent a particular individual is challenging however, due to the need for expensive 3D scanners, privacy issues with photographs or videos, and difficulty in making accurate tailoring measurements. We overcome these challenges by creating “The Virtual Caliper”, which uses VR game controllers to make simple measurements. First, we establish what body measurements users can reliably make on their own body. We find several distance measurements to be good candidates and then verify that these are linearly related to 3D body shape as represented by the SMPL body model. The Virtual Caliper enables novice users to accurately measure themselves and create an avatar with their own body shape …",Sergi Pujades and Betty Mohler and Anne Thaler and Joachim Tesch and Naureen Mahmood and Nikolas Hesse and Heinrich H Bülthoff and Michael J Black,16,5005715893805066535,IEEE transactions on visualization and computer graphics,5,1887-1897,IEEE,The virtual caliper: Rapid creation of metrically accurate avatars from 3D measurements,https://ieeexplore.ieee.org/abstract/document/8648222/,25,2019,/scholar?cites=5005715893805066535,6NjbexEAAAAJ:Y3Sh7dCAXz0C

1010224,"Present application refers to a method, a model generation unit and a computer program (product) for generating trained models (M) of moving persons, based on physically measured person scan data (S). The approach is based on a common template (T) for the respective person and on the measured person scan data (S) in different shapes and different poses. Scan data are measured with a 3D laser scanner. A generic personal model is used for co-registering a set of person scan data (S) aligning the template (T) to the set of person scans (S) while simultaneously training the generic personal model to become a trained person model (M) by constraining the generic person model to be scan-specific, person-specific and pose-specific and providing the trained model (M), based on the co registering of the measured object scan data (S).",,16,10479317930439557496,,,,,Co-registration—simultaneous alignment and modeling of articulated 3D shapes,https://patents.google.com/patent/US9898848B2/en,,2018,/scholar?cites=10479317930439557496,6NjbexEAAAAJ:uSZH581ylUkC

1010225,"Kalman filtering is a common method to decode neural signals from the motor cortex. In clinical research investigating the use of intracortical brain computer interfaces (iBCIs), the technique enabled people with tetraplegia to control assistive devices such as a computer or robotic arm directly from their neural activity. For reaching movements, the Kalman filter typically estimates the instantaneous endpoint velocity of the control device. Here, we analyzed attempted arm/hand movements by people with tetraplegia to control a cursor on a computer screen to reach several circular targets. A standard velocity Kalman filter is enhanced to additionally decode for the cursor's position. We then mix decoded velocity and position to generate cursor movement commands. We analyzed data, offline, from two participants across six sessions. Root mean squared error between the actual and estimated cursor trajectory improved …",Mark L Homer and Matthew T Harrison and Michael J Black and János A Perge and Sydney S Cash and Gerhard Friehs and Leigh R Hochberg,16,15083346792010473805,,,715-718,IEEE,Mixing decoded cursor velocity and position from an offline Kalman filter improves cursor control in people with tetraplegia,https://ieeexplore.ieee.org/abstract/document/6696034/,,2013,/scholar?cites=15083346792010473805,6NjbexEAAAAJ:_axFR9aDTf0C

1010226,"The statistical analysis of large corpora of human body scans requires that these scans be in alignment, either for a small set of key landmarks or densely for all the vertices in the scan. Existing techniques tend to rely on hand-placed landmarks or algorithms that extract landmarks from scans. The former is time consuming and subjective while the latter is error prone. Here we show that a model-based approach can align meshes automatically, producing alignment accuracy similar to that of previous methods that rely on many landmarks. Specifically, we align a low-resolution, artistcreated template body mesh to many high-resolution laser scans. Our alignment procedure employs a robust iterative closest point method with a regularization that promotes smooth and locally rigid deformation of the template mesh. We evaluate our approach on 50 female body models from the CAESAR dataset that vary significantly in body shape. To make the method fully automatic, we define simple feature detectors for the head and ankles, which provide initial landmark locations. We find that, if body poses are fairly similar, as in CAESAR, the fully automated method provides dense alignments that enable statistical analysis and anthropometric measurement.",David A Hirshberg and Matthew Loper and Eric Rachlin and Aggeliki Tsoli and Alexander Weiss and B Corner and MJ Black,16,15266748426618217027,2nd International Conference on 3D Body Scanning Technologies,,76-85,Hometrica Consulting,Evaluating the automated alignment of 3D human body scans,https://www.3dbodyscanning.org/cap/papers/2011/11076_26hirshberg.pdf,,2011,/scholar?cites=15266748426618217027,6NjbexEAAAAJ:h-U6AArFrx8C

1010227,"This study uses novel biometric figure rating scales (FRS) spanning body mass index (BMI) 13.8 to 32.2 kg/m2 and BMI 18 to 42 kg/m2. The aims of the study were (i) to compare FRS body weight dissatisfaction and perceptual distortion of women with anorexia nervosa (AN) to a community sample; (ii) how FRS parameters are associated with questionnaire body dissatisfaction, eating disorder symptoms and appearance comparison habits; and (iii) whether the weight spectrum of the FRS matters. Women with AN (n = 24) and a community sample of women (n = 104) selected their current and ideal body on the FRS and completed additional questionnaires. Women with AN accurately picked the body that aligned best with their actual weight in both FRS. Controls underestimated their BMI in the FRS 14–32 and were accurate in the FRS 18–42. In both FRS, women with AN desired a body close to their actual …",Simone C Mölbert and Anne Thaler and Stephan Streuber and Michael J Black and Hans‐Otto Karnath and Stephan Zipfel and Betty Mohler and Katrin E Giel,15,13858077995114073625,European Eating Disorders Review,6,607-612,,Investigating body image disturbance in anorexia nervosa using novel biometric figure rating scales: a pilot study,https://onlinelibrary.wiley.com/doi/abs/10.1002/erv.2559,25,2017,/scholar?cites=13858077995114073625,6NjbexEAAAAJ:K9zgXSuleLYC

1010228,"Relations between anisotropic diffusion and robust statistics are described. We show that anisotropic diffusion can be seen as a robust estimation procedure that estimates a piecewise smooth image from a noisy input image. The ""edge-stopping"" function in the anisotropic diffusion equation is closely related to the error norm and influence function in the robust estimation framework. This connection leads to a new ""edge-stopping"" function based on Tukey's biweight robust estimator, that preserves sharper boundaries than previous formulations and improves the automatic stopping of the diffusion. The robust statistical interpretation also provides a means for detecting the boundaries (edges) between the piecewise smooth regions in the image. We extend the framework to vector-valued images and show applications to robust image sharpening.",Michael Black and Guillermo Sapiro and David Marimont and David Heeger,15,17495353956809454040,,,263-266,IEEE,Robust anisotropic diffusion and sharpening of scalar and vector images,https://ieeexplore.ieee.org/abstract/document/647755/,1,1997,/scholar?cites=17495353956809454040,6NjbexEAAAAJ:xtRiw3GOFMkC

1010229,,Shannon X Ju and J Michael,15,9550137696943684352,Intl. Conf. Automatic Face and Gesture Recognition,,38-44,,"Black, and Yaser Yacoob. Cardboard people: A parameterized model of articulated image motion",http://scholar.google.com/scholar?cluster=9550137696943684352&hl=en&oi=scholarr,,,/scholar?cites=9550137696943684352,6NjbexEAAAAJ:jtusTj6o6osC

1010230,"Statistical models of the human body surface are generally learned from thousands of high-quality 3D scans in predefined poses to cover the wide variety of human body shapes and articulations. Acquisition of such data requires expensive equipment, calibration procedures, and is limited to cooperative subjects who can understand and follow instructions, such as adults. We present a method for learning a statistical 3D Skinned Multi-Infant Linear body model (SMIL) from incomplete, low-quality RGB-D sequences of freely moving infants. Quantitative experiments show that SMIL faithfully represents the RGB-D data and properly factorizes the shape and pose of the infants. To demonstrate the applicability of SMIL, we fit the model to RGB-D sequences of freely moving infants and show, with a case study, that our method captures enough motion detail for General Movements Assessment (GMA), a method used in …",Nikolas Hesse and Sergi Pujades and Michael Black and Michael Arens and Ulrich Hofmann and Sebastian Schroeder,14,8448671688133636202,IEEE transactions on pattern analysis and machine intelligence,,,IEEE,Learning and tracking the 3D body shape of freely moving infants from RGB-D sequences,https://ieeexplore.ieee.org/abstract/document/8732396/,,2019,/scholar?cites=8448671688133636202,6NjbexEAAAAJ:_TIfIljC7OAC

1010231,"Brief verbal descriptions of people’s bodies (e.g., “curvy,” “long-legged”) can elicit vivid mental images. The ease with which these mental images are created belies the complexity of three-dimensional body shapes. We explored the relationship between body shapes and body descriptions and showed that a small number of words can be used to generate categorically accurate representations of three-dimensional bodies. The dimensions of body-shape variation that emerged in a language-based similarity space were related to major dimensions of variation computed directly from three-dimensional laser scans of 2,094 bodies. This relationship allowed us to generate three-dimensional models of people in the shape space using only their coordinates on analogous dimensions in the language-based description space. Human descriptions of photographed bodies and their corresponding models matched closely …",Matthew Q Hill and Stephan Streuber and Carina A Hahn and Michael J Black and Alice J O’Toole,14,9878985667873371010,Psychological science,11,1486-1497,SAGE Publications,Creating body shapes from verbal descriptions by linking similarity spaces,https://journals.sagepub.com/doi/abs/10.1177/0956797616663878,27,2016,/scholar?cites=9878985667873371010,6NjbexEAAAAJ:VGxY11nYJJYC

1010232,"Advances in 3D scanning technology allow us to create realistic virtual avatars from full body 3D scan data. However, negative reactions to some realistic computer generated humans suggest that this approach might not always provide the most appealing results. Using styles derived from existing popular character designs, we present a novel automatic stylization technique for body shape and colour information based on a statistical 3D model of human bodies. We investigate whether such stylized body shapes result in increased perceived appeal with two different experiments: One focuses on body shape alone, the other investigates the additional role of surface colour and lighting. Our results consistently show that the most appealing avatar is a partially stylized one. Importantly, avatars with high stylization or no stylization at all were rated to have the least appeal. The inclusion of colour information and …",Reuben Fleming and Betty J Mohler and Javier Romero and Michael J Black and Martin Breidt,13,667672549444981890,,,335-345,Scitepress,Appealing female avatars from 3D body scans: Perceptual effects of stylization,https://www.scitepress.org/Papers/2016/56839/,2,2016,/scholar?cites=667672549444981890,6NjbexEAAAAJ:4IpgxnMJogoC

1010233,The recognition of human gestures and facial expressions in image sequences is an important and challenging problem that enables a host of human-computer interaction applications. This paper describes a framework forincremental recognition of human motion that extends the,Michael J Black and Allan D Jepson,13,9418400728731119919,Proc. ICCV,,176-181,,A probabilistic framework for matching temporal trajectories,http://scholar.google.com/scholar?cluster=9418400728731119919&hl=en&oi=scholarr,,1999,/scholar?cites=9418400728731119919,6NjbexEAAAAJ:sYWh8IhQ1GMC

1010234,"Neural control of movement is typically studied in constrained environments where there is a reduced set of possible behaviors. This constraint may unintentionally limit the applicability of findings to the generalized case of unconstrained behavior. We hypothesize that examining the unconstrained state across multiple behavioral contexts will lead to new insights into the neural control of movement and help advance the design of neural prosthetic decode algorithms. However, to pursue electrophysiological studies in such a manner requires a more flexible framework for experimentation. We propose that head-mounted neural recording systems with wireless data transmission, combined with markerless computer-vision based motion tracking, will enable new, less constrained experiments. As a proof-of-concept, we recorded and wirelessly transmitted broadband neural data from 32 electrodes in premotor cortex …",Justin D Foster and Oren Freifeld and Paul Nuyujukian and Stephen I Ryu and Michael J Black and Krishna V Shenoy,12,7561995482368442770,,,613-616,IEEE,Combining wireless neural recording and video capture for the analysis of natural gait,https://ieeexplore.ieee.org/abstract/document/5910623/,,2011,/scholar?cites=7561995482368442770,6NjbexEAAAAJ:VOx2b1Wkg3QC

1010235,"Probabilistic modeling of correlated neural population firing activity is central to understanding the neural code and building practical decoding algorithms. No parametric models currently exist for modeling multivariate correlated neural data and the high dimensional nature of the data makes fully non-parametric methods impractical. To address these problems we propose an energy-based model in which the joint probability of neural activity is represented using learned functions of the 1D marginal histograms of the data. The parameters of the model are learned using contrastive divergence and an optimization procedure for finding appropriate marginal directions. We evaluate the method using real data recorded from a population of motor cortical neurons. In particular, we model the joint probability of population spiking times and 2D hand position and show that the likelihood of test data under our model is significantly higher than under other models. These results suggest that our model captures correlations in the firing activity. Our rich probabilistic model of neural population activity is a step towards both measurement of the importance of correlations in neural coding and improved decoding of population activity.",Frank Wood and Stefan Roth and Michael J Black,12,761147180762808925,,,1537-1544,,Modeling neural population spiking activity with Gibbs distributions,https://papers.nips.cc/paper/2776-modeling-neural-population-spiking-activity-with-gibbs-distributions.pdf,,2006,/scholar?cites=761147180762808925,6NjbexEAAAAJ:KxtntwgDAa4C

1010236,"We investigated the influence of body shape and pose on the perception of physical strength and social power for male virtual characters. In the first experiment, participants judged the physical strength of varying body shapes, derived from a statistical 3D body model. Based on these ratings, we determined three body shapes (weak, average, and strong) and animated them with a set of power poses for the second experiment. Participants rated how strong or powerful they perceived virtual characters of varying body shapes that were displayed in different poses. Our results show that perception of physical strength was mainly driven by the shape of the body. However, the social attribute of power was influenced by an interaction between pose and shape. Specifically, the effect of pose on power ratings was greater for weak body shapes. These results demonstrate that a character with a weak shape can be …",Anna C Wellerdiek and Martin Breidt and Michael N Geuss and Stephan Streuber and Uwe Kloos and Michael J Black and Betty J Mohler,11,1061896746333784054,,,7-14,,Perception of strength and power of realistic male characters,https://dl.acm.org/doi/abs/10.1145/2804408.2804413,,2015,/scholar?cites=1061896746333784054,6NjbexEAAAAJ:k4O5U3vRA4YC

1010237,"Faces and bodies are complex structures, perception of which can play important roles in person identification and inference of emotional state. Face representations have been explored using behavioural adaptation: in particular, studies have shown that face aftereffects show relatively broad tuning for viewpoint, consistent with origin in a high-level structural descriptor far removed from the retinal image. Our goals were to determine first, if body aftereffects also showed a degree of viewpoint invariance, and second if they also showed pose invariance, given that changes in pose create even more dramatic changes in the 2-D retinal image. We used a 3-D model of the human body to generate headless body images, whose parameters could be varied to generate different body forms, viewpoints, and poses. In the first experiment, subjects adapted to varying viewpoints of either slim or heavy bodies in a neutral …",Alla Sekunova and Michael Black and Laura Parkinson and Jason JS Barton,11,14102152624128559296,Perception,2,176-186,SAGE Publications,Viewpoint and pose in body-form adaptation,https://journals.sagepub.com/doi/abs/10.1068/p7265,42,2013,/scholar?cites=14102152624128559296,6NjbexEAAAAJ:kz9GbA2Ns4gC

1010238,"We greatly appreciate the time and thought the authors of the replies have put into their commentaries on our paper [1–9]. We are concerned, however, that there has been some misinterpretation of our goals. We emphasize that we are attempting to represent a conservative position on the study of vision. It is not that we believe that current and past paradigms are ideal and should be maintained to the exclusion of all other approaches, but rather that we feel that the goal of reconstruction and scene recovery is viable and should not be completely abandoned. We claim this with full knowledge of the fact that these and related terms, most notably “general vision,” cannot be defined precisely at present (despite the best efforts of 13, 9])–a fact that advocates of the purposive paradigm have used as a justification for a radical departure from the current paradigm. Perhaps our concern in this regard is unwarranted, thereby …",Michael J Tarr and Michael J Black,11,7690986669126078095,CVGIP IMAGE UNDERSTANDING,,113-113,Academic Press,Reconstruction and purpose,http://128.148.32.110/people/mjblack/Papers/cviu.60.1.1994b.pdf,60,1994,/scholar?cites=7690986669126078095,6NjbexEAAAAJ:lX_RDcPAamoC

1010239,"We present a fully automatic system that takes a 3D scene and generates plausible 3D human bodies that are posed naturally in that 3D scene. Given a 3D scene without people, humans can easily imagine how people could interact with the scene and the objects in it. However, this is a challenging task for a computer as solving it requires that (1) the generated human bodies to be semantically plausible within the 3D environment (eg people sitting on the sofa or cooking near the stove), and (2) the generated human-scene interaction to be physically feasible such that the human body and scene do not interpenetrate while, at the same time, body-scene contact supports physical interactions. To that end, we make use of the surface-based 3D human model SMPL-X. We first train a conditional variational autoencoder to predict semantically plausible 3D human poses conditioned on latent scene representations, then we further refine the generated 3D bodies using scene constraints to enforce feasible physical interaction. We show that our approach is able to synthesize realistic and expressive 3D human bodies that naturally interact with 3D environment. We perform extensive experiments demonstrating that our generative framework compares favorably with existing methods, both qualitatively and quantitatively. We believe that our scene-conditioned 3D human generation pipeline will be useful for numerous applications; eg to generate training data for human pose estimation, in video games and in VR/AR. Our project page for data and code can be seen at: https://vlg. inf. ethz. ch/projects/PSI/.",Yan Zhang and Mohamed Hassan and Heiko Neumann and Michael J Black and Siyu Tang,10,18186734789872425495,,,6194-6204,,Generating 3D People in Scenes without People,http://openaccess.thecvf.com/content_CVPR_2020/html/Zhang_Generating_3D_People_in_Scenes_Without_People_CVPR_2020_paper.html,,2020,/scholar?cites=18186734789872425495,6NjbexEAAAAJ:EUsVPkoNztoC

1010240,"In this work, we consider the problem of decentralized multi-robot target tracking and obstacle avoidance in dynamic environments. Each robot executes a local motion planning algorithm which is based on model predictive control (MPC). The planner is designed as a quadratic program, subject to constraints on robot dynamics and obstacle avoidance. Repulsive potential field functions are employed to avoid obstacles. The novelty of our approach lies in embedding these non-linear potential field functions as constraints within a convex optimization framework. Our method convexifies nonconvex constraints and dependencies, by replacing them as pre-computed external input forces in robot dynamics. The proposed algorithm additionally incorporates different methods to avoid field local minima problems associated with using potential field functions in planning. The motion planner does not enforce predefined …",Rahul Tallamraju and Sujit Rajappa and Michael J Black and Kamalakar Karlapalem and Aamir Ahmad,10,4017894980225004667,,,1-8,IEEE,Decentralized mpc based obstacle avoidance for multi-robot target tracking scenarios,https://ieeexplore.ieee.org/abstract/document/8468655/,,2018,/scholar?cites=4017894980225004667,6NjbexEAAAAJ:2PBQaVm3t-0C

1010241,"Two research communities, motor systems neuroscience and motor prosthetics, examine the relationship between neural activity in the motor cortex and movement. The former community aims to understand how the brain controls and generates movement; the latter community focuses on how to decode neural activity as control signals for a prosthetic cursor or limb. Both have made progress toward understanding the relationship between neural activity in the motor cortex and behavior. However, these findings are tested using animal models in an environment that constrains behavior to simple, limited movements. These experiments show that, in constrained settings, simple reaching motions can be decoded from small populations of spiking neurons. It is unclear whether these findings hold for more complex, full-body behaviors in unconstrained settings. Here we present the results of freely-moving behavioral …",Justin D Foster and Paul Nuyujukian and Oren Freifeld and Stephen I Ryu and Michael J Black and Krishna V Shenoy,10,3012407679040105365,,,2736-2739,IEEE,A framework for relating neural activity to freely moving behavior,https://ieeexplore.ieee.org/abstract/document/6346530/,,2012,/scholar?cites=3012407679040105365,6NjbexEAAAAJ:35r97b3x0nAC

1010242,"The traditional goal of computer vision, to reconstruct, or recover properties of, the scene has recently been challenged by advocates of a new purposive approach in which the vision problem is defined in terms of the goals of an active agent. In the starkest light the debate can be characterized as one about the role of explicit representations. The extreme traditionalists strive for a detailed representation of the 3D world while the other extreme adopts a strict behaviorist stance which eschews representations in favor of “direct sensing.” This panel will explore the roles of action, representation, and purpose in computer vision and, in doing so, will hopefully discover areas of agreement.",Michael J Black and J Aloimonos and Christopher M Brown and Ian Horswill and Jitendra Malik and Giulio Sandini and Michael J Tarr,10,3283312854655338642,,,1661-1666,,"Action, Representation and Purpose: Re-evaluating the Foundations of Computational Vision",http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.9833&rep=rep1&type=pdf,,1993,/scholar?cites=3283312854655338642,6NjbexEAAAAJ:uWQEDVKXjbEC

1010243,,Alexandru OBalan and J Michael,10,14476797030573163029,European Conf. on Computer Vision,,15-29,,Black. The naked truth: Estimating body shape under clothing,http://scholar.google.com/scholar?cluster=14476797030573163029&hl=en&oi=scholarr,,,/scholar?cites=14476797030573163029,6NjbexEAAAAJ:KOc9rAu6-V4C

1010244,"We present a novel robotic front-end for autonomous aerial motion-capture (mocap) in outdoor environments. In previous work, we presented an approach for cooperative detection and tracking (CDT) of a subject using multiple micro-aerial vehicles (MAVs). However, it did not ensure optimal view-point configurations of the MAVs to minimize the uncertainty in the person's cooperatively tracked 3D position estimate. In this article, we introduce an active approach for CDT. In contrast to cooperatively tracking only the 3D positions of the person, the MAVs can actively compute optimal local motion plans, resulting in optimal view-point configurations, which minimize the uncertainty in the tracked estimate. We achieve this by decoupling the goal of active tracking into a quadratic objective and non-convex constraints corresponding to angular configurations of the MAVs w.r.t. the person. We derive this decoupling using …",Rahul Tallamraju and Eric Price and Roman Ludwig and Kamalakar Karlapalem and Heinrich H Bülthoff and Michael J Black and Aamir Ahmad,9,14213190838685855332,IEEE Robotics and Automation Letters,4,4491-4498,IEEE,Active perception based formation control for multiple aerial vehicles,https://ieeexplore.ieee.org/abstract/document/8784232/,4,2019,/scholar?cites=14213190838685855332,6NjbexEAAAAJ:0kxB6oEY0CcC

1010245,"The creation or streaming of photo-realistic self-avatars is important for virtual reality applications that aim for perception and action to replicate real world experience. The appearance and recognition of a digital self-avatar may be especially important for applications related to telepresence, embodied virtual reality, or immersive games. We investigated gender differences in the use of visual cues (shape, texture) of a self-avatar for estimating body weight and evaluating avatar appearance. A full-body scanner was used to capture each participant's body geometry and color information and a set of 3D virtual avatars with realistic weight variations was created based on a statistical body model. Additionally, a second set of avatars was created with an average underlying body shape matched to each participant’s height and weight. In four sets of psychophysical experiments, the influence of visual cues on the accuracy of body weight estimation and the sensitivity to weight changes was assessed by manipulating body shape (own, average) and texture (own photo-realistic, checkerboard). The avatars were presented on a large-screen display, and participants responded to whether the avatar's weight corresponded to their own weight. Participants also adjusted the avatar's weight to their desired weight and evaluated the avatar's appearance with regard to similarity to their own body, uncanniness, and their willingness to accept it as a digital representation of the self. The results of the psychophysical experiments revealed no gender difference in the accuracy of estimating body weight in avatars. However, males accepted a larger weight range of the …",Anne Thaler and Ivelina Piryankova and Jeanine K Stefanucci and Sergi Pujades and Stephan de La Rosa and Stephan Streuber and Javier Romero and Michael J Black and Betty J Mohler,9,1049398172128897090,Frontiers in ICT,,18,Frontiers,Visual perception and evaluation of photo-realistic self-avatars from 3D body scans in males and Females,https://www.frontiersin.org/articles/10.3389/fict.2018.00018/full,5,2018,/scholar?cites=1049398172128897090,6NjbexEAAAAJ:l1jknz_x7mgC

1010246,"Results▪ Single motion pattern with either diffuse (only dots) or specular reflection (dots or lines) visible▪ 10 random convex trials per stimulus and subject, 10 random concave trials, 8 subjects overall",Stefan Roth and Fulvio Domini and Michael J Black,9,9934556963427903995,Journal of Vision,9,413a,The Association for Research in Vision and Ophthalmology,Specular flow and the perception of surface reflectance,https://www.researchgate.net/profile/Michael_Black6/publication/2479458_Specular_Flow_And_The_Perception_Of_Surface_Reflectance/links/09e4151389d4fc39a4000000/Specular-Flow-And-The-Perception-Of-Surface-Reflectance.pdf,3,2003,/scholar?cites=9934556963427903995,6NjbexEAAAAJ:WbkHhVStYXYC

1010247,"Capturing human motion in natural scenarios means moving motion capture out of the lab and into the wild. Typical approaches rely on fixed, calibrated, cameras and reflective markers on the body, significantly limiting the motions that can be captured. To make motion capture truly unconstrained, we describe the first fully autonomous outdoor capture system based on flying vehicles. We use multiple micro-aerial-vehicles (MAVs), each equipped with a monocular RGB camera, an IMU, and a GPS receiver module. These detect the person, optimize their position, and localize themselves approximately. We then develop a markerless motion capture method that is suitable for this challenging scenario with a distant subject, viewed from above, with approximately calibrated and moving cameras. We combine multiple state-of-the-art 2D joint detectors with a 3D human body model and a powerful prior on human pose. We jointly optimize for 3D body pose and camera pose to robustly fit the 2D measurements. To our knowledge, this is the first successful demonstration of outdoor, full-body, markerless motion capture from autonomous flying vehicles.",Nitin Saini and Eric Price and Rahul Tallamraju and Raffi Enficiaud and Roman Ludwig and Igor Martinovic and Aamir Ahmad and Michael J Black,8,13874252158600295905,,,823-832,,Markerless outdoor human motion capture using multiple autonomous micro aerial vehicles,http://openaccess.thecvf.com/content_ICCV_2019/html/Saini_Markerless_Outdoor_Human_Motion_Capture_Using_Multiple_Autonomous_Micro_Aerial_ICCV_2019_paper.html,,2019,/scholar?cites=13874252158600295905,6NjbexEAAAAJ:S9ByAo1SvpUC

1010248,"The quantification of adipose tissue can give insights into obesity and the associated diseases. The segmentation of this tissue is however difficult, particularly due to the complex geometry and the local appearance similarities between the subcutaneous and visceral types. Shape priors can be used to regularise the segmentation of geometries with small variation in shape. However, human bodies are articulated and substantially different across subjects. In this paper, a novel method is proposed for the segmentation of the subcutaneous fat layer in full-body magnetic resonance imaging scans. The proposed method is based on a statistical shape model of the whole body surface, which is learned from geometric scans. The body model is factorised into pose and shape deformations, which allows a compact parametrisation of large variations in human shape. The proposed method is applied in the segmentation of …",SY Yeo and J Romero and M Loper and J Machann and M Black,8,796213047566385095,Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization,1,51-58,Taylor & Francis,Shape estimation of subcutaneous adipose tissue using an articulated statistical shape model,https://www.tandfonline.com/doi/abs/10.1080/21681163.2016.1163508,6,2018,/scholar?cites=796213047566385095,6NjbexEAAAAJ:N75c7piKpcAC

1010249,"Detection of new or rapidly evolving melanocytic lesions is crucial for early diagnosis and treatment of melanoma. We propose a fully automated pre-screening system for detecting new lesions or changes in existing ones, on the order of 2 − 3mm, over almost the entire body surface. Our solution is based on a multi-camera 3D stereo system. The system captures 3D textured scans of a subject at different times and then brings these scans into correspondence by aligning them with a learned, parametric, non-rigid 3D body model. This means that captured skin textures are in accurate alignment across scans, facilitating the detection of new or changing lesions. The integration of lesion segmentation with a deformable 3D body model is a key contribution that makes our approach robust to changes in illumination and subject pose.",Federica Bogo and Javier Romero and Enoch Peserico and Michael J Black,8,13176560057932025171,,,593-600,"Springer, Cham",Automated detection of new or evolving melanocytic lesions using a 3D body model,https://link.springer.com/chapter/10.1007/978-3-319-10404-1_74,,2014,/scholar?cites=13176560057932025171,6NjbexEAAAAJ:SSsxPzPPytkC

1010250,"This Technical Report contains the supplemental material to the main report on the MPI-Sintel optical flow dataset and evaluation [1]. In particular, we provide details of the image and optical flow statistics that are mentioned in the main paper. Additionally we provide details of the initial evaluation of optical flow algorithm performance on the dataset. Additional details and the dataset itself can be found on the MPI-Sintel website: http://sintel. is. tue. mpg. de",D Butler and Jonas Wulff and G Stanley and M Black,8,3173061179144879950,,,,,MPI-Sintel optical flow benchmark: Supplemental material,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.458.391&rep=rep1&type=pdf,,2012,/scholar?cites=3173061179144879950,6NjbexEAAAAJ:tYavs44e6CUC

1010251,"We develop an autoregressive moving average (ARMA) model for decoding hand motion from neural firing data and provide a simple method for estimating the parameters of the model. Results show that this method produces more accurate reconstructions of hand position than the previous Kalman filter and linear regression methods. The ARMA model combines the best properties of both these methods, producing reconstructed hand trajectories that are smooth and accurate. This simple technique is computationally efficient making it appropriate for real-time prosthetic control tasks",Jessica Fisher and Michael J Black,8,15274824354832300984,,,2130-2133,IEEE,Motor cortical decoding using an autoregressive moving average model,https://ieeexplore.ieee.org/abstract/document/1616881/,,2006,/scholar?cites=15274824354832300984,6NjbexEAAAAJ:K3LRdlH-MEoC

1010252,"This paper presents a simple, robust, gradient-based, approach to computing optical flow in the presence of noise and motion discontinuities. We begin with the standard gradient-based method of Horn and Schunck which corresponds to a least-squares estimate of the optical flow. Such estimates are susceptible to outliers which do not conform the statistical assumptions of the approach; for example, measurements at motion discontinuities. The result is that the least-squares solution has the undesirable property of smoothing the flow field across motion boundaries. Robust statistics can be used to address this problem. By reformulating the optical flow equation in terms of robust estimation, the problems of image noise and over-smoothing are reduced. The reformulation is straightforward, and results in a remarkable improvement in the estimated flow, particularly at motion discontinuities. The flow field is recovered …",Michael J Black,8,5933053211410367883,"IEEE Conference on Computer Vision and Pattern Recognition, Champagne-Urbana",,,,A robust gradient method for determining optical flow,http://www.cs.yale.edu/publications/techreports/tr891.pdf,,1992,/scholar?cites=5933053211410367883,6NjbexEAAAAJ:abG-DnoFyZgC

1010253,"Among the currently available grasp-type selection techniques for hand prostheses, there is a distinct lack of intuitive, robust, low-latency solutions. In this paper we investigate the use of a portable, forearm-mounted, video-based technique for the prediction of hand-grasp preshaping for arbitrary objects. The purpose of this system is to automatically select the grasp-type for the user of the prosthesis, potentially increasing ease-of-use and functionality. This system can be used to supplement and improve existing control strategies, such as surface electromyography (sEMG) pattern recognition, for prosthetic and orthotic devices. We designed and created a suitable dataset consisting of RGB-D video data for 2212 grasp examples split evenly across 7 classes; 6 grasps commonly used in activities of daily living, and an additional no-grasp category. We processed and analyzed the dataset using several state-of-the-art …",Luke T Taverne and Matteo Cognolato and Tobias Bützer and Roger Gassert and Otmar Hilliges,7,8487262658362736481,,,4975-4982,IEEE,Video-based Prediction of Hand-grasp Preshaping with Application to Prosthesis Control,https://ieeexplore.ieee.org/abstract/document/8794175/,,2019,/scholar?cites=8487262658362736481,6NjbexEAAAAJ:A_xf8jiGkywC

1010254,"A method for providing a three-dimensional body model which may be applied for an animation, based on a moving body, wherein the method comprises providing a parametric three-dimensional body model, which allows shape and pose variations; applying a standard set of body markers; optimizing the set of body markers by generating an additional set of body markers and applying the same for providing 3D coordinate marker signals for capturing shape and pose of the body and dynamics of soft tissue; and automatically providing an animation by processing the 3D coordinate marker signals in order to provide a personalized three-dimensional body model, based on estimated shape and an estimated pose of the body by means of predicted marker locations.",,7,1758873192953462641,,,,,Method for providing a three dimensional body model,https://patents.google.com/patent/US9710964B2/en,,2017,/scholar?cites=1758873192953462641,6NjbexEAAAAJ:9kZNi-u_WhAC

1010255,"This chapter discusses the needs for standard datasets in the articulated pose estimation and tracking communities. It describes the datasets that are currently available and the performance of state-of-the-art methods on them. We discuss issues of ground-truth collection and quality, complexity of appearance and poses, evaluation metrics and partitioning of data. We also discusses limitations of current datasets and possible directions in developing new datasets for future use.",Mykhaylo Andriluka and Leonid Sigal and Michael J Black,7,17899622315532990060,,,253-275,"Springer, London",Benchmark datasets for pose estimation and tracking,https://link.springer.com/chapter/10.1007/978-0-85729-997-0_13,,2011,/scholar?cites=17899622315532990060,6NjbexEAAAAJ:UHK10RUVsp4C

1010256,"In this paper we develop an incremental estimation algorithm for infinite mixtures of Gaussian process experts. Incremental, local, non-linear regression algorithms are required for a wide variety of applications, ranging from robotic control to neural decoding. Arguably the most popular and widely used of such algorithms is currently Locally Weighted Projection Regression (LWPR) which has been shown empirically to be both computationally efficient and sufficiently accurate for a number of applications. While incremental variants of non-linear Bayesian regression models have superior theoretical properties and have been shown to produce better function approximations than LWPR, they suffer from high computational and storage costs. Through exploitation of locality, infinite mixtures of Gaussian process experts (IMGPE) offer the same function approximation performance with reduced computation and storage cost. Our contribution is an incremental regression approach that has the theoretical benefits of a fully Bayesian model and computational benefits that derive from exploiting locality.",Frank Wood and Dan H. Grollman and KA Heller and Odest Chad Jenkins and Michael Black,7,5922738251098354201,,,,,Incremental Nonparametric Bayesian Regression,https://www.researchgate.net/profile/Odest_Jenkins/publication/228527054_Incremental_Nonparametric_Bayesian_Regression/links/09e4150e8a68822b78000000/Incremental-Nonparametric-Bayesian-Regression.pdf,,2008,/scholar?cites=5922738251098354201,6NjbexEAAAAJ:mvPsJ3kp5DgC

1010257,"A Switching Kalman Filter Model for the real-time inference of hand kinematics from a population of motor cortical neurons. Firing rates are modeled as a Gaussian mixture where the mean of each Gaussian component is a linear function of hand kinematics. A “hidden state” models the probability of each mixture component and evolves over time in a Markov chain. Gaussian mixture models and Expectation Maximization (EM) techniques are extended for automatic spike sorting. Good initialization of EM is achieved via spectral clustering. To account for noise, the mixture model is extended to include a uniform outlier process. A greedy optimization algorithm that selects models with different numbers of neurons according to their decoding accuracy is used to automatically determine the number of neurons recorded per electrode. Closed loop neural control of external events are demonstrated using neural control of …",,7,7014219549944451666,,,,,Method and system for automatic decoding of motor cortical activity,https://patents.google.com/patent/US20060165811A1/en,,2006,/scholar?cites=7014219549944451666,6NjbexEAAAAJ:eflP2zaiRacC

1010258,"Training computers to understand, model, and synthesize human grasping requires a rich dataset containing complex 3D object shapes, detailed contact information, hand pose and shape, and the 3D body motion over time. While “grasping” is commonly thought of as a single hand stably lifting an object, we capture the motion of the entire body and adopt the generalized notion of “whole-body grasps”. Thus, we collect a new dataset, called GRAB (GRasping Actions with Bodies), of whole-body grasps, containing full 3D shape and pose sequences of 10 subjects interacting with 51 everyday objects of varying shape and size. Given MoCap markers, we fit the full 3D body shape and pose, including the articulated face and hands, as well as the 3D object pose. This gives detailed 3D meshes over time, from which we compute contact between the body and object. This is a unique dataset, that goes well beyond …",Omid Taheri and Nima Ghorbani and Michael J Black and Dimitrios Tzionas,6,2290117580249334673,,,581-600,"Springer, Cham",GRAB: A dataset of whole-body human grasping of objects,https://link.springer.com/chapter/10.1007/978-3-030-58548-8_34,,2020,/scholar?cites=2290117580249334673,6NjbexEAAAAJ:Lbh3VFZM3akC

1010259,"The optical flow of humans is well known to be useful for the analysis of human action. Recent optical flow methods focus on training deep networks to approach the problem. However, the training data used by them does not cover the domain of human motion. Therefore, we develop a dataset of multi-human optical flow and train optical flow networks on this dataset. We use a 3D model of the human body and motion capture data to synthesize realistic flow fields in both single-and multi-person images. We then train optical flow networks to estimate human flow fields from pairs of images. We demonstrate that our trained networks are more accurate than a wide range of top methods on held-out test data and that they can generalize well to real image sequences. The code, trained models and the dataset are available for research.",Anurag Ranjan and David T Hoffmann and Dimitrios Tzionas and Siyu Tang and Javier Romero and Michael J Black,6,12913259340972342477,International Journal of Computer Vision,,1-18,Springer US,Learning multi-human optical flow,https://link.springer.com/content/pdf/10.1007/s11263-019-01279-w.pdf,,2020,/scholar?cites=12913259340972342477,6NjbexEAAAAJ:YClPFpxzHmwC

1010260,"The creation of realistic self-avatars that users identify with is important for many virtual reality applications. However, current approaches for creating biometrically plausible avatars that represent a particular individual require expertise and are time-consuming. We investigated the visual perception of an avatar’s body dimensions by asking males and females to estimate their own body weight and shape on a virtual body using a virtual reality avatar creation tool. In a method of adjustment task, the virtual body was presented in an HTC Vive head-mounted display either co-located with (first-person perspective) or facing (third-person perspective) the participants. Participants adjusted the body weight and dimensions of various body parts to match their own body shape and size. Both males and females underestimated their weight by 10-20% in the virtual body, but the estimates of the other body dimensions were …",Anne Thaler and Sergi Pujades and Jeanine K Stefanucci and Sarah H Creem-Regehr and Joachim Tesch and Michael J Black and Betty J Mohler,6,8390595054288964812,,,1-12,,The influence of visual perspective on body size estimation in immersive virtual Reality,https://dl.acm.org/doi/abs/10.1145/3343036.3343134,,2019,/scholar?cites=8390595054288964812,6NjbexEAAAAJ:brChLMnLtjYC

1010261,"Using styles derived from existing popular character designs, we present a novel automatic stylization technique for body shape and colour information based on a statistical 3D model of human bodies. We investigate whether such stylized body shapes result in increased perceived appeal with two different experiments: One focuses on body shape alone, the other investigates the additional role of surface colour and lighting. Our results consistently show that the most appealing avatar is a partially stylized one. Importantly, avatars with high stylization or no stylization at all were rated to have the least appeal. The inclusion of colour information and improvements to render quality had no significant effect on the overall perceived appeal of the avatars, and we observe that the body shape primarily drives the change in appeal ratings. For body scans with colour information, we found that a partially stylized …",Reuben Fleming and Betty J Mohler and Javier Romero and Michael J Black and Martin Breidt,6,8277931771432840596,,,175-196,"Springer, Cham",Appealing avatars from 3D body scans: Perceptual effects of stylization,https://link.springer.com/chapter/10.1007/978-3-319-64870-5_9,,2016,/scholar?cites=8277931771432840596,6NjbexEAAAAJ:E6rqZ6_0n1EC

1010262,"Statistical generative models of non-rigid deformable shape have numerous applications in computer vision, biometry, computer graphics, medical imaging, robotics, and other domains. The choice of shape representation has a great influence on the effectiveness of the statistical models. While shape representations come in different flavors, in the context of statistical modeling of deformable shape there are several properties we may desire the representation to possess. In particular, it is often desirable that the representation should:1. support shape synthesis, not just shape analysis; 2. lend itself to composition of more than one type of shape deformations (eg, two human shapes may differ from each other due to differences not only in physique but also in pose); 3. be differentiable; 4. allow for a meaningful notion of shape (dis) similarity.",Oren Freifeld,6,11372437651951719754,,,,,Statistics on manifolds with applications to modeling shape deformations,https://www.researchgate.net/profile/Vijayaragavan_Elumalai/post/What_is_the_best_way_to_do_active_shape_models_with_deformation_samples_collected_from_different_patients/attachment/59d642e7c49f478072eababd/AS%3A273805245648898%401442291666945/download/ThesisOrenFreifeld.pdf,,2014,/scholar?cites=11372437651951719754,6NjbexEAAAAJ:6jbE1kO3aKAC

1010263,"We introduce Puppet Flow (PF), a layered model describing the optical flow of a person in a video sequence. We consider video frames composed by two layers: a foreground layer corresponding to a person, and background. We model the background as an affine flow field. The foreground layer, being a moving person, requires reasoning about the articulated nature of the human body. We thus represent the foreground layer with the Deformable Structures model (DS), a parametrized 2D part-based human body representation. We call the motion field defined through articulated motion and deformation of the DS model, a Puppet Flow. By exploiting the DS representation, Puppet Flow is a parametrized optical flow field, where parameters are the person’s pose, gender and body shape.",Silvia Zuffi and Michael J Black,6,6757710341484098103,IJCV,3,437-458,,Puppet flow,https://ps.is.tue.mpg.de/uploads_file/attachment/attachment/151/mpi-is-tr-007.pdf,101,2013,/scholar?cites=6757710341484098103,6NjbexEAAAAJ:YohjEiUPhakC

1010264,"Neural motor prostheses (NMPs) require the accurate decoding of motor cortical population activity for the control of an artificial motor system. Previous work on cortical decoding for NMPs has focused on the recovery of hand kinematics. Human NMPs however may require the control of computer cursors or robotic devices with very different physical and dynamical properties. Here we show that the firing rates of cells in the primary motor cortex of non-human primates can be used to control the parameters of an artificial physical system exhibiting realistic dynamics. The model represents 2D hand motion in terms of a point mass connected to a system of idealized springs. The nonlinear spring coefficients are estimated from the firing rates of neurons in the motor cortex. We evaluate linear and a nonlinear decoding algorithms using neural recordings from two monkeys performing two different tasks. We found that the decoded spring coefficients produced accurate hand trajectories compared with state-of-the-art methods for direct decoding of hand kinematics. Furthermore, using a physically-based system produced decoded movements that were more “natural” in that their frequency spectrum more closely matched that of natural hand movements.",Gregory Shakhnarovich and Sung-Phil Kim and Michael J Black,6,16509332350288167984,,,1257-1264,,Nonlinear physically-based models for decoding motor-cortical population activity,https://papers.nips.cc/paper/3050-nonlinear-physically-based-models-for-decoding-motor-cortical-population-activity.pdf,,2007,/scholar?cites=16509332350288167984,6NjbexEAAAAJ:tOudhMTPpwUC

1010265,"This thesis addresses the problem of recovering a locally layered representation of image motion. We develop the Skin and Bones"" model for estimating optical flow that strikes a balance between the flexibility of regularization techniques and the robustness and accuracy of area-based regression techniques. The approach assumes that image motion can be represented by an affine flow model within local image patches. Since some image regions may not have sufficient information to estimate an affine motion model robustly, we define a spatial smoothness constraint on the affine flow parameters of neighboring patches. We refer to this as a Skin and Bones"" model in which the affine patches can be thought of as rigid patches of bone"" connected by a flexible skin."" Since local image patches may contain multiple motions we use a layered representation for the affine bones. With the possibility of multiple motions at a given point, standard regularization schemes cannot be used to smooth the multiple sets of affine parameters. We therefore develop a new framework for regularization with transparency that can applied to produce a smoothed layered motion representation. The motion estimation problem, with layered locally affine patches and transparent regularization, is formulated as an objective function that is minimized using a variant of the Expectation-Maximization EM algorithm. In addition, we also formulate spatial and temporal smoothness constraints on the EM ownership weights at the pixel level. This formulation fits naturally into the EM framework. We also exploit an incremental revision process to estimate the number of layers in each …",S Ju and Michael J Black and Allan D Jepson,6,17279894025598318354,Internation Journal of Computer Vision,,,,Estimating image motion in layers: the skin and bones model,http://files.is.tue.mpg.de/black/papers/juThesis.pdf,,1998,/scholar?cites=17279894025598318354,6NjbexEAAAAJ:He_SdS2HmmMC

1010266,,Leonid Sigal and Alexandru Balan and J Michael,6,10048048644351788028,Advances in neural information processing systems,,,,Black. 2007. Combined discriminative and generative articulated pose and non-rigid shape estimation,http://scholar.google.com/scholar?cluster=10048048644351788028&hl=en&oi=scholarr,20,,/scholar?cites=10048048644351788028,6NjbexEAAAAJ:aEyKTaVlRPYC

1010267,,Oren Freifeld and J Michael,6,16498345734974662702,ECCV (1),,1-14,,Black. 2012. Lie bodies: A manifold representation of 3d human shape,http://scholar.google.com/scholar?cluster=16498345734974662702&hl=en&oi=scholarr,,,/scholar?cites=16498345734974662702,6NjbexEAAAAJ:3r0_5JwaG5wC

1010268,"Motion capture is often retargeted to new, and sometimes drastically different, characters. When the characters take on realistic human shapes, however, we become more sensitive to the motion looking right. This means adapting it to be consistent with the physical constraints imposed by different body shapes. We show how to take realistic 3D human shapes, approximate them using a simplified representation, and animate them so that they move realistically using physically‐based retargeting. We develop a novel spacetime optimization approach that learns and robustly adapts physical controllers to new bodies and constraints. The approach automatically adapts the motion of the mocap subject to the body shape of a target subject. This motion respects the physical properties of the new body and every body shape results in a different and appropriate movement. This makes it easy to create a varied set of …",Mazen Al Borno and Ludovic Righetti and Michael J Black and Scott L Delp and Eugene Fiume and Javier Romero,5,12357972157900366545,Computer Graphics Forum,8,81-92,,Robust Physics‐based Motion Retargeting with Realistic Body Shapes,https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13514,37,2018,/scholar?cites=12357972157900366545,6NjbexEAAAAJ:cTLm0pkq19gC

1010269,"A novel “contour person”(CP) model of the human body is proposed that has the expressive power of a detailed 3D model and the computational benefits of a simple 2D part-based model. The CP model is learned from a 3D model of the human body that captures natural shape and pose variations; the projected contours of this model, along with their segmentation into parts forms the training set. The CP model factors deformations of the body into three components: shape variation, viewpoint change and pose variation.",,5,8448895236020885633,,,,,Parameterized model of 2D articulated human shape,https://patents.google.com/patent/US9489744B2/en,,2016,/scholar?cites=8448895236020885633,6NjbexEAAAAJ:7gg4mBK4JdgC

1010270,"The relation between clinical quality and bond rating for nonprofit hospitals has been proposed but never fully studied. We analyzed the relation between bond rating, clinical quality measures (The Joint Commission/Centers for Medicare and Medicaid Services [CMS] core measures), and balance sheet and income statement financial measures of 236 hospitals across the United States that are rated by Moody’s Investors Service and that reported clinical quality measures to CMS during the study period. We found a statistically significant relation between higher quality measures and more favorable bond ratings. This association remained significant after controlling for traditional financial parameters.",Ziad Haydar and David Nicewander and Paul Convery and Michael Black and David Ballard,5,11575629903796633462,American Journal of Medical Quality,3,181-185,SAGE Publications,Clinical quality is independently associated with favorable bond ratings,https://journals.sagepub.com/doi/abs/10.1177/1062860609354915,25,2010,/scholar?cites=11575629903796633462,6NjbexEAAAAJ:YP-lgzILWVMC

1010271,"Page 1. Max Planck Institute for Intelligent Systems – Perceiving Systems Department Detailed,
Accurate, Human Shape Estimation from Clothed 3D Scan Sequences Chao Zhang, Sergi Pujades,
Michael Black and Gerard Pons-Moll Goal BUFF dataset Method Results Single frame objective
Estimation of body shape and pose under clothing from scan sequences Problem • The body
is occluded by clothing • Current methods leverage body models but lack personalized details
Key Idea • As people move, the cloth drapes at different body parts → our method efficiently
leverages temporal information to estimate the shape Contribution • Our method optimizes a
free-from surface and body model parameters. Thus it captures the body shape and personalized
details (face, hair) 1) Registration 2) Shape estimation INRIA Dataset BUFF Dataset
E(TEst,M(β,0),θ;S) = λskinEskin + Ecloth + λcplEcpl + λpriorEprior … 
",Chao Zhang and Sergi Pujades and Michael Black and Gerard Pons-Moll,5,9675487256215582656,,,,,Goal,http://openaccess.thecvf.com/content_cvpr_2017/poster/1708_POSTER.pdf,,2003,/scholar?cites=9675487256215582656,6NjbexEAAAAJ:zDAX0LUT-dsC

1010272,,Dirk Ormoneit and Hedvig Sidenbladh and J Michael,5,199598179571697219,Leen et al.[28],,894-900,,"Black, and Trevor Hastie. Learning and tracking cyclic human motion",http://scholar.google.com/scholar?cluster=199598179571697219&hl=en&oi=scholarr,,2000,/scholar?cites=199598179571697219,6NjbexEAAAAJ:rPSSLjQITZsC

1010273,"Using computers to watch human activity has proven to be a research area having not only a large number of potentially important applications (in surveillance, communications, health, etc.) but also one the had led to a variety of new, fundamental problems in image processing and computer vision. In this chapter we review research that has been conducted at the University of Maryland during the past five years on various topics involving analysis of human activity.",Y Yacoob and L Davis and M Black and D Gavrila and T Horprasert and C Morimoto,5,7352912518883626378,Computer Vision for Human-Machine Interaction,,171,Cambridge University Press,Looking at People in Action-An Overview,http://books.google.com/books?hl=en&lr=&id=Pe7gG0LxEUIC&oi=fnd&pg=PA171&dq=info:is2UgPrKCmYJ:scholar.google.com&ots=O6mdDAIaLX&sig=V-508vBS2KHtapiXyf0PDxKhjb8,,1998,/scholar?cites=7352912518883626378,6NjbexEAAAAJ:u9iWguZQMMsC

1010274,"To understand how people look, interact, or perform tasks, we need to quickly and accurately capture their 3D body, face, and hands together from an RGB image. Most existing methods focus only on parts of the body. A few recent approaches reconstruct full expressive 3D humans from images using 3D body models that include the face and hands. These methods are optimization-based and thus slow, prone to local optima, and require 2D keypoints as input. We address these limitations by introducing ExPose (EXpressive POse and Shape rEgression), which directly regresses the body, face, and hands, in SMPL-X format, from an RGB image. This is a hard problem due to the high dimensionality of the body and the lack of expressive training data. Additionally, hands and faces are much smaller than the body, occupying very few image pixels. This makes hand and face estimation hard when body images are …",Vasileios Choutas and Georgios Pavlakos and Timo Bolkart and Dimitrios Tzionas and Michael J Black,4,13234841314490938022,,,20-40,"Springer, Cham",Monocular expressive body regression through body-driven attention,https://link.springer.com/chapter/10.1007/978-3-030-58607-2_2,,2020,/scholar?cites=13234841314490938022,6NjbexEAAAAJ:aDdGf5um_jkC

1010275,"Deep neural networks provide powerful tools for pattern recognition, while classical graph algorithms are widely used to solve combinatorial problems. In computer vision, many tasks combine elements of both pattern recognition and graph reasoning. In this paper, we study how to connect deep networks with graph decomposition into an end-to-end trainable framework. More specifically, the minimum cost multicut problem is first converted to an unconstrained binary cubic formulation where cycle consistency constraints are incorporated into the objective function. The new optimization problem can be viewed as a Conditional Random Field (CRF) in which the random variables are associated with the binary edge labels. Cycle constraints are introduced into the CRF as high-order potentials. A standard Convolutional Neural Network (CNN) provides the front-end features for the fully differentiable CRF. The parameters of both parts are optimized in an end-to-end manner. The efficacy of the proposed learning algorithm is demonstrated via experiments on clustering MNIST images and on the challenging task of real-world multi-people pose estimation.",Jie Song and Bjoern Andres and Michael J Black and Otmar Hilliges and Siyu Tang,4,9151807633400998821,,,10093-10102,,End-to-end learning for graph decomposition,http://openaccess.thecvf.com/content_ICCV_2019/html/Song_End-to-End_Learning_for_Graph_Decomposition_ICCV_2019_paper.html,,2019,/scholar?cites=9151807633400998821,6NjbexEAAAAJ:5aszrCQfcYQC

1010276,"The difficulty of annotating training data is a major obstacle to using CNNs for low-level tasks in video. Synthetic data often does not generalize to real videos, while unsupervised methods require heuristic losses. Proxy tasks can overcome these issues, and start by training a network for a task for which annotation is easier or which can be trained unsupervised. The trained network is then fine-tuned for the original task using small amounts of ground truth data. Here, we investigate frame interpolation as a proxy task for optical flow. Using real movies, we train a CNN unsupervised for temporal interpolation. Such a network implicitly estimates motion, but cannot handle untextured regions. By fine-tuning on small amounts of ground truth flow, the network can learn to fill in homogeneous regions and compute full optical flow fields. Using this unsupervised pre-training, our network outperforms similar …",Jonas Wulff and Michael J Black,4,13911288988655473878,,,567-582,"Springer, Cham",Temporal interpolation as an unsupervised pretraining task for optical flow estimation,https://link.springer.com/chapter/10.1007/978-3-030-12939-2_39,,2018,/scholar?cites=13911288988655473878,6NjbexEAAAAJ:FgeqF4j-V1wC

1010277,"A differential control strategy based on equal slip rates is introduced to improve the steering stability of an all-wheelelectric-drive underground articulated dumping truck. Steering kinematic and dynamic models of the truck are derived to describe the movement relationship and force of the driving wheels. In consideration of the difficulty of obtaining the absolute velocity for an all-wheel-drive truck, an acceleration sensor was set on a test truck, and a kalman filter was applied to obtain the actual value for the truck body. Simulation results for an equal-slip control strategy were compared with experimental results for an equal-torque control strategy. In the simulation, the four-wheel slip rate was 0.08 and the steering system of the truck was stable. The results verify that the equal-slip control strategy makes better use of the ground adhesion coefficient, is able to reasonably distribute drive power, notably reduces tire wear, and improves the use of driving power.",Jin Chun and Wang Ping and Shen Yanhua and Jossey B Michael,4,11899391004278319977,Journal of Engineering Science & Technology Review,4,,,Differential Control Strategy based on an Equal Slip Rate for an All-wheel Electric-drive Underground Articulated Dumping Truck.,http://jestr.org/downloads/Volume7Issue4/fulltext267414.pdf,7,2014,/scholar?cites=11899391004278319977,6NjbexEAAAAJ:ypzvKOdbExQC

1010278,"The 3D shape of the human body is useful for applications in fitness, games, and apparel. Accurate body scanners, however, are expensive, limiting the availability of 3D body models. Although there has been a great deal of interest recently in the use of active depth sensing cameras, such as the Microsoft Kinect, for human pose tracking, little has been said about the related problem of human shape estimation. We present a method for human shape reconstruction from noisy monocular image and range data using a single inexpensive commodity sensor. The approach combines low-resolution image silhouettes with coarse range data to estimate a parametric model of the body. Accurate 3D shape estimates are obtained by combining multiple monocular views of a person moving in front of the sensor. To cope with varying body pose, we use a SCAPE body model which factors 3D body shape and pose …",Alexander Weiss and David Hirshberg and Michael J Black,4,6011898301222965744,,,99-117,"Springer, London",Home 3D body scans from a single Kinect,https://link.springer.com/chapter/10.1007/978-1-4471-4640-7_6,,2013,/scholar?cites=6011898301222965744,6NjbexEAAAAJ:4MWp96NkSFoC

1010279,"Correspondence between non-rigid deformable 3D objects provides a foundation for object matching and retrieval, recognition, and 3D alignment. Establishing 3D correspondence is challenging when there are non-rigid deformations or articulations between instances of a class. We present a method for automatically finding such correspondences that deals with significant variations in pose, shape and resolution between pairs of objects. We represent objects as triangular meshes and consider normalized geodesic distances as representing their intrinsic characteristics. Geodesic distances are invariant to pose variations and nearly invariant to shape variations when properly normalized. The proposed method registers two objects by optimizing a joint probabilistic model over a subset of vertex pairs between the objects. The model enforces preservation of geodesic distances between corresponding …",Aggeliki Tsoli and Michael J Black,4,8443914416087047031,,,256-265,"Springer, Berlin, Heidelberg",Shape-and pose-invariant correspondences using probabilistic geodesic surface embedding,https://link.springer.com/chapter/10.1007/978-3-642-23123-0_26,,2011,/scholar?cites=8443914416087047031,6NjbexEAAAAJ:SdhP9T11ey4C

1010280,"The modeling of spatial discontinuities for problems such as surface recovery, segmentation, image reconstruction, and optical flow has been intensely studied in computer vision. While"" line-process"" models of discontinuities have received a great deal of attention, there has been recent interest in the use of robust statistical techniques to account for discontinuities. This paper unifies the two approaches. To achieve this we generaUze the notion of a"" line process"" to that of an analog"" outlier process"" and show how a problem formulated in terms of outlier processes can be viewed in terms of robust statistics. We also characterize a class of robust statistical problems for which an equivalent outlier-process formulation exists and give a straightforward method for converting a robust estimation problem into an outlier-process formulation. We also show how prior assumptions about the spatial structure of outliers can be …",Michael Black and Anand Rangarajan,4,15689646272113489316,,,,"Technical Report YALEU-DCS-RR-993, Department of Computer Science, Yale University","On line processes, outlier rejection, and robust statistics",http://www.cs.yale.edu/publications/techreports/tr993.pdf,,1993,/scholar?cites=15689646272113489316,6NjbexEAAAAJ:l7t_Zn2s7bgC

1010281,,Silvia Zuffi and Oren Freifeld and J Michael,4,6636927227846710845,"Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on",,3546-3553,,Black. From pictorial structures to deformable structures,http://scholar.google.com/scholar?cluster=6636927227846710845&hl=en&oi=scholarr,,,/scholar?cites=6636927227846710845,6NjbexEAAAAJ:BqLlocMOq84C

1010282,"General Movement Assessment (GMA) is a powerful tool to predict Cerebral Palsy (CP). Yet, GMA requires substantial training challenging its broad implementation in clinical routine. This inspired a world-wide quest for automated GMA.To test whether a low-cost, marker-less system for three-dimensional motion capture from RGB depth sequences using a whole body infant model may serve as the basis for automated GMA.Clinical case study at an academic neurodevelopmental outpatient clinic.Twenty-nine high risk infants were assessed at their clinical follow-up at 2–4 month corrected age (CA). Their neurodevelopmental outcome was assessed regularly up to 12–31 months CA.GMA according to Hadders-Algra by a masked GMA-expert of conventional and computed 3D body model (“SMIL motion”) videos of the same GMs. Agreement between both …",A Sebastian Schroeder and Nikolas Hesse and Raphael Weinberger and Uta Tacke and Lucia Gerstl and Anne Hilgendorff and Florian Heinen and Michael Arens and Linze J Dijkstra and Sergi Pujades Rocamora and Michael J Black and Christoph Bodensteiner and Mijna Hadders-Algra,3,6665673069357247608,Early Human Development,,104967,Elsevier,General Movement Assessment from videos of computed 3D infant body models is equally effective compared to conventional RGB video rating,https://www.sciencedirect.com/science/article/pii/S0378378219304979,144,2020,/scholar?cites=6665673069357247608,6NjbexEAAAAJ:7fE6T6CK6bcC

1010283," Neural networks need big annotated datasets for training. However, manual annotation can be too expensive or even unfeasible for certain tasks, like multi-person 2D pose estimation with severe occlusions. A remedy for this is synthetic data with perfect ground truth. Here we explore two variations of synthetic data for this challenging problem; a dataset with purely synthetic humans and a real dataset augmented with synthetic humans. We then study which approach better generalizes to real data, as well as the influence of virtual humans in the training loss. Using the augmented dataset, without considering synthetic humans in the loss, leads to the best results. We observe that not all synthetic samples are equally informative for training, while the informative samples are different for each training stage. To exploit this observation, we employ an adversarial student-teacher framework; the teacher …",David T Hoffmann and Dimitrios Tzionas and Michael J Black and Siyu Tang,3,13823312114275440388,,,609-623,"Springer, Cham",Learning to Train with Synthetic Humans,https://link.springer.com/chapter/10.1007/978-3-030-33676-9_43,,2019,/scholar?cites=13823312114275440388,6NjbexEAAAAJ:_r6PDwDh8pAC

1010284,"A system and method of estimating the body shape of an individual from input data such as images or range maps. The body may appear in one or more poses captured at different times and a consistent body shape is computed for all poses. The body may appear in minimal tight-fitting clothing or in normal clothing wherein the described method produces an estimate of the body shape under the clothing. Clothed or bare regions of the body are detected via image classification and the fitting method is adapted to treat each region differently. Body shapes are represented parametrically and are matched to other bodies based on shape similarity and other features. Standard measurements are extracted using parametric or non-parametric functions of body shape. The system components support many applications in body scanning, advertising, social networking, collaborative filtering and Internet clothing shopping.",,3,17750821245606410312,,,,,Method and apparatus for estimating body shape,https://patents.google.com/patent/US10339706B2/en,,2019,/scholar?cites=17750821245606410312,6NjbexEAAAAJ:uYElc5AnwZoC

1010285,"The individual shape of the human body, including the geometry of its articulated structure and the distribution of weight over that structure, influences the kinematics of a person’s movements. How sensitive is the visual system to inconsistencies between shape and motion introduced by retargeting motion from one person onto the shape of another? We used optical motion capture to record five pairs of male performers with large differences in body weight, while they pushed, lifted, and threw objects. From these data, we estimated both the kinematics of the actions as well as the performer’s individual body shape. To obtain consistent and inconsistent stimuli, we created animated avatars by combining the shape and motion estimates from either a single performer or from different performers. Using these stimuli we conducted three experiments in an immersive virtual reality environment. First, a group of participants …",Sophie Kenny and Naureen Mahmood and Claire Honda and Michael J Black and Nikolaus F Troje,3,12776387761505471955,ACM Transactions on Applied Perception (TAP),1,2,ACM,Perceptual Effects of Inconsistency in Human Animations,https://dl.acm.org/doi/abs/10.1145/3301411,16,2019,/scholar?cites=12776387761505471955,6NjbexEAAAAJ:l0_JBNIuc60C

1010286,"Previous research on own body size estimation has only looked at estimates made by comparing own body size to a test body in front view (eg, Mölbert et al. 2017). However, people constantly see and compare themselves to bodies in different viewpoints. Depending on the viewpoint, shape cues potentially used to judge body size, such as the waist-to-hip ratio or the overall body outline, vary. Here, we asked whether viewpoint influences estimates of own body size in female participants. For each participant, a personalized female avatar was generated using weight, height, inseam, and arm span, and then variations of the personalized avatar having different weights (±5%,±10%,±15%,±20%, and±25%) were created using a statistical body model. These eleven test bodies were presented in life-size in immersive virtual reality in six viewpoints: 0,±45,±90, 180. In a one-alternative forced choice paradigm …",Anne Thaler and Isabelle Bülthoff and Sergi Pujades and Michael Black and Betty Mohler,3,11221458213403963478,Journal of Vision,10,165-165,The Association for Research in Vision and Ophthalmology,Is Body Size Estimation Viewpoint Invariant?,https://jov.arvojournals.org/article.aspx?articleid=2699159,18,2018,/scholar?cites=11221458213403963478,6NjbexEAAAAJ:ZHR7-34Bl2wC

1010287,"Disclosed are computer-readable devices, systems and methods for generating a model of a clothed body. The method includes generating a model of an unclothed human body, the model capturing a shape or a pose of the unclothed human body, determining two-dimensional contours associated with the model, and computing deformations by aligning a contour of a clothed human body with a contour of the unclothed human body. Based on the two-dimensional contours and the deformations, the method includes generating a first two-dimensional model of the unclothed human body, the first two-dimensional model factoring the deformations of the unclothed human body into one or more of a shape variation component, a viewpoint change, and a pose variation and learning an eigen-clothing model using principal component analysis applied to the deformations, wherein the eigen-clothing model classifies …",,3,15599583938708467574,,,,,Parameterized model of 2D articulated human shape,https://patents.google.com/patent/US9761060B2/en,,2017,/scholar?cites=15599583938708467574,6NjbexEAAAAJ:xCS0c1RzPY8C

1010288,"Previous research demonstrated that estimates of others' body sizes are biased towards the average body size in the population (Cornelissen, Gledhill, Cornelissen & Tovée, 2016). Bodies in the environment not only influence the internal reference of what is perceived as average or"" normal"", but also play an essential role in self-body size evaluation via social comparison (Cattarin, Thompson, Thomas & Williams, 2000). In two psychophysical experiments, we asked whether there is also an influence of own body size on the perception of others' body sizes. For Experiment 1, four biometric female avatars with a body mass index (BMI) of 15, 25, 35, and 45 were generated, and then their weight was altered (±5,±10,±15, and±20% BMI change) based on a statistical body model. For each of the avatar series, female participants spanning the BMI range memorized what the avatar's body looked like and then responded …",Anne Thaler and Michael Geuss and Jeanine Stefanucci and Simone Mölbert and Katrin Giel and Michael Black and Betty Mohler,3,3455117549998197739,Journal of Vision,10,843-843,The Association for Research in Vision and Ophthalmology,Perception of others' body sizes is predicted by own body size,https://jov.arvojournals.org/article.aspx?articleid=2651718,17,2017,/scholar?cites=3455117549998197739,6NjbexEAAAAJ:QUKcMBy53xEC

1010289,"A direct neural interface system (NIS) promises to provide communication and independence to persons with paralysis by harnessing intact motor cortical signals to enable controlling prosthetic devices. An intracortical NIS aims to achieve this by sensing extracellular neuronal signals through chronically implanted microelectrodes and by decoding the spiking activity of neurons into prosthetic control signals. In non-human primate studies, decoding has been performed by finding a relationship between neuronal signals and actual limb movements. However, such decoding approaches face challenges in the case of paralyzed persons where there is no true movement information. Specifically, we have focused on dealing with several key questions in decoding of neural activity in humans with paralysis: what movement parameters should be decoded?; which decoding algorithms lead to more accurate estimation of …",Sung-Phil Kim and John D Simeral and Leigh R Hochberg and John P Donoghue and Michael J Black,3,4717096140308011912,,,988-993,IEEE,Computer cursor control by motor cortical signals in humans with tetraplegia,https://ieeexplore.ieee.org/abstract/document/5276154/,,2009,/scholar?cites=4717096140308011912,6NjbexEAAAAJ:fQNAKQ3IYiAC

1010290,"How to cluster event sequences generated via different point processes is an interesting and important problem in statistical machine learning. To solve this problem, we propose and discuss an effective model-based clustering method based on a novel Dirichlet mixture model of a special but significant type of point processes---Hawkes process. The proposed model generates the event sequences with different clusters from the Hawkes processes with different parameters, and uses a Dirichlet process as the prior distribution of the clusters. We prove the identifiability of our mixture model and propose an effective variational Bayesian inference algorithm to learn our model. An adaptive inner iteration allocation strategy is designed to accelerate the convergence of our algorithm. Moreover, we investigate the sample complexity and the computational complexity of our learning algorithm in depth. Experiments on both …",Noah Goodman and Joshua Tenenbaum and Michael Black,3,17163359261492832712,Advances in Neural Information Processing Systems,,457-464,,A bayesian framework for cross-situational word-learning,https://proceedings.neurips.cc/paper/2007/hash/dd8eb9f23fbd362da0e3f4e70b878c16-Abstract.html,20,2007,/scholar?cites=17163359261492832712,6NjbexEAAAAJ:PjKh-f16SfUC

1010291,"Photo-realistic visualization and animation of expressive human faces have been a long standing challenge. On one end of the spectrum, 3D face modeling methods provide parametric control but tend to generate unrealistic images, while on the other end, generative 2D models like GANs (Generative Adversarial Networks) output photo-realistic face images, but lack explicit control. Recent methods gain partial control, either by attempting to disentangle different factors in an unsupervised manner, or by adding control post hoc to a pre-trained model. Trained GANs without pre-defined control, however, may entangle factors that are hard to undo later. To guarantee some disentanglement that provides us with desired kinds of control, we train our generative model conditioned on pre-defined control parameters. Specifically, we condition StyleGAN2 on FLAME, a generative 3D face model. However, we found out that a naive conditioning on FLAME parameters yields rather unsatisfactory results. Instead we render out geometry and photo-metric details of the FLAME mesh and use these for conditioning instead. This gives us a generative 2D face model named GIF (Generative Interpretable Faces) that shares FLAME's parametric control. Given FLAME parameters for shape, pose, and expressions, parameters for appearance and lighting, and an additional style vector, GIF outputs photo-realistic face images. To evaluate how well GIF follows its conditioning and the impact of different design choices, we perform a perceptual study. The code and trained model are publicly available for research purposes at this https URL.",Partha Ghosh and Pravir Singh Gupta and Roy Uziel and Anurag Ranjan and Michael Black and Timo Bolkart,2,8581517327279399494,arXiv preprint arXiv:2009.00149,,,,Gif: Generative interpretable faces,https://arxiv.org/abs/2009.00149,,2020,/scholar?cites=8581517327279399494,6NjbexEAAAAJ:JMEA1obkRKoC

1010292,"A system and method of estimating the body shape of an individual from input data such as images or range maps. The body may appear in one or more poses captured at different times and a consistent body shape is computed for all poses. The body may appearin minimal tight-fitting clothing or in normal clothing wherein the described method produces an estimate of the body shape under the clothing. Clothed or bare regions of the body are detected via image classification and the fitting method is adapted to treat each region differently. Body shapes are represented parametrically and are matched to other bodies based on shape similarity and other features. Standard measurements are extracted using parametric or non-parametric functions of body shape. The system components support many applications in body scanning, advertising, social networking, collaborative filtering and Internet clothing shopping.",,2,3060299353628888006,,,,,Method and apparatus for estimating body shape,https://patents.google.com/patent/US10546417B2/en,,2020,/scholar?cites=3060299353628888006,6NjbexEAAAAJ:DRUjQUnLNDcC

1010293,"Disclosed is a method including receiving visual input comprising a human within a scene, detecting a pose associated with the human using a trained machine learning model that detects human poses to yield a first output, estimating a shape (and optionally a motion) associated with the human using a trained machine learning model associated that detects shape (and optionally motion) to yield a second output, recognizing the scene associated with the visual input using a trained convolutional neural network which determines information about the human and other objects in the scene to yield a third output, and augmenting reality within the scene by leveraging one or more of the first output, the second output, and the third output to place 2D and/or 3D graphics in the scene.",,2,3475576346017397867,,,,,Machine learning systems and methods for augmenting images,https://patents.google.com/patent/US10529137B1/en,,2020,/scholar?cites=3475576346017397867,6NjbexEAAAAJ:UlRcoTO8nVoC

1010294,"The goal of many computer vision systems is to transform image pixels into 3D representations. Recent popular models use neural networks to regress directly from pixels to 3D object parameters. Such an approach works well when supervision is available, but in problems like human pose and shape estimation, it is difficult to obtain natural images with 3D ground truth. To go one step further, we propose a new architecture that facilitates unsupervised, or lightly supervised, learning. The idea is to break the problem into a series of transformations between increasingly abstract representations. Each step involves a cycle designed to be learnable without annotated training data, and the chain of cycles delivers the final solution. Specifically, we use 2D body part segments as an intermediate representation that contains enough information to be lifted to 3D, and at the same time is simple enough to be learned in an unsupervised way. We demonstrate the method by learning 3D human pose and shape from un-paired and un-annotated images. We also explore varying amounts of paired data and show that cycling greatly alleviates the need for paired data. While we present results for modeling humans, our formulation is general and can be applied to other vision problems.",Nadine Rueegg and Christoph Lassner and Michael J Black and Konrad Schindler,2,10111724863663967840,arXiv preprint arXiv:2001.01613,,,,Chained Representation Cycling: Learning to Estimate 3D Human Pose and Shape by Cycling Between Representations,https://arxiv.org/abs/2001.01613,,2020,/scholar?cites=10111724863663967840,6NjbexEAAAAJ:kFzFP8IdBVAC

1010295,"We present the first method to perform automatic 3D pose, shape and texture capture of animals from images acquired in-the-wild. In particular, we focus on the problem of capturing 3D information about Grevy's zebras from a collection of images. The Grevy's zebra is one of the most endangered species in Africa, with only a few thousand individuals left. Capturing the shape and pose of these animals can provide biologists and conservationists with information about animal health and behavior. In contrast to research on human pose, shape and texture estimation, training data for endangered species is limited, the animals are in complex natural scenes with occlusion, they are naturally camouflaged, travel in herds, and look similar to each other. To overcome these challenges, we integrate the recent SMAL animal model into a network-based regression pipeline, which we train end-to-end on synthetically generated images with pose, shape, and background variation. Going beyond state-of-the-art methods for human shape and pose estimation, our method learns a shape space for zebras during training. Learning such a shape space from images using only a photometric loss is novel, and the approach can be used to learn shape in other settings with limited 3D supervision. Moreover, we couple 3D pose and shape prediction with the task of texture synthesis, obtaining a full texture map of the animal from a single image. We show that the predicted texture map allows a novel per-instance unsupervised optimization over the network features. This method, SMALST (SMAL with learned Shape and Texture) goes beyond previous work, which …",Silvia Zuffi and Angjoo Kanazawa and Tanya Berger-Wolf and Michael J Black,2,13291570063473392645,,,5359-5368,,"Three-D Safari: Learning to Estimate Zebra Pose, Shape, and Texture From Images",http://openaccess.thecvf.com/content_ICCV_2019/html/Zuffi_Three-D_Safari_Learning_to_Estimate_Zebra_Pose_Shape_and_Texture_ICCV_2019_paper.html,,2019,/scholar?cites=13291570063473392645,6NjbexEAAAAJ:ZWXmI6zqLYMC

1010296,"Aims: Anorexia nervosa (AN) is a serious eating disorder that goes along with underweight and high rates of psychological and physical comorbidity. Body image disturbance is a core symptom AN, but as yet distinctive features of this disturbance are unknown. This study uses individual 3D-avatars in virtual reality to investigate the following questions:(1) Do women with AN differ from controls in how accurately they perceive their body weight and (2) in what body weight they desire? Method: We investigated n= 24 women with AN (body mass index (kg/m2, BMI) M= 15.17, SD= 1.47) and n= 24 healthy controls (BMI M= 22.07, SD= 1.85). Based on a 3D body scan, we created individual avatars for each participant. Each avatar was manipulated to represent+/5, 10, 15 and 20 of the participant’s weight. Avatars were presented on a stereoscopic life-size screen. Using an 1 Alternative Forced Choice (1AFC) task and a Method of Adjustment (MoA) task, participants were asked to identify/adjust their correct body weight and their desired weight. Additionally, eating pathology, body dissatisfaction and self-esteem were assessed. In a control experiment, we repeated all tasks with an avatar that had the participant’s body shape, but another person’s look. Results: Women with AN and controls underestimated their current weight, with a trend that women with AN underestimated even more than controls (1AFC: AN M=-7.38, SD= 4.71; Con M=-3.80, SD= 5.02; F (1, 45)= 6.35, p<. 05; MoA: AN M=-5.94, SD= 5.81; Con M=-3.19, SD= 4.89, F (1, 45)= 3.09, p=. 086). The discrepancy between desired and actual body weight suggested that both groups wanted to …",S Mölbert and A Thaler and B Mohler and S Streuber and M Black and HO Karnath and S Zipfel and K Giel,2,4514259448328081645,,,162-162,,Assessing body image disturbance in patients with anorexia nervosa using biometric self-avatars in virtual reality: Attitudinal components rather than visual body size …,https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_2552372,,2017,/scholar?cites=4514259448328081645,6NjbexEAAAAJ:yHoQYHXJRqAC

1010297,"Human body shape variations can be measured physically and described verbally (eg, curvy, stocky), though little is known about the relationship between body shapes and descriptions. We examined this relationship by linking two similarity spaces: one created from body descriptions (descriptor space) and the other from full-body laser scans (shape space). The descriptor space was generated from a multivariate correspondence analysis (CA) applied to participants’ ratings of 164 female bodies using 27 body-descriptive terms. The shape space was made using a database of approximately 2000 full-body laser scans (cf. Anguelov et al. 2005). In interpreting individual axes, it appeared that similar information was captured in the first five components of both spaces, although axis ranking differed. To compare the spaces, the factor scores for the 164 bodies from the descriptor space (real bodies) were scaled and …",Matthew Hill and Stephan Streuber and Carina Hahn and Michael Black and Alice O'Toole,2,8620923851567390709,Journal of vision,12,931-931,The Association for Research in Vision and Ophthalmology,Exploring the relationship between body shapes and descriptions by linking similarity spaces,https://jov.arvojournals.org/article.aspx?articleid=2434039,15,2015,/scholar?cites=8620923851567390709,6NjbexEAAAAJ:ZtJ3RtM1NaMC

1010298,"Background:• Initial results from the first trial participant were recently reported (Hochberg, et al., 2006, Nature)",Sung-Phil Kim and John D Simeral and John P Donoghue and Leigh R Hochberg and Gerhard M Friehs and Jon A Mukand and David Chen and Michael J Black,2,8388354719567869624,"Society for Neuroscience Annual Meeting, Atlanta, GA",,,,A comparison of decoding models for imagined motions from human motor cortex,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.186.2410&rep=rep1&type=pdf,,2006,/scholar?cites=8388354719567869624,6NjbexEAAAAJ:geHnlv5EZngC

1010299,"A large literature on natural image statistics suggests the modeling of images in terms of a linear combination of Gabor-like filters. A variety of sparse image coding methods all arrive at similar filters and it has been often noted how these filters resemble the observed spatial receptive fields of V1 simple cells. Related recent work by Welling et al (2002) proposes a probabilistic model of image patches as a product of Student t distributions. As with standard sparse coding methods, this approach defines a model of image patches and not images. To model the probability of an entire image one must account for spatially overlapping receptive fields. Previous sparse coding methods fail to model the correlated image structure present in overlapping image regions.Recently we proposed a"" field of experts""(FOE) model (Roth and Black 2005) that defines a probability density over images by learning a Markov random field …",Michael J Black and Stefan Roth,2,13691853668387618433,"Cosyne, Salt Lake City, UT, March",,17-20,,The Receptive Fields of Markov Random Fields,http://scholar.google.com/scholar?cluster=13691853668387618433&hl=en&oi=scholarr,,2005,/scholar?cites=13691853668387618433,6NjbexEAAAAJ:5Ul4iDaHHb8C

1010300,"From the outside it may not be apparent that Brown University has a large, interdisciplinary, and vibrant computer vision community. Despite being a small school (5,674 undergraduate and 1,343 graduate students), Brown has a tightly knit community of vision researchers in various departments. This can be partly seen in this special issue which has contributions from researchers in the Division of Applied Mathematics, the Department of Computer Science, the Division of Engineering, and the Department of Cognitive and Linguistic Sciences. What we find amazing and wonderful about Brown is the high degree of interaction among researchers from these different disciplines. We hope the papers in this special issue give some glimpse into the computational vision research at Brown. Any collection of this type is only a snapshot at an instant in time and cannot hope to capture the full diversity of work going on here …",Michael J Black and Benjamin B Kimia,2,2726654516305374302,International Journal of Computer Vision,1-3,5-11,Kluwer Academic Publishers,Guest editorial: Computational vision at brown,https://link.springer.com/article/10.1023/A:1023788516099,54,2003,/scholar?cites=2726654516305374302,6NjbexEAAAAJ:J-pR_7NvFogC

1010301,"Principal Component Analysis (PCA) has been successfully applied to construct linear models of shape, graylevel, and motion. In particular, PCA has been widely used to model the variation in the appearance of people's faces. We extend previous work on facial modeling for tracking faces in video sequences as they undergo significant changes due to facial expressions. Here we develop person-specific facial appearance models (PSFAM), which use modular PCA to model complex intra-person appearance changes. Such models require aligned visual training data; in previous work, this has involved a time consuming and errorprone hand alignment and cropping process. Instead, we introduce parameterized component analysis to learn a subspace that is invariant to affine (or higher order) geometric transformations. The automatic learning of a PSFAM given a training image sequence is posed as a continuous …",Fernando de la Torre and Michael J Black,2,10717994518933877583,,,653-669,Springer-Verlag,Robust parameterized component analysis,https://dl.acm.org/citation.cfm?id=649253,,2002,/scholar?cites=10717994518933877583,6NjbexEAAAAJ:tuHXwOkdijsC

1010302,"We present a method for the modeling of 3D human motion data using functional analysis. First, we estimate a statistical model of typical activities from a large set of 3D human motion data. For this purpose, the human body is represented as a set of articulated cylinders and the evolution of a particular joint angle is described by a time-series. Specifically, we consider periodic motion such as"" walking"" in this work, and we develop a new set of tools that allows for the automatic segmentation of the training data into a sequence of identical"" motion cycles"". Then we compute the mean and the principal components of these cycles using a new algorithm that accounts for missing information and that enforces smooth transitions between cycles. As an application of this methodology we consider the visual tracking of human motion in a 2D video sequence. Here the principal components serve to define a low-dimensional …",Dirk Ormoneit and Trevor Hastie and MJ Black,2,7861875102179509708,"Proc. 5th World Congress of the Bernoulli Society for Probability and Mathematical Statistics and 63rd Annual Meeting of the Institute of Mathematical Statistics, Guanajuato, Mexico",,,,Functional analysis of human motion data,http://scholar.google.com/scholar?cluster=7861875102179509708&hl=en&oi=scholarr,,2000,/scholar?cites=7861875102179509708,6NjbexEAAAAJ:sSrBHYA8nusC

1010303,"Representational momentum (Freyd, 1987) is a phenomenon in which moving objects are remembered as appearing slightly past their actual final position. Freyd hypothesizes that this memory distortion results from dynamic visual representations that reflect an internalization of the inertial properties of real-world object motion. Moreover, she rejects the possibility that this distortion is the result of sensory mechanisms used for perceiving motion. In contrast, by introducing a temporal persistence constraint into the compution of low-level motion, the distortions associated with representational momentum may be explained by sensory mechanisms within early vision. This constraint simply assumes constant velocity for local surface patches over time. The model employing this constraint entails a highly parallel algorithm for computing velocity fields using information available directly in the intensity array, without …",MJ Tarr and MJ Black,2,10094920687119506929,Investigative Opthamology and Visual Science Supplement,,1050,,Psychophysical implications of temporal persistence in early vision: A computational account of representational momentum,http://scholar.google.com/scholar?cluster=10094920687119506929&hl=en&oi=scholarr,33,1992,/scholar?cites=10094920687119506929,6NjbexEAAAAJ:8AbLer7MMksC

1010304,,Stefan Roth and J Michael,2,3846433814117500181,Fields of Experts.“In: International Journal of Computer Vision,,205-229,,Black (2009).”,http://scholar.google.com/scholar?cluster=3846433814117500181&hl=en&oi=scholarr,82,,/scholar?cites=3846433814117500181,6NjbexEAAAAJ:KjnAay3C9J8C

1010305,,Matthew Loper and Naureen Mahmood and Javier Romero and Gerard Pons-Moll and J Michael,2,18393224294043195293,ACM Transactions on Graphics (TOG),,,,"Black."" SMPL: A skinned multi-person linear model.""",http://scholar.google.com/scholar?cluster=18393224294043195293&hl=en&oi=scholarr,34,,/scholar?cites=18393224294043195293,6NjbexEAAAAJ:8cTaIddhMp4C

1010306,"The SMPL body model is widely used for the estimation, synthesis, and analysis of 3D human pose and shape. While popular, we show that SMPL has several limitations and introduce STAR, which is quantitatively and qualitatively superior to SMPL. First, SMPL has a huge number of parameters resulting from its use of global blend shapes. These dense pose-corrective offsets relate every vertex on the mesh to all the joints in the kinematic tree, capturing spurious long-range correlations. To address this, we define per-joint pose correctives and learn the subset of mesh vertices that are influenced by each joint movement. This sparse formulation results in more realistic deformations and significantly reduces the number of model parameters to 20% of SMPL. When trained on the same data as SMPL, STAR generalizes better despite having many fewer parameters. Second, SMPL factors pose-dependent deformations from body shape while, in reality, people with different shapes deform differently. Consequently, we learn shape-dependent pose-corrective blend shapes that depend on both body pose and BMI. Third, we show that the shape space of SMPL is not rich enough to capture the variation in the human population. We address this by training STAR with an additional 10,000 scans of male and female subjects, and show that this results in better model generalization. STAR is compact, generalizes better to new bodies and is a drop-in replacement for SMPL. STAR is publicly available for research purposes at this http URL.",Ahmed AA Osman and Timo Bolkart and Michael J Black,1,766398854031447932,arXiv preprint arXiv:2008.08535,,,,STAR: Sparse Trained Articulated Human Body Regressor,https://arxiv.org/abs/2008.08535,,2020,/scholar?cites=766398854031447932,6NjbexEAAAAJ:RpHLKABnwqoC

1010307,"The modeling of human motion using machine learning methods has been widely studied. In essence it is a time-series modeling problem involving predicting how a person will move in the future given how they moved in the past. Existing methods, however, typically have a short time horizon, predicting a only few frames to a few seconds of human motion. Here we focus on long-term prediction; that is, generating long sequences (potentially infinite) of human motion that is plausible. Furthermore, we do not rely on a long sequence of input motion for conditioning, but rather, can predict how someone will move from as little as a single pose. Such a model has many uses in graphics (video games and crowd animation) and vision (as a prior for human motion estimation or for dataset creation). To address this problem, we propose a model to generate non-deterministic,\textit {ever-changing}, perpetual human motion, in which the global trajectory and the body pose are cross-conditioned. We introduce a novel KL-divergence term with an implicit, unknown, prior. We train this using a heavy-tailed function of the KL divergence of a white-noise Gaussian process, allowing latent sequence temporal dependency. We perform systematic experiments to verify its effectiveness and find that it is superior to baseline methods.",Yan Zhang and Michael J Black and Siyu Tang,1,10555703936513117078,arXiv preprint arXiv:2007.13886,,,,Perpetual Motion: Generating Unbounded Human Motion,https://arxiv.org/abs/2007.13886,,2020,/scholar?cites=10555703936513117078,6NjbexEAAAAJ:nlKf13ul9_IC

1010308,"Disclosed is a method including receiving an input image including a human, predicting, based on a convolutional neural network that is trained using examples consisting of pairs of sensor data, a corresponding body shape of the human and utilizing the corresponding body shape predicted from the convolutional neural network as input to another convolutional neural network to predict additional body shape metrics.",,1,6481436685185350928,,,,,Machine learning systems and methods of estimating body shape from images,https://patents.google.com/patent/US10679046B1/en,,2020,/scholar?cites=6481436685185350928,6NjbexEAAAAJ:4EsMycecMEYC

1010309,"Animated virtual characters are essential to many applications. Little is known so far about biological and personality inferences made from a virtual character’s body shape and motion. Here, we investigated how sex-specific differences in walking style relate to the perceived attractiveness and confidence of male and female virtual characters. The characters were generated by reconstructing body shape and walking motion from optical motion capture data. The results suggest that sexual dimorphism in walking style plays a different role in attributing biological and personality traits to male and female virtual characters. This finding has important implications for virtual character animation.",Anne Thaler and Andreas Bieg and Naureen Mahmood and Michael J Black and Betty J Mohler and Nikolaus F Troje,1,17019767147037625706,,,679-680,IEEE,Attractiveness and Confidence in Walking Style of Male and Female Virtual Characters,https://ieeexplore.ieee.org/abstract/document/9090610/,,2020,/scholar?cites=17019767147037625706,6NjbexEAAAAJ:-4bc1-6Giq0C

1010310,"A computer-implemented method for automatically obtaining pose and shape parameters of a human body. The method includes obtaining a sequence of digital 3D images of the body, recorded by at least one depth camera; automatically obtaining pose and shape parameters of the body, based on images of the sequence and a statistical body model; and outputting the pose and shape parameters. The body may be an infant body.",,1,12749572534374733432,,,,,Skinned Multi-Person Linear Model,https://patents.google.com/patent/US20200058137A1/en,,2020,/scholar?cites=12749572534374733432,6NjbexEAAAAJ:OxQqgzTNpSoC

1010311,"Our visual system can easily categorize objects (e.g. faces vs. bodies) and further differentiate them into subcategories (e.g. male vs. female). This ability is particularly important for objects of social significance, such as human faces and bodies. While many studies have demonstrated category selectivity to faces and bodies in the brain, how subcategories of faces and bodies are represented remains unclear. Here, we investigated how the brain encodes two prominent subcategories shared by both faces and bodies, sex and weight, and whether neural responses to these subcategories rely on low-level visual, high-level visual or semantic similarity. We recorded brain activity with fMRI while participants viewed faces and bodies that varied in sex, weight, and image size. The results showed that the sex of bodies can be decoded from both body- and face-responsive brain areas, with the former exhibiting more …",Celia Foster and Mintao Zhao and Javier Romero and Michael J Black and Betty J Mohler and Andreas Bartels and Isabelle Bülthoff,1,16936075515104688202,Neuroimage,,116085,Academic Press,Decoding subcategories of human bodies from both body-and face-responsive cortical regions,https://www.sciencedirect.com/science/article/pii/S1053811919306731,202,2019,/scholar?cites=16936075515104688202,6NjbexEAAAAJ:P9oYG7HA76QC

1010312,"Convolutional neural networks (CNNs) have achieved state of the art performance on recognizing and representing audio, images, videos and 3D volumes; that is, domains where the input can be characterized by a regular graph structure. However, generalizing CNNs to irregular domains like 3D meshes is challenging. Additionally, training data for 3D meshes is often limited. In this work, we generalize convolutional autoencoders to mesh surfaces. We perform spectral decomposition of meshes and apply convolutions directly in frequency space. In addition, we use max pooling and introduce upsampling within the network to represent meshes in a low dimensional space. We construct a complex dataset of 20,466 high resolution meshes with extreme facial expressions and encode it using our Convolutional Mesh Autoencoder. Despite limited training data, our method outperforms state-of-the-art PCA models of faces with 50% lower error, while using 75% fewer parameters.",Anurag Ranjan and Timo Bolkart and Michael J Black,1,8801450405199018418,,,,,Convolutional mesh autoencoders for 3d face representation,https://openreview.net/forum?id=SkgYEQ9h4m,,2018,/scholar?cites=8801450405199018418,6NjbexEAAAAJ:qxGx9raSUrEC

1010313,"A study on the flowering plant diversity of Thevarmala sacred grove in the Western Ghats of Kerala region was carried out during the period 2015-2016. During the study a total of 152 species of flowering plants belong to 136 genera under 50 families were documented. Plants in all life forms, viz. herbs (56 species), shrubs (64 species) and trees (32 species) are well represented in the grove. Fabaceae is the dominant family with 15 species in 12 genera followed by Euphorbiaceae and Rubiaceae. As many as 17 families are represented by single species in each. Out of the 152 species 18 are rare endemics especially confined to the southern Western Ghats. About 62% of the documented plants are having economic importance as medicine (76 species), food (8 species), timber (6 species), and fodder (3 species) or as source of commercially useful fibres and resins. 19 species documented in the present study are new record to the Kottayam district of Kerala state. The present conservation status of this sacred grove and future threats are also discussed in this paper.",Anoop P Balan and Bibin Thomas and Joseph Michael,1,5451796875591730816,Int J Adv Res Bot,1,1-11,,"Floristic diversity of Thevarmala sacred grove in Western Ghats, Kerala, India",http://scholar.google.com/scholar?cluster=5451796875591730816&hl=en&oi=scholarr,3,2017,/scholar?cites=5451796875591730816,6NjbexEAAAAJ:yM8WYnMLviIC

1010314,"Dense 3D reconstruction from RGB images is a highly ill-posed problem due to occlusions, textureless or reflective surfaces, as well as other challenges. We propose object-level shape priors to address these ambiguities. Towards this goal, we formulate a probabilistic model that integrates multi-view image evidence with 3D shape information from multiple objects. Inference in this model yields a dense 3D reconstruction of the scene as well as the existence and precise 3D pose of the objects in it. Our approach is able to recover fine details not captured in the input shapes while defaulting to the input models in occluded regions where image evidence is weak. Due to its probabilistic nature, the approach is able to cope with the approximate geometry of the 3D models as well as input shapes that are not present in the scene. We evaluate the approach quantitatively on several challenging indoor and outdoor datasets.",Ali Osman Ulusoy and Michael J Black and Andreas Geiger,1,17847598955715337336,,,2414-2423,,Semantic Multi-view Stereo: Jointly Estimating Objects and Voxels,http://openaccess.thecvf.com/content_cvpr_2017/html/Ulusoy_Semantic_Multi-View_Stereo_CVPR_2017_paper.html,,2017,/scholar?cites=17847598955715337336,6NjbexEAAAAJ:9cqGXoYeWaMC

1010315,"The invention comprises a learned model of human body shape and pose dependent shape variation that is more accurate than previous models and is compatible with existing graphics pipelines. Our Skinned Multi-Person Linear model (SMPL) is a skinned vertex based model that accurately represents a wide variety of body shapes in natural human poses. The parameters of the model are learned from data including the rest pose template, blend weights, pose-dependent blend shapes, identity-dependent blend shapes, and a regressor from vertices to joint locations. Unlike previous models, the pose-dependent blend shapes are a linear function of the elements of the pose rotation matrices. This simple formulation enables training the entire model from a relatively large number of aligned 3D meshes of different people in different poses. The invention quantitatively evaluates variants of SMPL using linear or dual …",,1,17571594016996988703,,,,,Skinned multi-person linear model,https://patents.google.com/patent/WO2016207311A1/en,,2016,/scholar?cites=17571594016996988703,6NjbexEAAAAJ:xmg73Fui0jkC

1010316,"Previous research has suggested that inaccuracies in own body size estimation can largely be explained by a known error in perceived magnitude, called contraction bias (Cornelissen, Bester, Cairns, Tovée & Cornelissen, 2015). According to this, own body size estimation is biased towards an average reference body, such that individuals with a low body mass index (BMI) should overestimate their body size and high BMI individuals should underestimate their body size. However, previous studies have mainly focused on self-body size evaluation of patients suffering from anorexia nervosa. In this study, we tested healthy females varying in BMI to investigate whether personal body size influences accuracy of body size estimation and sensitivity to weight changes, reproducing a scenario of standing in front of a full length mirror. We created personalized avatars with a 4D full-body scanning system that records …",Anne Thaler and Michael Geuss and Simone Molbert and Katrin Giel and Stephan Streuber and Michael Black and Betty Mohler,1,2712332474989314076,Journal of Vision,12,1400-1400,The Association for Research in Vision and Ophthalmology,Investigating the influence of personal BMI on own body size perception in females using self-avatars,https://jov.arvojournals.org/article.aspx?articleid=2551372,16,2016,/scholar?cites=2712332474989314076,6NjbexEAAAAJ:6G1OFF11MdUC

1010317,"Hintergrund: Die Körperbildstörung ist ein Kernsymptom der Anorexia Nervosa (AN). Sie gilt als Indikator für eine schlechte Prognose, als schwierig zu therapieren und besteht oft auch nach Gewichtszunahme fort. Diese Studie verwendet individuelle 3D-Avatare, um folgende Forschungsfragen näher zu untersuchen:(1) Repräsentieren AN Patientinnen körperbezogene Informationen generell anders oder ist die Körperbildstörung rein selbstbezogen?(2) Ist die Körperbildstörung eher perzeptuell oder eher durch dysfunktionale Bewertungen charakterisiert? Methoden: Untersucht werden N= 20 AN-Patientinnen, N= 20 remittierte AN-Patientinnen und N= 20 Kontrollprobandinnen. Von jeder Teilnehmerin wird auf Basis eines 3D-Körperscans ein individueller Avatar mit 9 verschiedenen BMI-Stufen gefertigt, nämlich aktueller BMI und+/-5, 10, 15 und 20 BMI. Um die Rolle des Selbstbezugs zu bestimmen, wird basierend auf der Figur der Teilnehmerin eine zweite Avatar-Serie mit dem Aussehen einer fremden Person erstellt. Die Avatare werden in einer virtuelle Realität-Umgebung lebensgroß und in 3D präsentiert. Das Experiment folgt einem 2x2 gemischten Design mit den Faktoren Gruppe (AN versus Kontrolle) und Avatar-Serie (eigenes versus fremdes Aussehen), wobei es zwei unterschiedliche Aufgabenformate gibt: Im 2 Alternatives Forced Choice Task sieht die Teilnehmerin jeden Avatar 20 Mal für 2 Sekunden, anschließend muss sie entscheiden, ob dies der eigene bzw. richtige oder ein manipulierter Avatar war. Im Method of Adjustment Task soll die Teilnehmerin jeden der Avatare jeweils so verändern, dass er ihrem aktuellen bzw. dem …",SC Mölbert and A Thaler and B Mohler and S Streuber and M Black and HO Karnath and S Zipfel and KE Giel,1,17648006920665518861,,,103-103,,Untersuchung der Körperbildstörung bei Anorexia Nervosa mithilfe biometrischer Avatare in virtueller Realität,https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_2547651,,2016,/scholar?cites=17648006920665518861,6NjbexEAAAAJ:ohlv4i5L2AoC

1010318,"This chapter introduces and summarizes recent work on probabilistic models of motor cortical activity and methods for inferring, or decoding, hand movements from this activity. A simple generalization of previous encoding models is presented in which neural ﬁring rates are represented as a linear function of hand movements. A Bayesian approach is taken to exploit this generative model of ﬁring rates for the purpose of inferring hand kinematics. In particular, we consider approximations of the encoding problem that allow efﬁcient inference of hand movement using a Kalman ﬁlter. Decoding results are presented and the use of these methods for neural prosthetic cursor control is discussed.",Michael J Black and John P Donoghue,1,7319695593464040941,Toward Brain-Computer Interfacing,,147-159,,Probabilistically modeling and decoding neural population activity in motor cortex,http://books.google.com/books?hl=en&lr=&id=V88swGX83ecC&oi=fnd&pg=PA147&dq=info:7Y1qYFzIlGUJ:scholar.google.com&ots=mZWJstaO9T&sig=QuItG8qOa5xPjv2Pifd_VSvhtuc,,2007,/scholar?cites=7319695593464040941,6NjbexEAAAAJ:_B80troHkn4C

1010319,"In the recent years we presented a number of methods for a fully automatic pose estimation [5, 7] and tracking [6] of human bodies in 2D [5] and 3D [6]. Initialization and failure recovery in these methods are facilitated by the use of loose-limbed body model [7] in which limbs are connected via learned probabilistic constraints. The pose estimation and tracking can then be formulated as an inference in a loopy graphical model and approximate belief propagation can be used to estimate the pose of the body at each time-step. Each node in the graphical model represents the position and orientation of the limb, and the directed edges between nodes represent statistical dependencies between limbs.There are a number of significant advantages of this paradigm as compared to the more traditional methods for tracking human motion. Most traditional models of the body resort to the kinematic tree-based representations in 2D, 2.5 D, or 3D leading to a high-dimensional search space. Searching for a body pose in this high dimensional space is impractical, and so most tracking methods rely on manual initialization or a canonical starting pose. Additionally, they often exploit strong priors characterizing the motions present, to speed up the search. The lack of automatic initialization from an arbitrary pose also makes it hard to recover from transient failures that often occur during tracking.",Leonid Sigal and Michael J Black,1,11094203060157731752,"Learning, Representation and Context for Human Sensing in Video Workshop",,24,,Hierarchical Approach for Articulated 3D Pose-Estimation and Tracking,https://www.researchgate.net/profile/Michael_Black6/publication/228794808_Hierarchical_Approach_for_Articulated_3D_Pose-Estimation_and_Tracking_Extended_Abstract/links/0fcfd512d21ebc39ce000000.pdf,23,2006,/scholar?cites=11094203060157731752,6NjbexEAAAAJ:1yQoGdGgb4wC

1010320,"A rail system having a light assembly is provided including a rail for holding a panel and at least one column, wherein the rail includes a recess for attachment to an edge of the panel, wherein the rail and at least one column comprise a housing for the light assembly.",,1,17603793140388726471,,,,,Rail system having light assembly,https://patents.google.com/patent/US20040129167A1/en,,2004,/scholar?cites=17603793140388726471,6NjbexEAAAAJ:Fx7lCCP36QIC

1010321,"The thermal infrared visual object tracking VOT-TIR2016 challenge results Felsberg, 
Michael; Kristian, Matej; Matas, Jiri; Arens, Michael; Krah, Sebastian; Becker, Stefan; 
Hübner, Wolfgang; et. al … The visual object tracking VOT2016 challenge results Kristan, 
Matej; Leonardis, Ales; Matas, Jiri; Becker, Stefan; Krah, Sebastian; Hübner, Wolsgang; 
Arens, Michael; et. al … Supporting fuzzy metric temporal logic based situation recognition by 
mean shift clustering Münch, D.; Michaelsen, E.; Arens, M … 6-DoF model-based tracking of 
arbitrarily shaped 3D objects Azad, P.; Münch, D.; Asfour, T.; Dillmann, R … An implicit shape 
model based approach to identify armed persons Becker, S.; Jüngling, K … Monocular camera 
trajectory optimization using LiDAR data Bodensteiner, C.; Hübner, W.; Jüngling, K.; Solbrig, 
P.; Arens, M … Detecting and tracking people and their body parts in infrared Jüngling … ",Stefan Becker and Norbert Scherer-Negenborn and Pooja Thakkar and Wolfgang Hübner and Michael Arens and Sebastian B Krah and Hilke Kieritz and Sebastian Bullinger and Christoph Bodensteiner and Sebastian Wuttke and Leo Doktorski and Qian Du and Eckart Michaelsen and Bing Zhang and Jocelyn Chanussot and Michael Felsberg and Matej Kristian and Jiri Matas and Sebastian Krah,1,15777358551790227390,,,,,/Author,"http://publica.fraunhofer.de/jsp/StarXmlQuery?style=iosb.xsl&sort=author&query=inst=%28iosb;iitb;fom%29+and+dept=240*+and+bdate=%282007*:2019*%29+and+author=%28becker,%20s*;muench*;brauer*;kieritz*;huebner,%20w*;juengling,%20k*;klinger,%20v*;%20mueller,%20j*;%20hilsenbeck,%20b*;%20hug,%20r*%29",,2004,/scholar?cites=15777358551790227390,6NjbexEAAAAJ:FSl0EHHYj-kC

1010322,"CiNii 国立情報学研究所 学術情報ナビゲータ[サイニィ]. メニュー 検索 … 
",MJ Black,1,11114580563071084253,CVIU,1,,,The robust estimation of multiple motions: parametric and piecewise-smooth flow fields,https://ci.nii.ac.jp/naid/10026743009/,63,2000,/scholar?cites=11114580563071084253,6NjbexEAAAAJ:3YTBxAczQXIC

1010323,"diva-portal.org. Please wait … 
",Dirk Ormoneit and Hedvig Sidenbladh and Michael J Black,1,4056189542945824077,,,,,Stochastic modeling and tracking of human motion,https://www.diva-portal.org/smash/record.jsf?pid=diva2:436227,,2000,/scholar?cites=4056189542945824077,6NjbexEAAAAJ:2KloaMYe4IUC

1010324,"This paper addresses the problem of recovering time-to-contact by actively tracking motion boundaries. Unlike previous approaches which use image features, we use the camera's own motion to both detect and track object boundaries. First we develop a framework in which the boundaries of objects are automatically detected using the motion parallax caused by the motion of an active camera. We use a correlation-based method to locate motion boundaries and our work has focused on detecting the motion boundaries early and robustly. A confidence field, which expresses the likelihood that a point lies on a motion boundary, is constructed from the shape of the correlation surface. Spatial coherence of object boundaries is modeled with dynamic contours which are automatically initialized using an attentional mechanism. Then, as the camera moves, the shapes of the dynamic contours are held fixed and they are …",Shanon Xuan Ju and Michael J Black,1,339424269915665478,,,26-37,International Society for Optics and Photonics,Time to contact from active tracking of motion boundaries,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/2354/0000/Time-to-contact-from-active-tracking-of-motion-boundaries/10.1117/12.189107.short,2354,1994,/scholar?cites=339424269915665478,6NjbexEAAAAJ:tS2w5q8j5-wC

1010325,"Author: Ambler M, Journal: Nursing times[1968/08].
",M Ambler and JA Anderson and M Black and P Draper and J Lewis and W Moss and TG Murrell,1,14174803024895013003,Nursing times,34,Suppl: 129-32,,Attachment of local health authority staff to general practices. 1. A study in three county boroughs with special reference to health visiting.,https://europepmc.org/article/med/5672681,64,1968,/scholar?cites=14174803024895013003,6NjbexEAAAAJ:LimhlhUO2s4C

1010326,"111 thi.) puper, we present un uutomutic. system fi, r UII-ulyzing and unnotuting video sequences of trchnicrd tulks. Our method uses U robust motion estiniution tec, hnique tci detect ke~ frunzes und segment the video sequence into subsequences cmtuining a single overhead slide. The subsequences ure stabilized to re-move motion that omm when the speukeradjusts their slides. Any chunges remuining between frunzes in the stubilized sequencxs muy be due to speuker gestures such us pointing or writing and we use uc-tive c~ intour.~ to automaticdl~ truck these potential gestures. Given the construined domuin we dejine U simple “voc-ubu-1un.” cguctions which~’un eusily be recognized bused on the active c~ intour shupe and motion. The recog-nized actions provide U rich unnotution ofthe sequence that cun be used to ucces. sa condensed version of the tulk from U web puge.",Michael J Black and Scott Minneman and Don Kimber,1,1840315885452505405,C om pu t er,,,,Analysis of Gesture and Action in Technical Talks for Video Indexing,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.871.9623&rep=rep1&type=pdf,1,,/scholar?cites=1840315885452505405,6NjbexEAAAAJ:oLQGhPHTrpcC

1010327,"While current monocular 3D face reconstruction methods can recover fine geometric details, they suffer several limitations. Some methods produce faces that cannot be realistically animated because they do not model how wrinkles vary with expression. Other methods are trained on high-quality face scans and do not generalize well to in-the-wild images. We present the first approach to jointly learn a model with animatable detail and a detailed 3D face regressor from in-the-wild images that recovers shape details as well as their relationship to facial expressions. Our DECA (Detailed Expression Capture and Animation) model is trained to robustly produce a UV displacement map from a low-dimensional latent representation that consists of person-specific detail parameters and generic expression parameters, while a regressor is trained to predict detail, shape, albedo, expression, pose and illumination parameters from a single image. We introduce a novel detail-consistency loss to disentangle person-specific details and expression-dependent wrinkles. This disentanglement allows us to synthesize realistic person-specific wrinkles by controlling expression parameters while keeping person-specific details unchanged. DECA achieves state-of-the-art shape reconstruction accuracy on two benchmarks. Qualitative results on in-the-wild data demonstrate DECA's robustness and its ability to disentangle identity and expression dependent details enabling animation of reconstructed faces. The model and code are publicly available at this https URL.",Yao Feng and Haiwen Feng and Michael J Black and Timo Bolkart,0,,arXiv preprint arXiv:2012.04012,,,,Learning an Animatable Detailed 3D Face Model from In-The-Wild Images,https://arxiv.org/abs/2012.04012,,2020,,6NjbexEAAAAJ:A8NefVh_EAoC

1010328,"A key step towards understanding human behavior is the prediction of 3D human motion. Successful solutions have many applications in human tracking, HCI, and graphics. Most previous work focuses on predicting a time series of future 3D joint locations given a sequence 3D joints from the past. This Euclidean formulation generally works better than predicting pose in terms of joint rotations. Body joint locations, however, do not fully constrain 3D human pose, leaving degrees of freedom undefined, making it hard to animate a realistic human from only the joints. Note that the 3D joints can be viewed as a sparse point cloud. Thus the problem of human motion prediction can be seen as point cloud prediction. With this observation, we instead predict a sparse set of locations on the body surface that correspond to motion capture markers. Given such markers, we fit a parametric body model to recover the 3D shape and pose of the person. These sparse surface markers also carry detailed information about human movement that is not present in the joints, increasing the naturalness of the predicted motions. Using the AMASS dataset, we train MOJO, which is a novel variational autoencoder that generates motions from latent frequencies. MOJO preserves the full temporal resolution of the input motion, and sampling from the latent frequencies explicitly introduces high-frequency components into the generated motion. We note that motion prediction methods accumulate errors over time, resulting in joints or markers that diverge from true human bodies. To address this, we fit SMPL-X to the predictions at each time step, projecting the solution back onto …",Yan Zhang and Michael J Black and Siyu Tang,0,,arXiv preprint arXiv:2012.00619,,,,We are More than Our Joints: Predicting how 3D Bodies Move,https://arxiv.org/abs/2012.00619,,2020,,6NjbexEAAAAJ:kbDB7uaqCfAC

1010329,"This study provides a comprehensive assessment of own body representation and linguistic representation of bodies in general in women with typical and atypical anorexia nervosa (AN).In a series of desktop experiments, participants rated a set of adjectives according to their match with a series of computer generated bodies varying in body mass index, and generated prototypic body shapes for the same set of adjectives. We analysed how body mass index of the bodies was associated with positive or negative valence of the adjectives in the different groups. Further, body image and own body perception were assessed.In a German‐Italian sample comprising 39 women with AN, 20 women with atypical AN and 40 age matched control participants, we observed effects indicative of weight stigmatization, but no significant differences between the groups. Generally, positive adjectives …",Simone Claire Behrens and Paolo Meneguzzo and Angela Favaro and Martin Teufel and Eva‐Maria Skoda and Marion Lindner and Lukas Walder and Alejandra Quiros Ramirez and Stephan Zipfel and Betty Mohler and Michael Black and Katrin E Giel,0,,European Eating Disorders Review,,,,Weight bias and linguistic body representation in anorexia nervosa: Findings from the BodyTalk project,https://onlinelibrary.wiley.com/doi/abs/10.1002/erv.2812,,2020,,6NjbexEAAAAJ:UUAsIpEgjrcC

1010330,"High fidelity digital 3D environments have been proposed in recent years, however, it remains extremely challenging to automatically equip such environment with realistic human bodies. Existing work utilizes images, depth or semantic maps to represent the scene, and parametric human models to represent 3D bodies. While being straightforward, their generated human-scene interactions are often lack of naturalness and physical plausibility. Our key observation is that humans interact with the world through body-scene contact. To synthesize realistic human-scene interactions, it is essential to effectively represent the physical contact and proximity between the body and the world.To that end, we propose a novel interaction generation method, named PLACE (Proximity Learning of Articulation and Contact in 3D Environments), which explicitly models the proximity between the human body and the 3D scene around it. Specifically, given a set of basis points on a scene mesh, we leverage a conditional variational autoencoder to synthesize the minimum distances from the basis points to the human body surface. The generated proximal relationship exhibits which region of the scene is in contact with the person. Furthermore, based on such synthesized proximity, we are able to effectively obtain expressive 3D human bodies that interact with the 3D scene naturally. Our perceptual study shows that PLACE significantly improves the state-of-the-art method, approaching the realism of real",Siwei Zhang and Yan Zhang and Qianli Ma and Michael J Black and Siyu Tang,0,,,,,,PLACE: Proximity Learning of Articulation and Contact in 3D Environments,https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/452857/1/PLACE-ProximityLearningofArticulationandContactin3DEnvironments.pdf,,2020,,6NjbexEAAAAJ:qLQjcG-1Y3AC

1010331,"Occlusion boundaries contain rich perceptual information about the underlying scene structure and provide important cues in many visual perception-related tasks such as object recognition, segmentation, motion estimation, scene understanding, and autonomous navigation. However, there is no formal definition of occlusion boundaries in the literature, and state-of-the-art occlusion boundary detection is still suboptimal. With this in mind, in this paper we propose a formal definition of occlusion boundaries for related studies. Further, based on a novel idea, we develop two concrete approaches with different characteristics to detect occlusion boundaries in video sequences via enhanced exploration of contextual information (e.g., local structural boundary patterns, observations from surrounding regions, and temporal context) with deep models and conditional random fields. Experimental evaluations of our methods …",Chaohui Wang and Huan Fu and Dacheng Tao and Michael Black,0,,IEEE Transactions on Pattern Analysis and Machine Intelligence,,,IEEE,Occlusion Boundary: A Formal Definition & Its Detection via Deep Exploration of Context,https://ieeexplore.ieee.org/abstract/document/9264681/,,2020,,6NjbexEAAAAJ:Ba4ZglSFa04C

1010332,"A method for generating a body shape, comprising: receiving one or more linguistic descriptors related to the body shape; retrieving an association between the one or more linguistic descriptors and a body shape; and generating the body shape, based on the association.",,0,,,,,,Crowdshaping realistic 3D avatars with words,https://patents.google.com/patent/US10818062B2/en,,2020,,6NjbexEAAAAJ:IsfZ5sDDKYkC

1010333,"Human gait patterns are rich in socially relevant information. While many studies have investigated sex-specific differences in walking style, little is known about how sexual dimorphism relates to the perceived attractiveness and confidence of a person. In two studies, 40 observers (20 female, 20 male) rated the attractiveness and another 36 observers (18 female, 18 male) rated the confidence of 50 men and 50 women from the bmlRUB motion capture database, each presented in three different ways in virtual reality:(a) as a 3D virtual character with each actor's individual shape and walking motion reconstructed from optical motion capture data using the MoSh algorithm (Loper et al. 2014, SIGGRAPH Asia),(b) as a static virtual character, and (c) as a walking stick-figure (Troje 2002, JOV). Correlations between all 12 sets of ratings (2 walker sex x 2 participant sex x 3 presentation types) of the two datasets revealed …",Anne Thaler and Andreas Bieg and Naureen Mahmood and Michael J Black and Betty J Mohler and Nikolaus F Troje,0,,Journal of Vision,11,878-878,The Association for Research in Vision and Ophthalmology,The Role of Sexual Dimorphism in the Perception of Attractiveness and Confidence,https://jov.arvojournals.org/article.aspx?articleid=2771830,20,2020,,6NjbexEAAAAJ:8p-ueveQw4wC

1010334,"The study of the morphology of the human spine has attracted research attention for its many potential applications, such as image segmentation, bio-mechanics or pathology detection. However, as of today there is no publicly available statistical model of the 3D surface of the full spine. This is mainly due to the lack of openly available 3D data where the full spine is imaged and segmented. In this paper we propose to learn a statistical surface model of the full-spine (7 cervical, 12 thoracic and 5 lumbar vertebrae) from partial and incomplete views of the spine. In order to deal with the partial observations we use probabilistic principal component analysis (PPCA) to learn a surface shape model of the full spine. Quantitative evaluation demonstrates that the obtained model faithfully captures the shape of the population in a low dimensional space and generalizes to left out data. Furthermore, we show that the model …",Di Meng and Marilyn Keller and Edmond Boyer and Michael Black and Sergi Pujades,0,,,,122-133,"Springer, Cham",Learning a statistical full spine model from partial observations,https://link.springer.com/chapter/10.1007/978-3-030-61056-2_10,,2020,,6NjbexEAAAAJ:4oLgDUE9yTUC

1010335,"Present application refers to a method, a model generation unit and a computer program (product) for generating trained models (M) of moving persons, based on physically measured person scan data (S). The approach is based on a common template (T) for the respective person and on the measured person scan data (S) in different shapes and different poses. Scan data are measured with a 3D laser scanner. A generic personal model is used for co-registering a set of person scan data (S) aligning the template (T) to the set of person scans (S) while simultaneously training the generic personal model to become a trained person model (M) by constraining the generic person model to be scan-specific, person-specific and pose-specific and providing the trained model (M), based on the co-registering of the measured object scan data (S).",,0,,,,,,Co-registration—simultaneous alignment and modeling of articulated 3D shapes,https://patents.google.com/patent/US10755464B2/en,,2020,,6NjbexEAAAAJ:plawwrVfPpoC

1010336,"Recent advances in deep generative models have led to an unprecedented level of realism for synthetically generated images of humans. However, one of the remaining fundamental limitations of these models is the ability to flexibly control the generative process, eg change the camera and human pose while retaining the subject identity. At the same time, deformable human body models like SMPL and its successors provide full control over pose and shape, but rely on classic computer graphics pipelines for rendering. Such rendering pipelines require explicit mesh rasterization that (a) does not have the potential to fix artifacts or lack of realism in the original 3D geometry and (b) until recently, were not fully incorporated into deep learning frameworks. In this work, we propose to bridge the gap between classic geometry-based rendering and the latest generative networks operating in pixel space by introducing a neural rasterizer, a trainable neural network module that directly"" renders"" a sparse set of 3D mesh vertices as photorealistic images, avoiding any hardwired logic in pixel colouring and occlusion reasoning. We train our model on a large corpus of human 3D models and corresponding real photos, and show the advantage over conventional differentiable renderers both in terms of the level of photorealism and rendering efficiency.",Sergey Prokudin and Michael J Black and Javier Romero,0,,arXiv preprint arXiv:2008.06872,,,,SMPLpix: Neural Avatars from 3D Human Models,https://arxiv.org/abs/2008.06872,,2020,,6NjbexEAAAAJ:gOF0WX6RF1sC

1010337,"High fidelity digital 3D environments have been proposed in recent years; however, it remains extreme challenging to automatically equip such environment with realistic human bodies. Existing work utilizes images, depths, or semantic maps to represent the scene, and parametric human models to represent 3D bodies in the scene. While being straightforward, their generated human-scene interactions are often lack of naturalness and physical plausibility. Our key observation is that humans interact with the world through body-scene contact. To explicitly and effectively represent the physical contact between the body and the world is essential for modeling human-scene interaction. To that end, we propose a novel interaction representation, which explicitly encodes the proximity between the human body and the 3D scene around it. Specifically, given a set of basis points on a scene mesh, we leverage a conditional variational autoencoder to synthesize the distance from every basis point to its closest point on a human body. The synthesized proximal relationship between the human body and the scene can indicate which region a person tends to contact. Furthermore, based on such synthesized proximity, we can effectively obtain expressive 3D human bodies that naturally interact with the 3D scene. Our perceptual study shows that our model significantly improves the state-of-the-art method, approaching the realism of real human-scene interaction. We believe our method makes an important step towards the fully automatic synthesis of realistic 3D human bodies in 3D scenes. Our code and model will be publicly available for research purpose.",Siwei Zhang and Yan Zhang and Qianli Ma and Michael J Black and Siyu Tang,0,,arXiv preprint arXiv:2008.05570,,,,Generating Person-Scene Interactions in 3D Scenes,https://arxiv.org/abs/2008.05570,,2020,,6NjbexEAAAAJ:UIW7YHcmbUEC

1010338,"In recent years, substantial progress has been made on robotic grasping of household objects. Yet, human grasps are still difficult to synthesize realistically. There are several key reasons:(1) the human hand has many degrees of freedom (more than robotic manipulators);(2) the synthesized hand should conform naturally to the object surface; and (3) it must interact with the object in a semantically and physical plausible manner. To make progress in this direction, we draw inspiration from the recent progress on learning-based implicit representations for 3D object reconstruction. Specifically, we propose an expressive representation for human grasp modelling that is efficient and easy to integrate with deep neural networks. Our insight is that every point in a three-dimensional space can be characterized by the signed distances to the surface of the hand and the object, respectively. Consequently, the hand, the object, and the contact area can be represented by implicit surfaces in a common space, in which the proximity between the hand and the object can be modelled explicitly. We name this 3D to 2D mapping as Grasping Field, parameterize it with a deep neural network, and learn it from data. We demonstrate that the proposed grasping field is an effective and expressive representation for human grasp generation. Specifically, our generative model is able to synthesize high-quality human grasps, given only on a 3D object point cloud. The extensive experiments demonstrate that our generative model compares favorably with a strong baseline. Furthermore, based on the grasping field representation, we propose a deep network for the …",Korrawe Karunratanakul and Jinlong Yang and Yan Zhang and Michael Black and Krikamol Muandet and Siyu Tang,0,,arXiv preprint arXiv:2008.04451,,,,Grasping Field: Learning Implicit Representations for Human Grasps,https://arxiv.org/abs/2008.04451,,2020,,6NjbexEAAAAJ:oC1yQlCKEqoC

1010339,"In this letter, we introduce a deep reinforcement learning (DRL) based multi-robot formation controller for the task of autonomous aerial human motion capture (MoCap). We focus on vision-based MoCap, where the objective is to estimate the trajectory of body pose, and shape of a single moving person using multiple micro aerial vehicles. State-of-the-art solutions to this problem are based on classical control methods, which depend on hand-crafted system, and observation models. Such models are difficult to derive, and generalize across different systems. Moreover, the non-linearities, and non-convexities of these models lead to sub-optimal controls. In our work, we formulate this problem as a sequential decision making task to achieve the vision-based motion capture objectives, and solve it using a deep neural network-based RL method. We leverage proximal policy optimization (PPO) to train a stochastic …",Rahul Tallamraju and Nitin Saini and Elia Bonetto and Michael Pabst and Yu Tang Liu and Michael J Black and Aamir Ahmad,0,,IEEE Robotics and Automation Letters,4,6678-6685,IEEE,AirCapRL: Autonomous Aerial Human Motion Capture using Deep Reinforcement Learning,https://ieeexplore.ieee.org/abstract/document/9158379/,5,2020,,6NjbexEAAAAJ:eeRCOjARQ4cC

1010340,"Children with motor development disorders benefit greatly from early interventions. An early diagnosis in pediatric preventive care (U2-U5) can be improved by automated screening. Current approaches to automated motion analysis, however, are expensive, require lots of technical support, and cannot be used in broad clinical application. Here we present an inexpensive, marker-free video analysis tool (KineMAT) for infants, which digitizes 3‑D movements of the entire body over time allowing automated analysis in the future. Three-minute video sequences of spontaneously moving infants were recorded with a commercially available depth-imaging camera and aligned with a virtual infant body model (SMIL model). The virtual image generated allows any measurements to be carried out in 3‑D with high precision. We demonstrate seven infants with different diagnoses. A selection of possible movement parameters was quantified and aligned with diagnosis-specific movement characteristics. KineMAT and the SMIL model allow reliable, three-dimensional measurements of spontaneous activity in infants with a very low error rate. Based on machine-learning algorithms, KineMAT can be trained to automatically recognize pathological spontaneous motor skills. It is inexpensive and easy to use and can be developed into a screening tool for preventive care for children.",Carmen Parisi and Nikolas Hesse and Uta Tacke and A Blaschek and M Hadders-Algra and MJ Black and F Heinen and W Müller-Felber and AS Schroeder,0,,,7,881-890,,Analysis of motor development within the first year of life: 3-D motion tracking without markers for early detection of developmental disorders,https://europepmc.org/article/med/32572501,63,2020,,6NjbexEAAAAJ:t4WtaE3RIIAC

1010341,"Accurately segmenting MRI images is crucial for many clinical applications. However, manually segmenting images with accurate pixel precision is a tedious and time consuming task. In this paper we present a simple, yet effective method to improve the efficiency of the image segmentation process. We propose to transform the image annotation task into a binary choice task. We start by using classical image processing algorithms with different parameter values to generate multiple, different segmentation masks for each input MRI image. Then, the user, instead of segmenting the pixels of the images, she/he only needs to decide if a segmentation is acceptable or not. This method allows us to efficiently obtain high quality segmentations with minor human intervention. With the selected segmentations we train a state-of-the-art neural network model. For the evaluation, we use a second MRI dataset (1.5T Dataset), acquired with a different protocol and containing annotations. We show that the trained network i) is capable to automatically segment cases where none of the classical methods obtained a high quality result ii) generalizes to the second MRI dataset, which was acquired with a different protocol and never seen at training time ; and iii) allows to detect miss-annotations in this second dataset. Quantitatively, the trained network obtains very good results : DICE score - mean 0.98, median 0.99- and Hausdorff distance (in pixels) - mean 4.7, median 2.0-.",Rajat Thankur and Sergi Pujades and Lavika Goel and Rolf Pohmann and Jürgen Machann and Michael J Black,0,,,,,,GENTEL: GENerating Training data Efficiently for Learning to segment medical images,https://hal.inria.fr/hal-02988367/,,2020,,6NjbexEAAAAJ:d2hLqSNro9AC

1010342,"Kinder mit motorischer Entwicklungsstörung profitieren von einer frühen Entwicklungsförderung. Eine frühe Diagnosestellung in der kinderärztlichen Vorsorge (U2–U5) kann durch ein automatisiertes Screening verbessert werden. Bisherige Ansätze einer automatisierten Bewegungsanalyse sind jedoch teuer und aufwendig und nicht in der Breite anwendbar. In diesem Beitrag soll ein neues System zur Videoanalyse, das Kinematic Motion Analysis Tool (KineMAT) vorgestellt werden. Es kann bei Säuglingen angewendet werden und kommt ohne Körpermarker aus. Die Methode wird anhand von 7 Patienten mit unterschiedlichen Diagnosen demonstriert.Mit einer kommerziell erhältlichen Tiefenbildkamera (RGB-D[Red-Green-Blue-Depth]-Kamera) werden 3‑minütige Videosequenzen von sich spontan bewegenden Säuglingen aufgenommen und mit einem virtuellen Säuglingskörpermodell (SMIL[Skinned Multi …",Carmen Parisi and Nikolas Hesse and Uta Tacke and Sergi Pujades Rocamora and Astrid Blaschek and Mijna Hadders-Algra and Michael J Black and Florian Heinen and Wolfgang Müller-Felber and A Sebastian Schroeder,0,,,,1-10,Springer Berlin Heidelberg,Analyse der Spontanmotorik im 1. Lebensjahr: Markerlose 3-D-Bewegungserfassung zur Früherkennung von Entwicklungsstörungen,https://link.springer.com/article/10.1007/s00103-020-03163-2,,2020,,6NjbexEAAAAJ:kmGFBRAO0EoC

1010343,"A system generates a clothing deformation model which models one or more of a pose-dependent clothing shape variation which is induced by underlying body pose parameters, a pose-independent clothing shape variation which is induced by clothing size and underlying body shape parameters and a clothing shape variation including a combination of the pose-dependent clothing shape variation and/or the pose-independent clothing shape variation. The system generates, for an input human body, a custom-shaped garment associated with a clothing type by mapping, via the clothing deformation model, body shape parameters of the input human body to clothing shape parameters of the clothing type and dresses the input human body with the custom-shaped garment.",,0,,,,,,System and method for simulating realistic clothing,https://patents.google.com/patent/US10529127B2/en,,2020,,6NjbexEAAAAJ:-pSblevFsSkC

1010344,"The invention comprises a learned model of human body shape and pose dependent shape variation that is more accurate than previous models and is compatible with existing graphics pipelines. Our Skinned Multi-Person Linear model (SMPL) is a skinned vertex based model that accurately represents a wide variety of body shapes in natural human poses. The parameters of the model are learned from data including the rest pose template, blend weights, pose-dependent blend shapes, identity-dependent blend shapes, and a regressor from vertices to joint locations. Unlike previous models, the pose-dependent blend shapes are a linear function of the elements of the pose rotation matrices. This simple formulation enables training the entire model from a relatively large number of aligned 3D meshes of different people in different poses. The invention quantitatively evaluates variants of SMPL using linear or dual …",,0,,,,,,Skinned multi-person linear model,https://patents.google.com/patent/US20190392626A1/en,,2019,,6NjbexEAAAAJ:HjGq7OYTVFUC

1010345,"Disclosed are computer-readable devices, systems and methods for generating a model of a clothed body. The method includes generating a model of an unclothed human body, the model capturing a shape or a pose of the unclothed human body, determining two-dimensional contours associated with the model, and computing deformations by aligning a contour of a clothed human body with a contour of the unclothed human body. Based on the two-dimensional contours and the deformations, the method includes generating a first two-dimensional model of the unclothed human body, the first two-dimensional model factoring the deformations of the unclothed human body into one or more of a shape variation component, a viewpoint change, and a pose variation and learning an eigen-clothing model using principal component analysis applied to the deformations, wherein the eigen-clothing model classifies …",,0,,,,,,Parameterized Model of 2D Articulated Human Shape,https://patents.google.com/patent/US20190385381A1/en,,2019,,6NjbexEAAAAJ:_xmTp9Pj6u8C

1010346,"A method for providing a three-dimensional body model which may be applied for an animation, based on a moving body, wherein the method comprises providing a parametric three-dimensional body model, which allows shape and pose variations; applying a standard set of body markers; optimizing the set of body markers by generating an additional set of body markers and applying the same for providing 3D coordinate marker signals for capturing shape and pose of the body and dynamics of soft tissue; and automatically providing an animation by processing the 3D coordinate marker signals in order to provide a personalized three-dimensional body model, based on estimated shape and an estimated pose of the body by means of predicted marker locations.",,0,,,,,,Method for providing a three dimensional body model,https://patents.google.com/patent/US10417818B2/en,,2019,,6NjbexEAAAAJ:aKos2Y7kUz0C

1010347,"Our visual system allows us to recognize familiar individuals across different viewpoints, despite large differences in low-level visual information. Previous neuroimaging research has shown that there is a hierarchical organisation across face-responsive brain regions, with lower-level regions representing head viewpoint and higher-level regions representing face identity. In this study, we investigated whether a similar hierarchy is present in body-responsive brain regions, as we also see bodies from many different viewpoints and psychological research has shown we also use information from the body for identification. Furthermore, we investigated whether representations of viewpoint and identity are face and body specific, or generalise to a common representation. We trained participants to recognize three individuals from images of their face and body. We then recorded their brain activity using fMRI while they viewed images of the face and body (shown separately) of the individuals from different viewpoints. Participants responded to the identity or viewpoint, revealing differences in neural representation depending on which feature participants attended to. We found that the occipital face area and extrastriate body area contain representations of face and body viewpoint, and that these viewpoint representations generalize across the face and body (eg a classifier trained to distinguish viewpoint of faces could decode viewpoint of bodies). Furthermore, we found that the fusiform body area (FBA) represents body identity in a viewpoint-invariant manner. We decoded face identity in the FBA, and also found a trend in the anterior temporal face …",Celia Foster and Mintao Zhao and Timo Bolkart and Michael J Black and Andreas Bartels and Isabelle Bülthoff,0,,,,54-55,"Scholar One, Inc.",Decoding the Viewpoint and Identity of Faces and Bodies,https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_3050004,,2019,,6NjbexEAAAAJ:wNvz2w4be3AC

1010348,"The invention comprises a learned model of human body shape and pose dependent shape variation that is more accurate than previous models and is compatible with existing graphics pipelines. Our Skinned Multi-Person Linear model (SMPL) is a skinned vertex based model that accurately represents a wide variety of body shapes in natural human poses. The parameters of the model are learned from data including the rest pose template, blend weights, pose-dependent blend shapes, identity-dependent blend shapes, and a regressor from vertices to joint locations. Unlike previous models, the pose-dependent blend shapes are a linear function of the elements of the pose rotation matrices. This simple formulation enables training the entire model from a relatively large number of aligned 3D meshes of different people in different poses. The invention quantitatively evaluates variants of SMPL using linear or dual …",,0,,,,,,Skinned multi-person linear model,https://patents.google.com/patent/US10395411B2/en,,2019,,6NjbexEAAAAJ:M6kHaddf_34C

1010349,"Disclosed are computer-readable devices, systems and methods for generating a model of a clothed body. The method includes generating a model of an unclothed human body, the model capturing a shape or a pose of the unclothed human body, determining two-dimensional contours associated with the model, and computing deformations by aligning a contour of a clothed human body with a contour of the unclothed human body. Based on the two-dimensional contours and the deformations, the method includes generating a first two-dimensional model of the unclothed human body, the first two-dimensional model factoring the deformations of the unclothed human body into one or more of a shape variation component, a viewpoint change, and a pose variation and learning an eigen-clothing model using principal component analysis applied to the deformations, wherein the eigen-clothing model classifies …",,0,,,,,,Parameterized model of 2D articulated human shape,https://patents.google.com/patent/US10388078B2/en,,2019,,6NjbexEAAAAJ:EsO17nB32j8C

1010350,"A system generates a clothing deformation model which models one or more of a pose-dependent clothing shape variation which is induced by underlying body pose parameters, a pose-independent clothing shape variation which is induced by clothing size and underlying body shape parameters and a clothing shape variation including a combination of the pose-dependent clothing shape variation and/or the pose-independent clothing shape variation. The system generates, for an input human body, a custom-shaped garment associated with a clothing type by mapping, via the clothing deformation model, body shape parameters of the input human body to clothing shape parameters of the clothing type and dresses the input human body with the custom-shaped garment.",,0,,,,,,System and method for simulating realistic clothing,https://patents.google.com/patent/US10347041B2/en,,2019,,6NjbexEAAAAJ:m5Mwo8ouzesC

1010351,"Previous research on own visual body size estimation has only looked at estimates made by comparing own body size to a test body viewed in third-person perspective. However, people spend relatively little time seeing their body from this perspective as compared to the first-person perspective. Here, we asked whether the visual perspective on the body influences the accuracy of estimating own body dimensions. A 3D virtual test body was presented in life-size in immersive virtual reality either from a first-or a third-person perspective. In a method of adjustment task, participants adjusted a varying number of the test body's dimensions (weight, leg length, arm span, hip width, and upper torso area) to match their own body. Results showed that participants were more accurate in estimating own body dimensions in the third-person perspective condition, suggesting that our mental body image is informed by viewing the own body as a whole, such as in a full-length mirror.",Anne Thaler and Sergi Pujades and Isabelle Bülthoff and M Black and Betty J Mohler,0,,,,73,Pion Ltd.,Body size estimation: The influence of visual perspective,https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_2621375,,2019,,6NjbexEAAAAJ:c3oc_9pK2TEC

1010352,"We propose a novel end-to-end trainable framework for the graph decomposition problem. The minimum cost multicut problem is first converted to an unconstrained binary cubic formulation where cycle consistency constraints are incorporated into the objective function. The new optimization problem can be viewed as a Conditional Random Field (CRF) in which the random variables are associated with the binary edge labels of the initial graph and the hard constraints are introduced in the CRF as high-order potentials. The parameters of a standard Neural Network and the fully differentiable CRF can be optimized in an end-to-end manner. We demonstrate the proposed learning algorithm in the context of clustering of hand written digits, particularly in a setting where no direct supervision for the graph decomposition task is available, and multiple person pose estimation from images in the wild. The experiments validate the effectiveness of our approach both for the feature learning and for the final clustering task.",Jie Song and Bjoern Andres and Michael Black and Otmar Hilliges and Siyu Tang,0,,,,,,Learning Graph Decomposition,https://openreview.net/forum?id=SkeZEhR5FQ,,2018,,6NjbexEAAAAJ:8aAMN6PqWdYC

1010353,"The individual shape of the human body, including the geometry of its articulated structure and the distribution of weight over that structure, influences the kinematics of a person's movements. How sensitive is the visual system to inconsistencies between shape and motion introduced by retargeting motion from one person onto the shape of another? We used optical motion capture to record five pairs of male performers with large differences in body weight, while they pushed, lifted, and threw objects. Based on a set of 67 markers, we estimated both the kinematics of the actions as well as the performer's individual body shape. To obtain consistent and inconsistent stimuli, we created animated avatars by combining the shape and motion estimates from either a single performer or from different performers. In a virtual reality environment, observers rated the perceived weight or thrown distance of the objects. They …",Sophie Kenny and Naureen Mahmood and Claire Honda and Michael J Black and Nikolaus F Troje,0,,,,1-7,,Effects of animation retargeting on perceived action outcomes,https://dl.acm.org/doi/abs/10.1145/3119881.3119891,,2017,,6NjbexEAAAAJ:iqOphse3MeQC

1010354,"Humans can easily categorize images of human bodies and faces according to their sex/gender and weight. Objectively speaking this is a difficult task due to category-independent variability in image size, lighting, facial expression and body sex and weight of faces and bodies, and whether the representations would be face-or body-selective. We used fMRI to record the brain activity of subjects viewing faces and bodies that varied in sex, weight, and image size (factor 2). Using multivoxel pattern analyses, we found that the extrastriate body area (EBA), fusiform body area (FBA) and occipital face area (OFA) consistently discriminated bodies of different sexes, including in a cross-classification analysis where training and test data were based on different stimulus sizes. Body weight could be decoded in OFA and FFA, size-invariantly in the latter. When voxels of body-regions were pooled, the sex and weight of bodies could be decoded invariant with respect to image size. No region consistently decoded the sex or weight of faces, nor did face-related decoding work when voxels were pooled across face-or bodyselective regions. We hypothesize that this may be due to the fact that neither weight nor sex appeared very prominently in controlled face stimuli used here (eg excluding hair). We conclude that information relating to the body categories sex and weight is found in both body and face responsive brain regions, but that size-invariant information is mostly located in body responsive regions.",C Foster and M Zhao and J Romero and M Black and BJ Mohler and A Bartels and I Bülthoff,0,,,,241-241,,Decoding categories shared by the face and body,https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_2552035,,2017,,6NjbexEAAAAJ:F1-V36_CjEsC

1010355,"The previous body image literature has focused on how females perceive their body weight. We investigated potential gender differences in the use of visual cues (shape, texture) to estimate own body weight. A full-body scanner was used to capture each participant’s own body geometry and colour information and a set of nine personalized 3D virtual bodies (avatars) with realistic weight variations (0,±5%,±10%,±15%,±20% of actual weight) was created based on a statistical body model. Additionally, a second set of avatars was created for each participant with an average underlying body shape matched in height, weight, inseam, and arm length. In four sets of psychophysical experiments, the influence of visual cues on accuracy of body weight perception and sensitivity to weight changes was assessed by manipulating body shape (own, average) and texture (own, checkerboard). The avatars were presented on a large-screen display, and participants responded to whether the body corresponded to their own weight. Overall, we found no gender difference in the accuracy of body weight estimation. Men however visually perceived the avatars with underlying average shape as thinner as avatars with their own shape. Further, males were less sensitive to weight changes than females and accepted a larger weight range as corresponding to their weight. Females’ desired body weight was lower than their actual weight, while actual and desired body weight for males was identical, suggesting that the weight dimension might be more important to women than to men in terms of their ideal body.",A Thaler and Ivelina Piryankova and Michael N Geuss and Jeanine K Stefanucci and Stephan de la Rosa and S Streuber and J Romero and Michael J Black and Betty J Mohler,0,,,,103-103,,Gender differences in visual perception of own body weight,https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_2562313,,2017,,6NjbexEAAAAJ:KIMFRoSX18MC

1010356,"Aims: Body image disturbance is a core symptom of anorexia nervosa (AN), and it is often assessed using Figure Rating Scales (FRS). Typically, FRS consist of a series of body drawings, and participants are asked to pick the body that corresponds best to their current and their desired body. So far, hardly any FRS is based on biometric data. Here, we use two new biometric FRS to investigate whether the presented weight spectrum influences a) accuracy in identifying the current weight and b) the desired weight in women with AN and controls. Method: Based on a statistical body model of human body shape and pose (Anguelov et al., 2005) and body scans of 2094 women from the CAESAR data set (Robinette et al., 1999) we generated biometric average bodies of women with predefined Body Mass Index (kg/m2, BMI). For the FRS 14-32 we used nine bodies with a BMI of 13.8 to 32.3 and for the FRS 18-42 we used nine bodies with BMI of 18 to 42. We administered the scales along with questionnaires assessing height, weight, body dissatisfaction, habits of social comparison and eating disorder symptoms to n= 104 women from the normal population (BMI= 23.90, SD= 6.06) and n= 24 women with anorexia nervosa (BMI= 15.07, SD= 1.62). n= 61 women from the normal population and n= 18 women with AN completed both FRS. Results: In the FRS 18-42, both groups were accurate in picking the body that corresponded best to their current weight (average offset in weight steps: Controls M= 0.12, SD= 1.05; AN M= 0.33, SD= 0.97; F (1,120)= 0.67, ns). In the FRS 14-32, women with AN were still accurate while controls significantly …",S Mölbert and A Thaler and S Streuber and M Black and HO Karnath and S Zipfel and B Mohler and K Giel,0,,,,161-162,,Investigating body image disturbance in patients with anorexia nervosa using new biometric figure rating scales,https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_2552368,,2017,,6NjbexEAAAAJ:nFloTcPoiwMC

1010357,"Person Index Abreu, Ana Maria 96 Alibali, Martha W. 11, 131, 136 Alverson, Hoyt 55 
Anderson, John 49, 140 Arnheim, Rudolf 136 Ascoli, Giorgio A. 27–45 Attardo, Salvatore 
156, 184 Barcelona, Antonio 9, 128, 136 Bargh, John A. 64, 105, 164 Barsalou, Lawrence 
W. 5, 125–126, 128, 223–224 Barton, David 186 Bergen, Benjamin K. 5, 21, 141, 224 
Bierwiaczonek, Boguslaw 163 Bishop, Bill 104, 107 Black, Max 20, 242, 298 Boers, Frank 6, 
293 Bordwell, David 254 Boroditsky, Lera 5, 48, 55, 63, 294 Bottini, Roberto 46–48, 56–57, 60 
Bowdle, Brian F. 19, 280, 285, 291 Calbris, Geneviève 121, 124 Cameron, Lynne 4, 6, 11, 
13, 16, 18, 174, 181–186, 200–201, 209, 214, 216, 218, 237 … Person Index 367 
Gibson, James J. 163, 257, 260, 269 Giora, Rachel 136, 164, 280, 285, 298 Glenberg, Arthur 
M. 12, 162 Glucksberg, Sam 19, 71, 127, 134, 220, 280, 288–289 Goatly, Andrew 10, 19 … ",Ana Maria Abreu and Martha W Alibali and Hoyt Alverson and John Anderson and Rudolf Arnheim and Giorgio A Ascoli and Salvatore Attardo and Antonio Barcelona and John A Bargh and Lawrence W Barsalou and David Barton and Benjamin K Bergen and Boguslaw Bierwiaczonek and Bill Bishop and Max Black and Frank Boers and David Bordwell and Brian F Bowdle and Geneviève Calbris,0,,Metaphor: Embodied Cognition and Discourse,,366,Cambridge University Press,Person Index,http://books.google.com/books?hl=en&lr=&id=idAoDwAAQBAJ&oi=fnd&pg=PA366&dq=info:Ftg88dIoDjYJ:scholar.google.com&ots=i_Hkdsq-dx&sig=dvz_VrVri_MCRGwSiUnl8YcWJvk,,2017,,6NjbexEAAAAJ:CgSwehex2-EC

1010358,"Previous research has suggested that size estimates of bodies (own and others') are biased towards an average reference body (Cornelissen et al., 2015; Cornelissen et al., 2016). The role of personal body size in body size perception of others is still unclear. In this study, we tested healthy females varying in body mass index (BMI) to investigate whether personal body size influenced accuracy of body size estimation and sensitivity to weight changes of others. We generated four biometric female avatars with BMIs of 15, 25, 35, and 45 and altered the weight of the avatars (5, 10, 15, and 20).",A Thaler and MN Geuss and SC Mölbert and KE Giel and MJ Black and BJ Mohler,0,,,,28-28,,Does Sensitivity to Weight Changes of Others Depend on Personal Body Size?,https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_2547187,,2016,,6NjbexEAAAAJ:_Ycx_gLZKoMC

1010359,"While there exists plenty of work on facial attractiveness only little is known about how the rest of the body determines the perception of another person. We were particularly interested in how the shape of the body and the way it moves contributes to attractiveness. Observers (20 male and 20 female) rated the attractiveness of 50 men and 50 women from the BML database each displayed in either of three ways in a 3D immersive virtual reality:(a) static bodies reconstructed from the motion capture data by means of MoSh (Loper et al. 2014, SIGGRAPH Asia) displayed as detailed 3D shapes;(b) walking stick-figures (Troje 2002, JOV);(c) same bodies as above, but animated with the corresponding walking movements. Correlations between all 12 sets of ratings (2 participant sex x 2 walker sex x 3 display types) reveal three different factors that contribute to the perception of attractiveness. The first factor is sexual …",Nikolaus Troje and Andreas Bieg and Naureen Mahmood and Betty Mohler and Michael Black,0,,Journal of Vision,12,393-393,The Association for Research in Vision and Ophthalmology,People perception: Attractiveness from shape and motion,https://jov.arvojournals.org/article.aspx?articleid=2550373,16,2016,,6NjbexEAAAAJ:h4edN3iSU_gC

1010360,"norexia nervosa (AN) is a serious eating disorder that goes along with underweight and high rates of psychological and physical comorbidity. Body image disturbance is a core symptom of AN, but as yet distinctive features of this disturbance unknown. This study uses individual 3D-avatars in virtual reality to investigate the following questions:(1) Do women with AN differ from controls in how accurately they perceive their body weight?(2) Do women with AN generally perceive bodies of their own shape differently than controls or only when viewing their own body? We investigate 25 women with AN and 25 healthy controls. Based on a 3D body scan, we create individual avatars for each participant. The avatar is manipulated to represent+/-5, 10, 15 and 20 of the participant’s weight. Additionally, for the control task, we manipulate identity of the avatar using a standard texture. Avatars were presented on a stereoscopic life-size screen. In the two-alternative forced choice (2AFC) task, participants see each avatar 20 times for two seconds. After each presentation, they have to decide whether that was the correct or a manipulated avatar. In the Method of Adjustment (MoA) task, participants are asked to adjust each avatar to match both, the correct size and their ideal size. In the control task, participants memorize the body with standard texture and afterwards perform the same 2AFC and MoA tasks with respect to the memorized body. Additionally, eating pathology, body dissatisfaction and self-esteem are assessed. First results from 19 women with AN and 16 controls show a tendency of patients to be accurate or to underestimate their current body size …",S Mölbert and A Thaler and B Mohler and S Streuber and MJ Black and HO Karnath and S Zipfel and KE Giel,0,,,,,,Investigating Body Image Disturbance in Anorexia Nervosa Using Biometric Self-Avatars in Virtual Reality,https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_2547222,,2016,,6NjbexEAAAAJ:mSXQG6lSlFkC

1010361,"We describe the first method to automatically estimate the3D pose of the human body as well as its 3D shape from a single un-constrained image. We estimate a full 3D mesh and show that 2D jointsalone carry a surprising amount of information about body shape. Theproblem is challenging because of the complexity of the human body, articulation, occlusion, clothing, lighting, and the inherent ambiguityin inferring 3D from 2D. To solve this, we first use a recently publishedCNN-based method, DeepCut, to predict (bottom-up) the 2D body jointlocations. We then fit (top-down) a recently published statistical bodyshape model, called SMPL, to the 2D joints. We do so by minimizingan objective function that penalizes the error between the projected 3Dmodel joints and detected 2D joints. Because SMPL captures correla-tions in human shape across the population, we are able to robustly fit itto very little data. We further …",Federica Bogo and Angjoo Kanazawa and Christoph Lassner and Peter V Gehler and Javier Romero and Michael J Black,0,,arXiv preprint arXiv:1607.08128,,,,Keep it {SMPL:} Automatic Estimation of 3D Human Pose and Shape from a Single Image. CoRR abs/1607.08128 (2016),http://scholar.google.com/scholar?cluster=9458152598199085047&hl=en&oi=scholarr,,2016,,6NjbexEAAAAJ:3DN2I6VP0lQC

1010362,"Humans are social beings and they often act jointly together with other humans (joint actions) rather than alone. Successful joint action requires the understanding and the coordination of ones own actions with another persons actions. The research attempts to advance our knowledge about joint action coordination by extending existing research in two novel and important ways. First, prominent theories of joint action agree on visual information being critical for successful joint action coordination but are vague about the exact source of visual information being used during a joint action. However, in a real life interaction several sources of visual information exist which inform an interaction partner about the ongoing course of the interaction (eg visual information about objects, tools, other persons). Knowing which sources of visual information are used, however, is important for a more detailed characterization of the functioning of action coordination in joint actions. Second, previous studies investigating the role of visual information in social settings often constrain the experimental tasks to artificial laboratory settings. To examine joint action mechanisms under realistic conditions I devised experimental tasks that allowed a close-to-natural joint action. As a result the perceptual and motor components of the experimental tasks were less constrained allowing for a more natural interaction compared to previous studies. The current research examines the importance of different sources of visual information on joint action coordination under realistic settings. In three studies I examined the influence of different sources of visual information (Study 1), the …",Stephan Streuber,0,,,,21,,The influence of different sources of visual information on joint action performance,https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_1787416,,2012,,6NjbexEAAAAJ:0xcHesCNKywC

1010363,"This technical report is complementary to [1] and contains proofs, formulas and additional plots. It is identical to the supplemental material submitted to European Conference on Computer Vision (ECCV 2012) on March 2012.",Oren Freifeld and Michael J Black,0,,,,,MPI f. Intelligente Systeme,LIE BODIES: A MANIFOLD REPRESENTATION OF 3D HUMAN SHAPE SUPPLEMENTAL MATERIAL,http://files.is.tue.mpg.de/black/papers/mpi-is-tr-005.pdf,,2012,,6NjbexEAAAAJ:1fM7sLBYaPUC

1010364,"Die Erzeugung realistischer 3D-Computeranimationen von Gesichtern ist auf Grund der hohen Bedeutung des menschlichen Gesichts für eine Vielzahl von Anwendungsbereichen von Interesse. Neben virtuellen Schauspielern in der Film-und Computerspiele-Industrie oder Online-Avataren verlangt auch die experimentelle Untersuchung der menschlichen Wahrnehmung von Gesichtern nach effizienten Lösungen zur Erstellung von Gesichtsanimationen. Insbesondere die experimentelle Verwendung motiviert den in dieser Arbeit vertretenen datenbasierten Ansatz, der möglichst ohne die in der Industrie übliche kreativ-handwerkliche Gestaltung der Gesichtsdaten auskommen will. Die Arbeit beschreibt, wie Messdaten realer Gesichter in Form von Motion Capture sowie 3D-bzw. 4D-Scans für diese Aufgabe eingesetzt werden können. Ausgehend von der Grundannahme der Darstellbarkeit eines Gesichts und dessen Bewegungen als Linearkombination werden Möglichkeiten der Gewinnung und Nutzung solcher Daten aufgezeigt: Der erste Teil kombiniert statische Oberflächenmessungen des Gesichts in Form von räumlich hoch aufgelösten 3D-Scans mit den zeitlich hoch aufgelösten, markerbasierten Bewegungsdaten eines Motion-Capture-Systems. Hierzu werden die gemessenen Bewegungen durch eine semantische Parametrisierung auf Basis des Facial Action Coding Systems (FACS) dargestellt. Dies erlaubt nicht nur die identitätsunabhängige Übertragung der Bewegung auf ein beliebiges Gesicht, sondern auch eine kompakte und gleichzeitig interpretierbare Beschreibung der Bewegung. Die zweite Hälfte der Arbeit baut auf neuen …",Martin Breidt,0,,,,,Logos Verlag,Datenbasierte Gesichtsanimation,https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_1787709,,2012,,6NjbexEAAAAJ:yhXl426oeGMC

1010365,"Background: Faces are important stimuli in social interactions, but the perception of bodies may also play an important role in person identification and inference of emotional state. Adaptation has proven a useful means of exploring face representations in the visual system, and can inform us of the nature of body representations. Body aftereffects may be particularly useful for studying invariance in object representations, as they can be subjected to more drastic manipulations of pose. Objective: Our goals were to determine if body aftereffects could be obtained, and if so, to what degree these show viewpoint and pose invariance. Methods: Headless body images were generated from a realistic 3-D mesh model of the human body created from laser range scans of over 2000 people. Statistical machine learning methods were used to factor body shape variations due to identity from those due to pose. By varying the …",Alla Sekunova and Michael Black and Laura Parkinson and Jason Barton,0,,Journal of Vision,11,585-585,The Association for Research in Vision and Ophthalmology,Adaptation for perception of the human body: investigations of transfer across viewpoint and pose,https://jov.arvojournals.org/article.aspx?articleid=2140112,11,2011,,6NjbexEAAAAJ:q3oQSFYPqjQC

1010366,"Autor: Roth, S. et al.; Genre: Buchkapitel; Im Druck veröffentlicht: 2011;
Keywords: MPI für Intelligente Systeme; Abt. Black; ; Titel: Steerable
random fields for image restoration and inpainting.
",S Roth and MJ Black,0,,,,377-387,MIT Press,Steerable random fields for image restoration and inpainting,https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_1577713,,2011,,6NjbexEAAAAJ:UwBXQvKX0hQC

1010367,"Document title: Benchmark datasets for pose estimation and tracking Authors: Andriluka, M.; Sigal,
L.; Black, MJ Document type: InBook Language: English Publisher: Springer Review Status: not
specified External Publication Status: published Audience: Experts Only Title of Book: Visual
Analysis of Humans: Looking at People Date of Publication (YYYY-MM-DD): 2011 Place of
Publication: London Full Name of Book-Editor(s): Moeslund, TB; Hilton, A.; Krüger, V.; Sigal, L.
Communicated by: Heide Klooz Affiliations: MPI für Intelligente Systeme/Abt. Black External
Affiliations: TU Darmstadt, Germany; Disney Research Pittsburg in conjunction with Carnegie
Mellon University; Identifiers: DOI:10.1007/978-0-85729-997-0_13
",Mykhaylo Andriluka and Leonid Sigal and Michael Black,0,,,,,Springer,of Book: Visual Analysis of Humans: Looking at People,http://www.edoc.mpg.de/573982,,2011,,6NjbexEAAAAJ:g3aElNc5_aQC

1010368,"Document title: Steerable random fields for image restoration and inpainting Authors: Roth, S.;
Black, MJ Document type: InBook Language: English Publisher: MIT Press Review Status: not
specified External Publication Status: published Audience: Experts Only Title of Book: Markov
Random Fields for Vision and Image Processing Date of Publication (YYYY-MM-DD): 2011 Place
of Publication: Cambridge, Mass. [et al.] Full Name of Book-Editor(s): Blake, A.; Kohli, P.; Rother,
C. Communicated by: Heide Klooz Affiliations: MPI für Intelligente Systeme/Abt. Black
",S Roth and MJ Black,0,,,,,MIT Press,of Book: Markov Random Fields for Vision and Image Processing,http://www.edoc.mpg.de/574064,,2011,,6NjbexEAAAAJ:NJ774b8OgUMC

1010369,"Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut être utilisé dans le cadre d’une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya señalado antes, el contenido de este registro bibliográfico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS",Leonid SIGAL and Michael J BLACK,0,,International journal of computer vision,1-2,,,Evaluation of Articulated Human Motion and Pose Estimation,https://pascal-francis.inist.fr/vibad/index.php?action=getRecordDetail&idt=22316737,87,2010,,6NjbexEAAAAJ:OvCsJ6o9tOQC

1010370,"Human visual scene understanding is remarkable: with only a brief glanceat an image, an abundance of information is available-spatialstructure, scene category and the identity of main objects in the scene. In traditional computer vision, scene and object recognition are twovisual tasks generally studied separately. However, it is unclearwhether it is possible to build robust systems for scene and objectrecognition, matching human performance, based only on localrepresentations. Another key component of machine vision algorithms isthe access to data that describe the content of images. As the fieldmoves into integrated systems that try to recognize many object classesand learn about contextual relationships between objects, the lack oflarge annotated datasets hinders the fast development of robustsolutions. In the early days, the first challenge a computer visionresearcher would encounter would be the difficult task of digitizing aphotograph. Even once a picture was in digital form, storing a largenumber of pictures (say six) consumed most of the availablecomputational resources. In addition to the algorithmic advancesrequired to solve object recognition, a key component to progress isaccess to data in order to train computational models for the differentobject classes. This situation has dramatically changed in the lastdecade, especially via the internet, which has given computer visionresearchers access to billions of images and videos. In this talk I willdescribe recent work on visual scene understanding that try to buildintegrated models for scene and object recognition, emphasizing thepower of large database of annotated images in computer …",Michael J Black,0,,,,,,Introduction to Computer Vision,https://cs.brown.edu/courses/csci1430/2009/lecture22.pdf,,2009,,6NjbexEAAAAJ:5XSfyxoPzb8C

1010371,,Richard Blomquist and Min Kyung Lee and Maxim Makatchev and G Ayorkor Korsah and Jack Mostow and M Bernardine Dias and Tracy Morrison Sweet and Sarah M Belousov and Malcolm Frederick Dias and Haijun Gong and Kian Hsiang Low and John M Dolan and Pradeep Khosla and Mark B Mosely and Benjamin P Grocholsky and Carol Cheung and Sanjiv Singh and Nathan Ratliff and Brian D Ziebart and Kevin Peterson and J Andrew Drew Bagnell and Martial Hebert and Anind Dey and Siddhartha Srinivasa and Learning Thin Junction Trees via Graph and Cuts Dafna Shahaf and Anton Chechetka and Carlos Ernesto Guestrin and Occlusion Boundaries from Motion and Andrew Stein and Gregg Podnar and Stephen B Stancliff and Alberto Elfes and Tom Lauwers and Illah Nourbakhsh and Emily Hamner and J Melenchon and F De la Torre and E Martinez and JA Montero and Hanns Tappeiner and Roberta L Klatzky and Bertram Unger and Ralph Hollis and Rebecca C Thurston and Karen A Matthews and Javier Hernandez and Fernando De la Torre and Y Tian and M Gupta and SG Narasimhan and L Zhang and Illah R Nourbakhsh and G Barlow and SF Smith and Mikhail Pivtoraiko and Alonzo Kelly and Issa Nesnas and Gita Sukthankar and Katia Sycara and Joseph Andrew Giampapa and Christopher Burnett and Seungkyu Lee and Yanxi Liu and Ross Alan Knepper and Ethan Tira-Thompson and David Lawrence and Richard Elphic and Jonathan Weinberg and Gregory Delory and Richard Dissly and Jonathan Evanyo and Dana Crider and Paul Lucey and Terrence W Fong and Richard Vondrak and Kris Zacny and Irene Yachbes and Brenna Argall and Nicholas Melchior and Reid Simmons,0,,Journal Article,3,459-468,,Home/Publications,https://www.ri.cmu.edu/pubs/page/82/?wpv_view_count=4514-TCPID4515&wpv_paged=48,17,2009,,6NjbexEAAAAJ:C7HQDqNFSbYC

1010372,"Given the primary mission of libraries, archives, and documentation centers in meeting the need of users for information, a number of novel models are currently considered for designing such centers, particularly web-based digital libraries.",Donald Bailey and Dana H Ballard and Shumeet Baluja and Andrea Baraldi and Matthew Beal and Peter N Belhumeur and Tim Bell and Marco Bertini and J Ross Beveridge and Michael J Black and Dan Blumberg and Dirk Borghys and Kim L Boyer and Michael Brill and Ing Hans Burkhardt and Michael C Burl and Peter Burt and Stefan Carlsson and Miguel Carreira-perpinan and Edward Chang and Jean Marc Chassery and Chanchal Chatterjee and Qian Chen and Zen Chen and Kong Man Cheung and Isaac Cohen and Laurent Cohen and Luis Alvarez and Francis Bach and Christophe Collet and David B Cooper and Timothy F Cootes and Marc Coram and James Coughlan and Ross Cutler and Anne Dougherty and Tom Drummond and Gregory Dudek and Pierre Dupont and Charles Dyer and David Eggert and Graham Finlayson and Randall Fish and Margaret Fleck and David Forsyth and Glenn Fung,0,,,,,,2004 Reviewers List,http://178.239.158.31/handle/Hannan/464864,,2008,,6NjbexEAAAAJ:AkQCnCHIR28C

1010373,"The purpose of this study was to determine the effects of supplementing cranberry seed oil to a population who had borderline high to high total blood cholesterol levels (>200 mg/dl). A total of 19 participants completed this research study. The experimental group consumed cranberry seed oil daily for eight weeks. The control group consumed canola oil daily for eight weeks. At weeks one, four, and eight a lipid profile test was conducted on each subject. A decrease of 5.7 mg/dl in total cholesterol occurred in the experimental group after just four weeks, with an increase of 4 mg/dl in HDL. These results warrant further research into the in vivo effects of cranberry seed oil supplementation.",Megan Eno,0,,,,,,The effect on lipid profiles after supplementation of cranberry seed oil,https://minds.wisconsin.edu/handle/1793/52973,,2008,,6NjbexEAAAAJ:Ecsxi449JjsC

1010374,"Journal of Neuroscience Methods 173 (2008) 318–319 Contents lists available at ScienceDirect Journal of Neuroscience Methods journal homepage: www. elsevier. com/locate/jneumeth Issue 1 15 August 2008 Basic Neuroscience A nonparametric Bayesian alternative to spike sorting F. Wood and MJ Black (UK, USA) 1 Attribution and Social Cognitive Neuroscience: A new approach for the “online-assessment” of causality ascriptions and their emotional consequences S. Terbeck, P. Chesterman, F. Ph. S. Fischmeister, U. Leodolter and H. Bauer (Austria, UK) 13 Single-synapse ablation and long-term imaging in live C. elegans PB Allen, AE Sgro, DL Chao, BE Doepker, JS Edgar, K. Shen and DT Chiu (USA) 20 Discrimination of cell types in mixed cortical culture using calcium imaging: A comparison to immunocytochemical labeling M. Pickering, BW Pickering, KJ Murphy and JJ O’Connor (Ireland) 27 Wavelet …",F Wood and MJ Black and S Terbeck and P Chesterman and F Ph S Fischmeister and U Leodolter and H Bauer and PB Allen and AE Sgro and DL Chao and BE Doepker and JS Edgar and K Shen and DT Chiu and M Pickering and BW Pickering and KJ Murphy and JJ O’Connor and AB Wiltschko and GJ Gage and JD Berke and S Carrubba and C Frilot and AL Chesson Jr and AA Marino and S Kaempf and P Walter and AK Salz and G Thumann and C Orizio and M Solomonow and B Diemont and M Gobbo and AM Seggio and KS Ellison and MR Hynd and W Shain and DM Thompson and A Hayar and C Gu and ED Al-Chaer and JRT van Weering and R Wijntjes and H de Wit and J Wortel and LN Cornelisse and WJH Veldkamp and M Verhage and M Negishi and M Abildgaard and I Laufer and T Nixon and RT Constable and C Weiss and JF Disterhoft and H Tamura and DC Ng and T Tokuda and H Naoki and T Nakagawa and T Mizuno and Y Hatanaka and Y Ishikawa and J Ohta and S Shiosaka and LA Damron and DJ Dearth and RL Hoffman and BC Clark and AD Dorval and SJ Gilson and AW Fitzgibbon,0,,Journal of Neuroscience Methods,,318-319,,Volume contents Volume 173 (2008),http://scholar.google.com/scholar?cluster=12341375770436398887&hl=en&oi=scholarr,173,2008,,6NjbexEAAAAJ:foquWX3nUaYC

1010375,,Jeff Schneider and David Apfelbaum and J Andrew Drew Bagnell and Reid Simmons and Fernando De la Torre Frade and Carlos Vallespi-Gonzalez and Paul Rybski and Manuela Veloso and Takeo Kanade and M Bernardine Dias and Robert Michael Zlot and Nidhi Kalra and Anthony Tony Stentz and Elie A Shammas and Karen Schmidt and Howie Choset and Nicolas Vandapel and James Kuffner and Omead Amidi and Jun Morimoto and Jun Nakanishi and Gen Endo and Gordon Cheng and Chris Atkeson and Garth Zeglin and G Ayorkor Korsah and Thrishantha Nanayakkara and Paul Scerri and Joseph Andrew Giampapa and Katia Sycara and David Ferguson and Illah Nourbakhsh and Emily Hamner and E Porter and Brian Dunlavey and Ellen M Ayoob and T Hsiu and M Lotter and S Shelly and Yanxi Liu and Yanghai Tsin and Wen-Chieh Lin and Alon Wolf and Aaron Christopher Morris and David Silver and Scott Thayer and J Oh and SF Smith and Massimo Paolucci and Julien Soudry and Naveen Srinivasan and Hulya Yalcin and Robert Collins and Michael Black and Martial Hebert and David R Thompson and Scott Niekum and Trey Smith and David Wettergreen and Stephen Smith and David W Hildum and David R Crimm and Shmuel Weinstein and David Pane and Lauren A Ernst and Edwin Minkley and Fred Lanni and Michael D Wagner and Stuart Heys and James Teza and Alan Waggoner and Terrence W Fong and Jean Hyaejin Oh and James M Dohm and Nathalie A Cabrol and Edmond A Grin and Jeffrey Moersch and Guillermo Chong Diaz and Charles Cockell and Peter Coppin and Gregory Fisher and Andrew N Hock and Lucia Marinangeli and GG Ori and Jennifer L Piatek and Kim Warren-Rhodes and Michael Wyatt and Kristen Stubbs and Geb Thomas and Justin Glasgow and L Pedersen and DE Smith and M Deans and R Sargent and C Kunz and D Lees and S Rajagopalan and Orientation Preserving Angular Swivel Joint,0,,Journal Article,2,145-159,,Home/Publications,https://www.ri.cmu.edu/pubs/page/99/?wpv_view_count=4514-TCPID4515&wpv_paged=25,62,2005,,6NjbexEAAAAJ:XzWLPxS1ir4C

1010376,"Author: Staples E, Journal: Perspectives (Gerontological Nursing Association (Canada))[2005].
",E Staples and M Black and M Turner,0,,Perspectives (Gerontological Nursing Association (Canada)),2,12-19,,Is there a need for the Geriatric Nurse Practitioner?,https://europepmc.org/article/med/16171299,29,2005,,6NjbexEAAAAJ:t1niNHmIXQYC

1010377,"A process of curing psychosis comprising the steps of having a therapist guide the patent through the steps of directing the patient to try to recall when the last time in their life they felt “happy” or felt “good” about “things in general”; directing the patient to try to remember anything that occurred that seemed “strange” or “odd” at the time; directing the patient to imagine what could have happened to someone else if they were in one of the above situations to insure the patient comes to the realization that he/she has had a traumatic experience; and, directing the patient to select a place of complete privacy to which he/she can go when feelings of sadness begin to be felt (either sad mood or specific sad event) to create in the patient the experience of re-integrative polarization convulsion.",,0,,,,,,Process for curing psychosis in humans,https://patents.google.com/patent/US20040191737A1/en,,2004,,6NjbexEAAAAJ:ILCMxgzxjrQC

1010378,"*.
",Huylia Yalcin and Ronan Fablet and Michael Black,0,,,,,,The dense estimation of motion and appearance,https://hal.archives-ouvertes.fr/hal-02341793/,,2004,,6NjbexEAAAAJ:U3HXUhiBGqIC

1010379,,J Ross Beveridge and Michael J Black and A Bubel and Rama Chellappa and Lawrence S Chen and Ira Cohen and Jeffrey F Cohn and Fernando De la Torre and Bruce A Draper and Ashutosh Garg and AZ Kouzani and M Kowalczyk and David J Kriegman and Volker Krueger and Yanxi Liu and Aleix M Martínez and Sinjini Mitra and WS Mokrzycki and Hiroshi Murase and Joshua D Neuheisel and Amit K Roy Chowdhury and Karen L Schmidt and Stan Sclaroff and Nicu Sebe and Andrea Selinger and Diego A Socolinsky and Jane Wu and Ming-Hsuan Yang and Shaohua Zhou,0,,Computer Vision and Image Understanding,,368,,"Baek, Kyungim, 115 Bartlett, Marian Stewart, 115 Bergevin, R., 302",http://scholar.google.com/scholar?cluster=9487926285014548868&hl=en&oi=scholarr,91,2003,,6NjbexEAAAAJ:PoWvk5oyLR8C

1010380,,F De la Torre and MJ Black,0,,Lecture Notes in Computer Science,,653-669,"Berlin: Springer-Verlag, 1973-",Calibration/Active and Real-Time and Robot Vision/Image and Video Indexing/Medical Image Understanding/Vision Systems/Engineering and Evaluations/Statistical Learning-Robust,http://scholar.google.com/scholar?cluster=4276058264687964377&hl=en&oi=scholarr,2353,2002,,6NjbexEAAAAJ:t6usbXjVLHcC

1010381,"This document examines the current state of image motion analysis and suggests possible directions for future research.Gibson pointed out that the changing pattern of brightness on the retina of a moving observer provides information about the environment including the subject’s motion with respect to surfaces in the world [16](Figure 1). The computation of this “optical flow” has been seen as providing metric information about the world including the ego-motion of the observer, the orientation and depth of surfaces in the scene, and the location of surface boundaries or discontinuities. Computational models of optical flow have focused on these metric properties and great progress has been made in the last fifteen years. Robust statistical techniques [5, 8, 2], parameterized models [3, 18, 5], and layered representations [9, 1, 20, 25, 26] have led to accurate algorithms for estimating optical flow in certain situations …",Michael J Black,0,,,,,,Smoke and Mirrors: The State of Image Motion Analysis and Directions for Further Research,http://scholar.google.com/scholar?cluster=8011604054213720401&hl=en&oi=scholarr,,2001,,6NjbexEAAAAJ:dTyEYWd-f8wC

1010382,,Remzo Dedic and M Hudjec and A Vucina and Bernard Mettler and MB Tischler and Takeo Kanade and Lee Hotraphinyo and Cameron Riviere and Vincent Cicirello and Stella Yu and TS Lee and Laura M Tomokiyo and Alex Waibel and Ashitey Trebi-Ollennu and John M Dolan and Pradeep Khosla and S Lucey and S Sridharan and V Chandran and Nicola Tomatis and Illah Nourbakhsh and Roland Siegwart and Bertram Unger and Alex Nicolaidis and Peter Berkelman and A Thompson and Roberta Klatzky and Ralph Hollis and Teruko Yata and Chuck Thorpe and T Schultz and Jianbo Shi and Terence Sim and Sundar Vedula and Karen Myers and Stephen Smith and David W Hildum and Peter Jarvis and R de Lacaze and Frank Dellaert and Terrence W Fong and S Grange and Charles Baur and Simon Baker and David R Crimm and M Bernardine Dias and Anthony Tony Stentz and A Safeguarded Teleoperation Controller and Stewart Moorehead and Richard Grace and Karen Schmidt and Jeffrey Cohn and Yanxi Liu and RL Weaver and N Serban and Manufacturing Vincent Cicirello and Matthew T Mason and Dinesh Pai and Kees van den Doel and Doug James and Jochen Lang and John E Lloyd and Joshua L Richmond and Som H Yau and Howie Choset and Ji Yeong Lee and J Andrew Drew Bagnell and Andrew Y Ng and Jeff Schneider and Young-Woo Seo and Byoung-Tak Zhang and F De la Torre and MJ Black and H Choset and E Acar and Y Zhang and M Schervish and Surya Singh and Scott Thayer and Chuck Rosenberg and Martial Hebert and Sebastian Thrun and Joseph Andrew Giampapa and Katia Sycara and Distributed Manipulation Using Discrete Actuator Arrays and Jon Luntz and William Messner and Liang Zhao and Kenichi Kanatani and Daniel D Morris and Mei Han and Perceiving Shapes through Region,0,,Journal Article,,,,Home/Publications,https://www.ri.cmu.edu/pubs/page/138/?wpv_view_count=4514-TCPID4515&wpv_paged=54,,2001,,6NjbexEAAAAJ:iKz1iSBcTNcC

1010383,,Manufacturing Vincent Cicirello and Stephen Smith and Matthew T Mason and Dinesh Pai and Kees van den Doel and Doug James and Jochen Lang and John E Lloyd and Joshua L Richmond and Som H Yau and Howie Choset and Ji Yeong Lee and J Andrew Drew Bagnell and Andrew Y Ng and Jeff Schneider and Y Nakauchi and R Simmons and Young-Woo Seo and Byoung-Tak Zhang and F De la Torre and MJ Black and H Choset and E Acar and Y Zhang and M Schervish and Simon Baker and Terence Sim and Takeo Kanade and Terrence W Fong and Chuck Thorpe and Charles Baur and Surya Singh and Scott Thayer and Chuck Rosenberg and Martial Hebert and Sebastian Thrun and Joseph Andrew Giampapa and Katia Sycara and Distributed Manipulation Using Discrete Actuator Arrays and Jon Luntz and William Messner and Liang Zhao and Kenichi Kanatani and Daniel D Morris and Stella Yu and Jianbo Shi and Karen Myers and David W Hildum and Peter Jarvis and R de Lacaze and Mei Han and Perceiving Shapes through Region and Matthew Deans and Daniel Huber and Bart Nabbe and Nicolas Vandapel and Uluc Saranli and Martin Buehler and DE Koditschek and Rahul Sukthankar and Tat-Jen Cham and Gita Sukthankar and Jim Rehg and J Hsu and T Leung and Yanghai Tsin and Visvanathan Ramesh and Naoya Takao and Iain Matthews and Towards Worldwide Literacy,0,,Journal Article,4,,,Home/Publications,https://www.ri.cmu.edu/pubs/page/132/?wpv_view_count=4514-TCPID4515&wpv_paged=75,17,2001,,6NjbexEAAAAJ:zVX0Cq83Iy8C

1010384,,A Safeguarded Teleoperation Controller and Terrence W Fong and Chuck Thorpe and Charles Baur and Stewart Moorehead and Richard Grace and Karen Schmidt and Jeffrey Cohn and Yanxi Liu and RL Weaver and N Serban and Vincent Cicirello and Stephen Smith and Manufacturing Vincent Cicirello and Matthew T Mason and Dinesh Pai and Kees van den Doel and Doug James and Jochen Lang and John E Lloyd and Joshua L Richmond and Som H Yau and Howie Choset and Ji Yeong Lee and J Andrew Drew Bagnell and Andrew Y Ng and Jeff Schneider and Y Nakauchi and R Simmons and Young-Woo Seo and Byoung-Tak Zhang and F De la Torre and MJ Black and H Choset and E Acar and Y Zhang and M Schervish and Simon Baker and Terence Sim and Takeo Kanade and Surya Singh and Scott Thayer and Chuck Rosenberg and Martial Hebert and Sebastian Thrun and Joseph Andrew Giampapa and Katia Sycara and Distributed Manipulation Using Discrete Actuator Arrays and Jon Luntz and William Messner and Liang Zhao and Kenichi Kanatani and Daniel D Morris and Stella Yu and Jianbo Shi and Karen Myers and David W Hildum and Peter Jarvis and R de Lacaze and Mei Han and Perceiving Shapes through Region and Matthew Deans and Daniel Huber and Bart Nabbe and Nicolas Vandapel and Uluc Saranli and Martin Buehler and DE Koditschek and Rahul Sukthankar and Tat-Jen Cham and Gita Sukthankar and Jim Rehg and J Hsu and T Leung and Yanghai Tsin and Visvanathan Ramesh and Naoya Takao and Iain Matthews and Towards Worldwide Literacy,0,,Journal Article,4,,,Home/Publications,https://www.ri.cmu.edu/pubs/page/132/?wpv_view_count=4514-TCPID4515&wpv_paged=28,17,2001,,6NjbexEAAAAJ:kRWl-cVF35UC

1010385,"Stinziano JR, Bui V, Crous K, Way DA.(In review) Estimates of light respiration using the photorespiratory CO 2 compensation point (G*) and a single AC i curve: the reduced Laisk method.",DA Way,0,,,,,,Home» Publications,https://daniellewayblog.wordpress.com/publications/,,2001,,6NjbexEAAAAJ:rn2Io16i3IwC

1010386,,Michael Bett and Ralph Gross and Hua Yu and Xiaojin Zhu and Yue Pan and Jie Yang and Alex Waibel and Wing-Choi Ma and Alfred Rizzi and Ralph Hollis and Sebastian Thrun and Andrew Moore and Jeff Schneider and Justin Boyan and MS Lee and Mahesh Saptharishi and Kiran Bhat and Chris Diehl and Spence Oliver and Marios Savvides and Alvaro Soto and John M Dolan and Pradeep Khosla and Sanjiv Singh and Reid Simmons and Trey Smith and Anthony Tony Stentz and Vandi Verma and Alex Yahja and Kurt Schwehr and Frank Broz and Jonathan Knight and Sam Listopad and Brian Magerko and Illah Nourbakhsh and M Asada and R D'Andrea and A Birk and H Kitano and Manuela Veloso and Arthur Quaid and Tucker Balch and M Hybinette and Devin Balkcom and Matthew T Mason and Mark Moll and Michael Erdmann and Michael Chen and Shinji Kume and H Sidenbladh and F De la Torre and MJ Black and Y Yacoob and L Davis and Takeo Kanade and Jeffrey Cohn and Ying-Li Tian and Farhana Kagalwala and F Lanni and Teruko Yata and Hallucinating Faces and Simon Baker and Geoffrey Gordon and Image-Based Multiresolution Modeling by Surface and Deformation Li Zhang and Terence Sim and Rahul Sukthankar and Matthew Mullin and Shumeet Baluja and Curt Bererton and Luis Ernesto Navarro-Serment and Robert Grabowski and Chris Paredis and Koichi Ogawara and Soshi Iba and Hiroshi Kimura and Katsushi Ikeuchi and Huikai Xie and Lars Erdmann and Qi Jing and Gary K Fedder and D Schulz and W Burgard and Dieter Fox and AB Creemers and A Cesta and A Oddi and Stephen Smith and Howard Wactlar and Alex Hauptmann and Michael Christel and Ricky Houghton and Andreas Olligschlaeger and DeWitt Talmadge Latimer and Howie Choset and Sean Walker and Kunnayut Eiamsa-Ard and Joel Burdick and Liam Pedersen and Dimi Apostolopoulos,0,,Workshop Paper,,,,Home/Publications,https://www.ri.cmu.edu/pubs/page/134/?wpv_view_count=4514-TCPID4515&wpv_paged=65,,2000,,6NjbexEAAAAJ:oufuJXaDW1QC

1010387,,Moshe Ben-Ezra and Horst Bischof and Michael J Black and Alfred M Bruckstein and Fei-Long Chen and James Coughlan and Yuntao Cui and David Demirdjian and Jan-Olof Eklundh and Camper English and David J Fleet and C Galambos and Eiichi Hosoya and Astrid ML Kappers and Nahum Kiryati and J Kittler and Jan J Koenderink and Shang-Hong Lai and Aleš Leonardis and Shiaur-Wehn Lin and Rong Lu and Atsuto Maki and J Matas and Peter Meer and Mahmoud Meribout and Mamoru Nakanishi and Peter Nordlund and Takeshi Ogura and Shmuel Peleg and Azriel Rosenfeld and Dan Snow and Charles V Stewart and PHS Torr and David E Tyler and Juyang Weng and Michael Werman and Yaser Yacoob and Alan Yuille and A Zisserman,0,,Computer Vision and Image Understanding,,374,,"Atsalakis, Antonios, 336",http://scholar.google.com/scholar?cluster=2823745332686699381&hl=en&oi=scholarr,78,2000,,6NjbexEAAAAJ:SpbeaW3--B0C

1010388,,N Armande and Michael J Black and Michael Boshra and Nozha Boujemaa and Horst Bunke and Terry Caelli and Q Cai and Francis HY Chan and Clifford ST Choy and Stéphane Christy and Roberto Cipolla and Klaus Donner and Iris Fermin and G Häusler and Henk JAM Heijmans and Radu Horaud and Shi-Jinn Horng and Atsushi Imiya and Xiaoyi Jiang and SH Joseph and Frederic Jurie and Sing Bing Kang and Sridhar R Kundur and Rolf Lakämper and FK Lam and Feiyu Liu and Stéphane Marchand-Maillet and Gérard Medioni and O Monga and P Montesinos and Hirobumi Nishida and Clark F Olson and Adrian R Pearce and Natan Peterfreund and Daniel Raviv and D Ritter and Paul L Rosin and Yazid M Sharaiha and WC Siu and Jean-Philippe Tarel and John K Tsotsos and Guy Vaysseix and Robert Wagner and Richard Weiss and Yaser Yacoob and Yiming Ye and Hong Zhang and Hui Zhu,0,,,,,,"Aggarwal, JK, 428",http://scholar.google.com/scholar?cluster=1594463956226240511&hl=en&oi=scholarr,,1999,,6NjbexEAAAAJ:xtoqd-5pKcoC

1010389,"Thispaperdescribesoureffortstodevelopa “DigitalOffice” in which we augment a physicaloffice setting with cameras andother electronic devices. Our goal is to bring the worlds of electronic and physical documentscloser together and to facilitate the interaction of humans with all kinds of documents. In the “Digital Office” we extend the traditional notionof “scanning” documentstoincludethecaptureofwhiteboards, books, desktops, andthehumanofficeworkersthemselves. In particular, we give an overview of three systems in which video cameras unobtrusively observe and capture whiteboardsandhumangestures, papersonthedesktop, and the motion of a user’s face which is used to control the displayofelectronicdocumentsinabrowser. Eachofthesesystemscombinesthe featuresandaffordancesof bothphysical andelectronicdocuments, andtogethertheybeginto illuminate the intelligent office environmentof the future.",Michael J Black and François Berard and Allan Jepson and William Newman,0,,,,,,"fblack, saund, socherg@ parc. xerox. com, fwnewman, mtaylorg@ xrce. xerox. com",http://scholar.google.com/scholar?cluster=7861808296583319266&hl=en&oi=scholarr,,1998,,6NjbexEAAAAJ:JoZmwDi-zQgC

1010390,,M BLACK and R ROSENHOLTZ,0,,,4,S477-S477,LIPPINCOTT-RAVEN PUBL,A COMPUTATIONAL MODEL FOR SHAPE FROM TEXTURE FOR MULTIPLE TEXTURES,http://scholar.google.com/scholar?cluster=1789778904321096184&hl=en&oi=scholarr,36,1995,,6NjbexEAAAAJ:e_rmSamDkqQC

1010391,"THESE THOUGHTS ARISE from the experience of writing explanatory notes for the new Penguin edition of The White Peacock, a text full of literary echoes. Accounting for the allusions in a necessarily brief note, or reading such notes and having the allusion'explained'causes one to think of the original references as themselves little pieces of information, or at most signals from author to reader of some kind of cultural solidarity ('yu recognise this, of course'). The form of the explanatory note, a dense packet of fact and reference, can mislead one into thinking of the allusions in this way. But they are, rather, a mental event much more like figures of speech, a kind of metaphor. They have two elements, a locus in the text and a parallel locus in another text. These two are for a moment bent towards each other or even bound together; certainly they modify each other. Like metaphor they establish something new, yet they …",Michael Black,0,,The Cambridge Quarterly,2,133-151,Oxford University Press,Visiting the bottom of the monstrous world: allusion as metaphor in Lawrence,https://www.jstor.org/stable/42967666,24,1995,,6NjbexEAAAAJ:27qsyVibG6YC

1010392,"The sample of 3,974 employees of Apple Computer were divided into male (n = 2,088) and female (n = 1,886) groups and then further categorized according to age and the degree of participation in the Apple Health and Fitness Program. Mean age for males was 34.5 years +/- 7.55, while the mean age for females was 34.7 years +/- 7.58. The mean  health care cost was $1,053.8 +/- 3,705 for males and $1,420.0 +/- 4,168.1 for females. Participation was measured over an 11 month testing period and divided into 4 subgroup headings: no use, low use, moderate use, and high use. Rather than use overall health care means, independent age group means were used to assign cost status. After skewness and kurtosis measurements determined that the sample was not normally distributed, chi-square tests were applied to locate statistical significance, In both males and females, chi-square tests examined differences in high and low cost status for the subjects within a particular age group. For both male and female subjects no significant differences were found within the age and participation subgroups (p > .05). The same subjects and age groups were then categorized into just 2 usage groups: user and nonuser. No significant difference was found among male users and the nonusers within the three age groups (p > .05). Meanwhile, a significant difference was found in females 31 to 40 years old and females 41 and older (p < .05). In females 31 to 40 the nonusers were found to have significantly lower medical costs while the opposite was true for females over 41 years of age.",Michael W Black,0,,,,,,Effects of a corporate sponsored fitness program on health care costs: a comparison of users and nonusers,https://minds.wisconsin.edu/handle/1793/48650,,1995,,6NjbexEAAAAJ:6KBr9xvF6m4C

1010393,"Recently, the assumed goal of computer vision, reconstructing a representation of the scene, has been critcized as unproductive and impractical. Critics have suggested that the reconstructive approach should be supplanted by a new purposive approach that emphasizes functionality and task driven perception at the cost of general vision. In response to these arguments, we claim that the recovery paradigm central to the reconstructive approach is viable, and, moreover, provides a promising framework for understanding and modeling general purpose vision in humans and machines. An examination of the goals of vision from an evolutionary perspec-tive and a case study involving the recovery of optic ﬂow support this hypothesis. In particular, while we acknowledge that there are instances where the purposive approach may be appropriate, these are insufﬁcient for implementing the wide range of visual tasks …",MICHAEL J BLACK,0,,,,,,MICHAEL J. TARR,http://files.is.tue.mpg.de/black/papers/cviu.60.1.1994a.pdf,,1994,,6NjbexEAAAAJ:7T2F9Uy0os0C

1010394,"We greatly appreciate the time and thought the authors of the replies have put into their commentaries on our paper [l-9]. We are concerned, however, that there has been some misinterpretation of our goals. We emphasize that we are attempting to represent a conservative position on the study ofvision. It is not that we believe that current and past paradigms are ideal and should be maintained to the exclusion of all other approaches, but rather that we feel that the goal of reconstruction and scene recovery is viable and should not be completely abandoned. We claim this with full knowledge of the fact that these and related terms, most notably “general vision,” cannot be deﬁned precisely at present (despite the best efforts of [3, 9])—a fact that advocates of the purposive paradigm have used as a justification for a radical departure from the current paradigm. Perhaps our concern in this regard is unwarranted, thereby …",Michael J Tarr and Michael J Black,0,,,,,,RESPONSE TO REPLIES,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.19.4861&rep=rep1&type=pdf,,1994,,6NjbexEAAAAJ:9vf0nzSNQJEC

1010395,,SX Ju and MJ Black,0,,PROCEEDINGS-SPIE THE INTERNATIONAL SOCIETY FOR OPTICAL ENGINEERING,,26-26,SPIE INTERNATIONAL SOCIETY FOR OPTICAL,Time to contact from active tracking of motion boundaries [2354-05],http://scholar.google.com/scholar?cluster=4197301568732671522&hl=en&oi=scholarr,,1994,,6NjbexEAAAAJ:olpn-zPbct0C

1010396,"This paper presents a method for incrementally segmenting images over time using both intensity and motion information. This is done by formulating a simple model of surface patches using local constraints on intensity and motion and then finding the optimal segmentation over time using an incremental stochastic minimization technique. The result is a robust and dynamic segmentation of the scene over a sequence of images. The approach has a number of benefits. First, discontinuities are ertracted and tracked simultaneously. Second, a segmentation is always available and it improves over time. Finally, by combining motion and intensity, the structural properties of discontinuities can be recovered; that is, discontinuities can be classified as surface markings or actual surface boundaries.",Michael J Black,0,,,,,,Combining Intensity and Motion for Incremental Segmentation and Tracking Over Long Image,https://cpsc.yale.edu/sites/default/files/files/tr873.pdf,,1991,,6NjbexEAAAAJ:IA09g522ZoUC

1010397,"This paper presents a simple, robust, gradient-based, approach to computing optical flow in the presence of noise and motion discontinuities.‘We begin with the standard gradient-based method of Horn and Schunck which corresponds to a least-squares estimate of the opticalﬂow. Such estimates are susceptible to outliers which do not conform the statistical assumptions of the approach; for example, measurements at motion discontinuities. The result is that the least-squares solution has the undesirable property of smoothing the ﬂow ﬁeld across motion boundaries. Robust statistics can be used to address this problem. By reformulating the optical flow equation in terms of robust estimation, the problems of image noise and over-smoothing are reduced. The reformulation is straightforward, and results in a remarkable improvement in the estimated ﬂow, particularly at motion discontinuities. The flow ﬁeld is recovered …",Michael J Black,0,,,,,,Determining Optical Flow,http://cs-www.cs.yale.edu/publications/techreports/tr891.pdf,,1991,,6NjbexEAAAAJ:q3CdL3IzO_QC

1010398,This paper presents an approach for the incremental estimation of visual motion over time. The task of estimating visual motion involves specifying constraints which relate spatiotemporal intensity variations to image motion and express our assumptions about the spatiotemporal variation of the motion itself. We also require an effective procedure for computing the motion consistent with the assumptions.,Michael J Black P Anandan,0,,"Proceedings, CVPR'91: June 3-6, 1991, Lahaina, Maui, Hawaii",,296,IEEE Computer Society Press,Robust Dynamic Motion Estimation Over Time,http://scholar.google.com/scholar?cluster=2270969174493616745&hl=en&oi=scholarr,,1991,,6NjbexEAAAAJ:UuaQgmrAG1sC

1010399,"This is the final report for the Phase II SBIR contract, Spatial Data Structures for Robotic Vehicle Route Planning. The report describes the work completed during Phase II and discusses the directions for future research. The goal of the Phase II SBIR contract was to investigate techniques and tradeoffs for representing digital terrain information in a computer environment. The long-term goal of this research is to build a Spatial Data Structure Development System (SDSDS) to serve as the infrastructure base for terrain analysis applications. The Phase II contract addressed the following issues: 1) implementation of common terrain representations, 2) implementation of common spatial operations, 3) design of a methodology for evaluating the performance of spatial operations, 4) evaluation of the implemented representations and operations, and 5) initial design of testbed on which the SDSDS would be built.Descriptors:* TERRAIN INTELLIGENCE,* ROBOTICS,* ROUTING,* SURFACE NAVIGATION, COMPUTERS, GROUND VEHICLES, TRADE OFF ANALYSIS, TEST BEDS, SPATIAL DISTRIBUTION, DIGITAL SYSTEMS, DATA BASES, CONTRACTS",Michael J Black and David L Milgram and Sharon O Cioffi and Patrice Gelband,0,,,ADS-TR-3185-01,,ADVANCED DECISION SYSTEMS MOUNTAIN VIEW CA,Spatial Data Structures for Robotic Vehicle Route Planning,http://scholar.google.com/scholar?cluster=159045653458710364&hl=en&oi=scholarr,,1988,,6NjbexEAAAAJ:GL0K47J-u9kC

1010400,"This study was conducted to determine the effects of a circuit weight training program on cardiac patients. Certain variables, such as blood pressure measurements and strength increase, were chosen to be examined so that safe and effective guidelines for a circuit weight training program for cardiac patients could be established.",Karen J Toomey,0,,,,,,"The effects of a circuit weight training program on heart rate, blood pressure and electrocardiographic activity in cardiac patients",https://minds.wisconsin.edu/handle/1793/54459,,1985,,6NjbexEAAAAJ:sFUlmsclzkgC

1010401,"French, T., 114 Freud, A., 165, 336 Freud, S., 3-21, 65 n, 96, 97,101,104, 121 n, 129, 134,146 n, 160—161,164, 166-167, 168, 170, 171, 181-186, 188, 189, 190, 198, 206, 209, 237, 259-261, 307, 312-313, 319, 319 n-32O n, 328, 329, 331, 332, 335, 336, 337, 338, 341, 342, 347, 348, 349, 357-361, 362, 364, 373-374, 375, 377, 378 n, 380",JD Adamson and DR Aleksandrowicz and F Alexander and E Alfert and KZ Altshuler and P Amacher and C Amatruda and J Ambrose and L Andreas-Salomé and JS Antrobus and B Apfelbaum and R Arnheim and H Aronson and Newton Arvin and SE Asch and JW Atkinson and F Attneave and F Auld Jr and P Babkin and J Baines and MM Barr and S Barrera and Béla Bartok and G Bateson and N Bayley and MC Beardsley and A Beck and SS Becker and JG Beebe-Center and R Beer-Hofmann and Ludwig von Beethoven and V Bellugi and T Benedek and JD Benjamin and D Beres and Alban Berg and P Bergman and S Bernfeld and N Bernick and D Bickerton and R Binion and RS Blacher and M Black and RP Blackmur,0,,Psychoanalysis and Contemporary Science,,393,International Universities Press,"Bak, RC, 320 n Balderston, KC, 389",http://scholar.google.com/scholar?cluster=7711986420111757675&hl=en&oi=scholarr,,1972,,6NjbexEAAAAJ:HZAC7m4lW-wC

1010402,"1. Nurs Times. 1968 Aug 30;64(35):Suppl:133-4. Attachment of local health authority staff
to general practices. 2. Discussion: a study in three county boroughs with special reference
to health visiting. Ambler M, Anderson JA, Black M, Draper P, Lewis J, Moss W, Murrell TG.
PMID: 5672691 [Indexed for MEDLINE]. MeSH terms. Family Practice*; Home Care Services*;
Interprofessional Relations; State Medicine; United Kingdom.
",M Ambler and JA Anderson and M Black and P Draper and J Lewis and W Moss and TG Murrell,0,,Nursing times,35,Suppl: 133,,Attachment of local health authority staff to general practices. 2. Discussion: a study in three county boroughs with special reference to health visiting.,https://www.ncbi.nlm.nih.gov/pubmed/5672691,64,1968,,6NjbexEAAAAJ:J2VLEJC5QowC

1010403,"The independent and. localised nature of County Council administration is well illustrated by the practice of the three Smallholdings Authorities in Yoi'k. shire,. both at. the time of purchase and sub-division of estates and in the current policy of estate management and selection of tenants.The various Smallholdings Acts placed a statutory duty upon County Councils to provide sufficient holdings. to meet the demand for: them. It is interesting to see how the, number, prbvided comp'ares with the number of farm workers in each Riding. The total of agricultural workers in Yorkshire has declined considerably since 1921, but at different rates in the three Ridings.. The Vest Riding lost almost one-third of Its adult male regular workers in the forty years between 1921 and 1961, so. that the difference in numbers between the Ridings has been considerably reduced..",Michael Black,0,,,2120-2018-4715,,,County Council Smallholdings in Yorkshire: A Social and Economic Assessment,https://ageconsearch.umn.edu/record/275308/files/LEEDS-067.pdf,,1965,,6NjbexEAAAAJ:viTTOddtVMkC

1010404,"The University takes the opportunity to thank all those who have helped in the preparation of this report, including the officers of FMC (Meat) Ltd., Northern Region, the secretaries of the Calf Groups in the area and, above all, the co-operating farmers whose interest has made the investigation possible. Part of the field work for the survey was carried out by Messrs. LW Bolton, EG Dawson and IG Simpson.",JB Butler and M Black and JK Hardie,0,,,2120-2018-4712,,,Economic Aspects of Cattle Feeding: A Study of Production Systems in Yorkshire and Supply Trends in the United Kingdom,https://ageconsearch.umn.edu/record/275305/files/LEEDS-064.pdf,,1964,,6NjbexEAAAAJ:wy5MF_2MSNEC

1010405,"Rex K. John is Principal of Lincoln High School, Manitowoc, Wisconsin. r II HE student exchange idea is not new. For several years a few high schools in the eastern part of the United States have carried on student exchanges with high schools in nearby states. Such exchanges have enabled groups of students from one community to become acquainted with groups of students from other communities, to discover fof themselves ways in which they are similar or un-like, and to see at first hand conditions under which young people like themselves live. Undoubtedly one basic belief underlying the whole student exchange idea is the firm conviction that national unity can best be promoted through a better common understanding of the beliefs and customs of widely separated regions and that there is no satisfactory substitute for individual and group contacts.",Rex K John and MM Black and Willard H Van Dyke,0,,The bulletin of the National Association of Secondary School Principals,194,247-252,Sage Publications,What Are Promising Administrative Practices in the Senior High School?,https://journals.sagepub.com/doi/pdf/10.1177/019263655303719449,37,1953,,6NjbexEAAAAJ:MWSB05WFU5AC

1010406,"As we move through our visual environment, the spatial and temporal pattern of light that enters our eyes is strongly influenced by the properties of objects within the environment, their motion relative to each other, and our own motion relative to the external world. Quantifying the distributed neural representation of luminance and motion in the early visual pathway is a critical step in understanding how scene information is extracted and prepared for processing in higher visual centers. We argue that it is important to model neural population responses to visual scenes with the rich complexity of the natural visual world. Current natural scene movies provide complex scene statistics but the uncontrolled nature of these stimuli limits their usefulness for understanding the visual code. Consequently, we have developed new image sequences of naturalistic scenes using computer graphics methods in which we know …",Garrett Stanley and Michael Black and JP Lewis and Gaelle Desbordes and Jianzhong Jin and Jose-Manuel Alonso,0,,Frontiers in Neuroscience,,52,,Population coding of ground truth motion in natural scenes in the early visual system,http://scribblethink.org/Work/Pdfs/cosyne09.pdf,2,1910,,6NjbexEAAAAJ:UmJFWc0aipQC

1010407,"This index covers all technical items—papers, correspondence, reviews, etc.—that appeared 
in this periodical during 2020, and items from previous years that were commented upon or corrected 
in 2020. Departments and other items may also be covered if they have been judged to have 
archival value. The Author Index contains the primary entry for each item, listed under the first 
author's name. The primary entry includes the coauthors' names, the title of the paper or other 
item, and its location, specified by the publication abbrevia- tion, year, month, and inclusive 
pagination. The Subject Index contains entries describing the item under all appropriate subject 
headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive 
pages. Note that the item title is found only under the primary entry in the Author Index … 
Aberdam, A., see Sulam, J., TPAMI Aug. 2020 1968-1980 Achterhold, J., see … ",A Aberdam and J Achterhold and JK Adams and E Adeli and S Agaian and K Aizawa and E Akagunduz and N Akhtar and T Akilan and X Alameda-Pineda and S Albanie and C Albl and M Almatrafi and S Alpert and JM Alvarez and JC Alvarez-Paiva and RA Amjad and BB Amor and A Andonian and B Andres and GR Arce and M Arens and A Arnab and H Ashtiani and MS Asif and A Auvolat and H Averbuch-Elor and S Avidan and S Ayache and RV Babu and S Bai and X Bai and R Baldwin and DR Balfour and V Balntas and S Baluja and N Bar and SA Bargal and X Baro and A Bartoli and R Basri and M Batz and J Bazin and A Beck and M Belkin and R Benenson and M Bennamoun and D Berman and F Bernard and S Berretti and A Bhandari and S Bianco and T Birdal and H Bischof and B Bischoff and MJ Black and V Blanz and MB Blaschko and V Boominathan and G Borghi and A Borji and AG Bors and A Bousseau and P Bouthemy and R Bowden and A Brandt and AM Bronstein and MM Bronstein and L Brown and MS Brown and T Brox and A Bulat and B Busam,0,,,,,,2020 Index IEEE Transactions on Pattern Analysis and Machine Intelligence Vol. 42,https://ieeexplore.ieee.org/abstract/document/9280440/,,,,6NjbexEAAAAJ:viPVbuMW504C

1010408,"Humans move their hands and bodies together to communicate and solve tasks. Capturing and replicating such coordinated activity is critical for virtual characters that behave realistically. Surprisingly, most methods treat the 3D modeling and tracking of bodies and hands separately. Here we formulate a model of hands and bodies interacting together and fit it to full-body 4D sequences. When scanning or capturing the full body in 3D, hands are small and often partially occluded, making their shape and pose hard to recover. To cope with low-resolution, occlusion, and noise, we develop a new model called MANO (hand Model with Articulated and Non-rigid defOrmations). MANO is learned from around 1000 high-resolution 3D scans of hands of 31 subjects in a wide variety of hand poses. The model is realistic, low-dimensional, captures non-rigid shape changes with pose, is compatible with standard graphics …",Javier Romero and Dimitrios Tzionas and Michael J Black,0,,,,,,Embodied Hands: Modeling and Capturing Hands and Bodies Together Download PDF Open Website,http://scholar.google.com/scholar?cluster=3982418065896062965&hl=en&oi=scholarr,,,,6NjbexEAAAAJ:kiFE3DPpsncC

1010409,"We describe the first method to automatically estimate the3D pose of the human body as well as its 3D shape from a single un-constrained image. We estimate a full 3D mesh and show that 2D jointsalone carry a surprising amount of information about body shape. Theproblem is challenging because of the complexity of the human body, articulation, occlusion, clothing, lighting, and the inherent ambiguityin inferring 3D from 2D. To solve this, we first use a recently publishedCNN-based method, DeepCut, to predict (bottom-up) the 2D body jointlocations. We then fit (top-down) a recently published statistical bodyshape model, called SMPL, to the 2D joints. We do so by minimizingan objective function that penalizes the error between the projected 3Dmodel joints and detected 2D joints. Because SMPL captures correla-tions in human shape across the population, we are able to robustly fit itto very little data. We further …",Federica Bogo and Javier Romero and Matthew Loper and Michael J Black,0,,,,,,FAUST: Dataset and evaluation for 3D mesh registration Download PDF,http://scholar.google.com/scholar?cluster=7977446483798486776&hl=en&oi=scholarr,,,,6NjbexEAAAAJ:p6f6DfXMsGMC

1010410,"We present a learned model of human body shape and pose-dependent shape variation that is more accurate than previousmodels and is compatible with existing graphics pipelines. OurSkinned Multi-Person Linear model (SMPL) is a skinned vertex-based model that accurately represents a wide variety of bodyshapes in natural human poses. The parameters of the model arelearned from data including the rest pose template, blend weights, pose-dependent blend shapes, identity-dependent blend shapes, anda regressor from vertices to joint locations. Unlike previous mod-els, the pose-dependent blend shapes are a linear function of theelements of the pose rotation matrices. This simple formulation en-ables training the entire model from a relatively large number ofaligned 3D meshes of different people in different poses. We quan-titatively evaluate variants of SMPL using linear or dual-quaternionblend …",Matthew Loper and Naureen Mahmood and Javier Romero and Gerard Pons-Moll and Michael J Black,0,,,,,,SMPL: A Skinned Multi-Person Linear Model Download PDF,http://scholar.google.com/scholar?cluster=6564038123209219050&hl=en&oi=scholarr,,,,6NjbexEAAAAJ:KIG7iI7jH74C

1010411,"To understand and analyze human behavior, we need to capture humans moving in, and interacting with, the world. Most existing methods perform 3D human pose estimation without explicitly considering the scene. We observe however that the world constrains the body and vice-versa. To motivate this, we show that current 3D human pose estimation methods produce results that are not consistent with the 3D scene. Our key contribution is to exploit static 3D scene structure to better estimate human pose from monocular images. The method enforces Proximal Relationships with Object eXclusion and is called PROX. To test this, we collect a new dataset composed of 12 different 3D scenes and RGB sequences of 20 subjects moving in and interacting with the scenes. We represent human pose using the 3D human body model SMPL-X and extend SMPLify-X to estimate body pose using scene constraints. We …",Mohamed Hassan and Vasileios Choutas and Dimitrios Tzionas and Michael J Black,0,,,,,,Resolving 3D Human Pose Ambiguities with 3D Scene Constraints Download PDF Open Website,http://scholar.google.com/scholar?cluster=15130799031944065855&hl=en&oi=scholarr,,,,6NjbexEAAAAJ:c5LcigzBm8MC

1010412,"Estimating human pose, shape, and motion from images and video are fundamental challenges with many applications. Recent advances in 2D human pose estimation use large amounts of manually-labeled training data for learning convolutional neural networks (CNNs). Such data is time consuming to acquire and difficult to extend. Moreover, manual labeling of 3D pose, depth and motion is impractical. In this work we present SURREAL: a new large-scale dataset with synthetically-generated but realistic images of people rendered from 3D sequences of human motion capture data. We generate more than 6 million frames together with ground truth pose, depth maps, and segmentation masks. We show that CNNs trained on our synthetic dataset allow for accurate human depth estimation and human part segmentation in real RGB images. Our results and the new datast open up new possibilities for advancing …",Gul Varol and Javier Romero and Xavier Martin and Naureen Mahmood and Michael J Black and Ivan Laptev and Cordelia Schmid,0,,,,,,Learning from Synthetic Humans Download PDF,http://scholar.google.com/scholar?cluster=9481068744586824501&hl=en&oi=scholarr,,,,6NjbexEAAAAJ:INESB4G31EoC

1010413,"We propose a novel end-to-end trainable framework for the graph decomposition problem. The minimum cost multicut problem is first converted to an unconstrained binary cubic formulation where cycle consistency constraints are incorporated into the objective function. The new optimization problem can be viewed as a Conditional Random Field (CRF) in which the random variables are associated with the binary edge labels of the initial graph and the hard constraints are introduced in the CRF as high-order potentials. The parameters of a standard Neural Network and the fully differentiable CRF are optimized in an end-to-end manner. Furthermore, our method utilizes the cycle constraints as meta-supervisory signals during the learning of the deep feature representations by taking the dependencies between the output random variables into account. We present analyses of the end-to-end learned representations …",Jie Song and Bjoern Andres and Michael Black and Otmar Hilliges and Siyu Tang,0,,,,,,End-to-end Learning for Graph Decomposition Download PDF,http://scholar.google.com/scholar?cluster=1940447949937992547&hl=en&oi=scholarr,,,,6NjbexEAAAAJ:-jjRUaukNG4C

1010414,"–Our modified version of the object meshes of [2].–Our marker locations on each object mesh.–Body shape templates for our subjects.–Pose parameters for our subjects and objects.–Code to reproduce the interacting meshes, as seen in our video.–Per-vertex contact annotations on meshes (body and object) for each frame.–Vicon MoCap files (labeled marker positions, incl. on the floor and table).",Omid Taheri and Nima Ghorbani and Michael J Black and Dimitrios Tzionas,0,,,,,,GRAB: A Dataset of Whole-Body Human Grasping of Objects* Supplemental Material,http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123490562-supp.pdf,,,,6NjbexEAAAAJ:5buzqZzMjwkC

1010415,"Pose Generator. architecture is depicted in Figure 1. After feature extraction using ResNet50, we use 2 layer GRU network followed by a linear projection layer. The pose and shape parameters are then estimated by a SMPL parameter regressor. We employ a residual connection to assist network during training. The SMPL parameter regressor is initialized with the pretrained weights from HMR [5, 7]. We decrease the learning rate if the reconstruction does not improve for more than 5 epochs.Motion Discriminator. We employ 2 GRU layers with a hidden size of 1024. For self-attention mechanism, in the case of SOTA results, we use 2 MLP layers with 1024 neurons and a dropout rate of 0.1 to estimate attention weights. For the ablation experiments we keep the same parameters changing the number of neurons and number of MLP layers only. During training, we use label smoothing for adversarial training by a random number∈[0, 0.1][10].",Muhammed Kocabas and Nikos Athanasiou and Michael J Black,0,,,,,,Supplementary Material for VIBE: Video Inference for Human Body Pose and Shape Estimation,https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Kocabas_VIBE_Video_Inference_CVPR_2020_supplemental.pdf,,,,6NjbexEAAAAJ:pIp0rujYkN4C

1010416,"Condition module: for pose θ, we remove the parameters that are not related to clothing, eg head, hands, fingers, feet and toes, resulting in 14 valid joints from the body. The pose parameters from each joint are represented by the flattened rotational matrix (see Sec. 4.1,“Conditional model”). This results in the overall pose parameter R9× 14. We feed this into a small fully-connected network: θ∈ R9× 14→ FC63→ LReLU→ FC24→ zθ∈ R24The clothing type c refers to the type of “outfit”, ie a combination of upper body clothing and lower body clothing. There are four types of outfits in our training data: longlong: long sleeve shirt/T-shirt/jersey with long pants; shortlong: short sleeve shirt/T-shirt/jersey with long pants; and their opposites, shortshort and longshort. As the types of clothing are discrete by nature, we represent them using a one-hot vector, c∈ R4, and feed it into a linear layer:",Qianli Ma and Jinlong Yang and Anurag Ranjan and Sergi Pujades and Gerard Pons-Moll and Siyu Tang and Michael J Black,0,,,,,,Supplementary Material: Learning to Dress 3D People in Generative Clothing,https://cape.is.tue.mpg.de/uploads/ckeditor/attachments/214/CAPE_suppmat.pdf,,,,6NjbexEAAAAJ:9fSugHr6AN8C

1010417,"We first present an ablation study for the different losses we defined on the MANO hand model (Section A. 1). Then, we study the latent hand representation (Section A. 2). Finally, we validate our hand pose estimation branch and demonstrate its competitive performance compared to the state-of-the-art methods on a benchmark dataset (Section A. 3).",Yana Hasson and Gül Varol and Dimitrios Tzionas and Igor Kalevatykh and Michael J Black and Ivan Laptev and Cordelia Schmid,0,,,,,,Supplemental Material: Learning joint reconstruction of hands and manipulated objects,http://openaccess.thecvf.com/content_CVPR_2019/supplemental/Hasson_Learning_Joint_Reconstruction_CVPR_2019_supplemental.pdf,,,,6NjbexEAAAAJ:abCsMXLaarkC

1010418,"Comparison of SMPL, SMPL+ H & SMPL-X: In Section 4.2 of the main paper, in Table 1 we present a quantitative comparison between different models with different modeling capacities. In Fig. A. 1 we present a similar comparison for SMPL (left), SMPL+ H (middle) and SMPL-X (right) for an image of the EHB dataset. For fair comparison we fit all models with a variation of SMPLify-X to a single RGB image. The figure reflects the same findings as Table 1 of the paper, but qualitatively; there is a clear increase in expressiveness from left to right, as model gets richer from body-only (SMPL) to include hands (SMPL+ H) or hands and face (SMPL-X).Holistic vs part models: In Section 4.2 and Fig. 5 of the main paper we compare our holistic SMPL-X model to the hand-only approach of [24] on EHB. Figure A. 2 shows a similar qualitative comparison, this time on the data of [24]. To further explore the benefit of holistic reasoning, we also focus on the head and we compare SMPL-X fitting to a head-only method by fitting FLAME [16] to 2D keypoints similar to our method. The context of the full body stabilizes head estimation for occlusions or non-frontal views (see Fig. A. 3). This benefit is also quantitative, where the holistic SMPL-X improves over the head-only fitting by 17% in our EHF dataset in terms of vertex-to-vertex error. Failure cases: Figure A. 4 shows some representative failure cases; depth ambiguities can cause wrong estimation of torso pose or wrong ordinal depth estimation of body parts due to the simple 2D re-projection data term. Furthermore, occluded joints leave certain body parts unconstrained, which currently leads to failures. We plan to …",Georgios Pavlakos and Vasileios Choutas and Nima Ghorbani and Timo Bolkart and Ahmed AA Osman and Dimitrios Tzionas and Michael J Black,0,,,,,,"Expressive Body Capture: 3D Hands, Face, and Body from a Single Image** Supplementary Material",http://openaccess.thecvf.com/content_CVPR_2019/supplemental/Pavlakos_Expressive_Body_Capture_CVPR_2019_supplemental.pdf,,,,6NjbexEAAAAJ:tCoNjB6AT50C

1010419,"MoCap Data. To pose the body we use 1, 515 MoCap sequences from the CMU dataset [1], 62 from HumanEva [14], 41 from the PosePrior dataset [3] and 157 unpublished sequences recorded with our own motion capture system. To reduce the similarity of poses we subsample every 10th frame, resulting in 12 fps for most of the datasets. We end up with 253, 762 individual poses. Hand Poses. Without variations of hand poses, a keypoint detector trained on the synthetic data might not generalize to other hand poses. To avoid this, we use SMPL+ H [13] and pose the hands and fingers. However, conventional MoCap systems do not record the pose of fingers [1, 3, 14]. To obtain realistic poses for hands and fingers we use the “embodied hands” dataset [13]. Shape. Besides body pose, humans differ in their body shape. To express these differences in our synthetic datasets we extract shape parameters β from standard MoCap datasets using MoSh [9]. Textures. Textures have a large influence on the perceived realism of synthetic data. For the synthetic humans we use the textures published with the SURREAL dataset [18]. The dataset provides 772 textures of people in casual clothing and 157 in minimal clothing. The former were collected by the authors of [18]. The latter were acquired from the CAESAR dataset [11]. We use 80% of these textures and keep the remaining 20% for validation and test data, even though we do not use any synthetic validation or test data for this particular work. The reason for this decision is to keep the data splits for training, test and validation consistent across projects.Noise and Lighting. Real images are subject to …",David T Hoffmann and Dimitrios Tzionas and Michael J Black and Siyu Tang,0,,,,,,Learning to Train with Synthetic Humans** Supplementary Material,https://pdfs.semanticscholar.org/00aa/0dddcccbeb341a0db190bb8dfc7d32f785b2.pdf,,,,6NjbexEAAAAJ:8dmKnlANe1sC

1010420,"Previous research has suggested that own body size estimates are biased towards an average reference body (Cornelissen, Bester, Cairns, Tovée & Cornelissen, 2015). The role of personal body size in body size perception of others is still unclear. In two sets of psychophysical experiments, we tested healthy females varying in body mass index (BMI) to investigate whether personal body size influenced accuracy of body size estimates and sensitivity to weight changes of others. For the first set of psychophysical experiments, we generated four biometric female avatars with BMIs of 15, 25, 35, and 45 and altered the weight of the avatars (±5,±10,±15, and±20% BMI change) based on a statistical body model. The stimuli were presented on a stereoscopic, large-screen immersive display. For each avatar series, participants memorized what the original body looked like and then responded for each of the presented bodies whether it was the same as the one memorized. Our results show that there was no influence of personal BMI on the accuracy of body size estimates of the avatars. Interestingly however, participants were more sensitive to weight changes of an avatar close in BMI to their own. To further investigate this effect, in a second set of experiments we presented female participants varying in BMI with two bodies simultaneously and asked them to judge which of the two bodies was fatter. Again, sensitivity to differences in body weight was highest for bodies close to own BMI.",Anne Thaler134 and Michael N Geuss and Simone C Mölbert145 and Stephan Streuber and Katrin E Giel and Michael J Black and Betty J Mohler,0,,,,,,Does Sensitivity to Weight Changes of Others Depend on Personal Body Size?,http://scholar.google.com/scholar?cluster=4477373339629207717&hl=en&oi=scholarr,,,,6NjbexEAAAAJ:sq_mVe84DbIC

1010421,"The goal of this Supplementary Material is to provide additional details that were not included in the main manuscript due to space constraints. In Section 1 we present additional quantitative results. Section 2 aims to provide qualitative results for a wide range of settings, including: visualization from novel viewpoints, comparison with the approach of Kanazawa et al.[6], comparison of the “unpaired” version and the version that has access to 3D ground truth, etc. Then, in Section 3, we provide more details about the training procedure. Finally, in Section 4, we discuss the evaluation metrics used to report results.",Nikos Kolotouros and Georgios Pavlakos and Michael J Black and Kostas Daniilidis,0,,,,,,Learning to Reconstruct 3D Human Pose and Shape via Model-fitting in the Loop** Supplementary Material,http://openaccess.thecvf.com/content_ICCV_2019/supplemental/Kolotouros_Learning_to_Reconstruct_ICCV_2019_supplemental.pdf,,,,6NjbexEAAAAJ:FuNQ1RLggQIC

1010422,"This supplementary document provides additional results on White-box and Black-box attacks as well as an analysis of FlowNet2 [3] and Back2Future [4] under the Zero-Flow test. In the video 1, we show real world attacks using a printed patch placed in the environment.",Anurag Ranjan and Joel Janai and Andreas Geiger and Michael J Black,0,,,,,,Supplementary Material: Attacking Optical Flow,http://openaccess.thecvf.com/content_ICCV_2019/supplemental/Ranjan_Attacking_Optical_Flow_ICCV_2019_supplemental.pdf,,,,6NjbexEAAAAJ:pqgf-8x9CmQC

1010423,"Sec. 4.1 of the main paper presents the SSM (Synchronized Scans and Markers) dataset. To record this dataset we use an optical motion capture system synchronized and calibrated together with a high resolution 4D scanning system. We used an OptiTrack motion capture system (Natural-Point, Inc. DBA OptiTrack. Corvallis, OR)[4] consisting of 24 Optitrack Prime 17W optical mocap cameras. Each subject was fitted with 67 reflective mocap markers based on the optimized marker-set layout proposed in [3]. The subjects wore minimal clothing to avoid artifacts due to sliding of cloth. The markers were placed directly on the skin of the subjects wherever possible. The motion capture system was synchronized to be triggered with a 3dMD 4D body scanning system (3dMD LLC, Atlanta, GA)[1]. The 4D scanner is capable of capturing high-resolution 3D scans of a person at 60 frames per second. The 4D system uses 22 pairs of stereo cameras, 22 color cameras and 34 speckle projectors and arrays of white-light LED panels.",Naureen Mahmood and Nima Ghorbani and Nikolaus F Troje and Gerard Pons-Moll and Michael J Black,0,,,,,,AMASS: Archive of Motion Capture as Surface Shapes* Supplementary Material,http://openaccess.thecvf.com/content_ICCV_2019/supplemental/Mahmood_AMASS_Archive_of_ICCV_2019_supplemental.zip,,,,6NjbexEAAAAJ:yFpZgd9WRDkC

1010424,"Our method enforces Proximal Relationships with Object eXclusion and is called PROX. The figures below show representative examples where the human body pose is estimated with (gray color) and without (yellow color) our environmental terms. From the viewpoint of the camera, both solutions look good and match the 2D image features but, when placed in a scan of the 3D scene, the results without environment constraints can be grossly inaccurate. Adding our constraints to the optimization reduces inter-penetration and encourages appropriate contact. Why such constraints are not typically used? One key reason is that to estimate and reason about contact and interpenetration, one needs both a model of the 3D scene and a realistic model of the human body. The former is easy to obtain today with many scanning technologies but, if the body model is not accurate, it does not make sense to reason about contact and inter-penetration. Consequently we use the SMPL-X body model [3], which is realistic enough to serve as a “proxy” for the real human in the 3D scene. In particular, the feet, hands, and body of the model have realistic shape and degrees of freedom. Is it realistic to assume a 3D scene for refining pose? Here we assume that a rough 3D model of the scene is available; one could argue that this is a hard assumption. Reconstructing a 3D scene from a single RGB image is a hot research topic, but the problem is ill-posed and currently unsolved. Here we want to show in the first place that knowledge about the scene helps pose estimation. Our results support this hypothesis, and scanning a scene today is quite easy. Our next step is …",Mohamed Hassan and Vasileios Choutas and Dimitrios Tzionas and Michael J Black,0,,,,,,Resolving 3D Human Pose Ambiguities with 3D Scene Constraints** Supplementary Material,http://openaccess.thecvf.com/content_ICCV_2019/supplemental/Hassan_Resolving_3D_Human_ICCV_2019_supplemental.pdf,,,,6NjbexEAAAAJ:d7BmB2BcYiwC

1010425,"Barker, Marilyn, 177 basketry, 108, 135, 137, 141 Basques, 113, 163, 241 Bear Dance, 130, 
131, 132, 136 beehive (state symbol), 13, 105, 174, 191, 192, 268 Beehive Band, 10 beliefs, 
17, 37, 40, 70, 71, 239 Benavides, E. Ferol, 156, 158, 166 Bennett, Keith, 183 Bentley, Harold 
W., 39, 60, 224–27, 226, 252 bibliographies, 36, 279–336 Bingham Canyon, 163, 219 
Birney, Hoffman, 27 Black, Mary Holiday, 124, 141, 195, 199, back cover Blakely, Pamela and 
Tom, 250 Bonamont, Mollie, 137 Bonar, Linda, 183 Book of Mormon, The, 7, 143, 145, 191 
Booth, Bertha, 1–3, 3 Bountiful, Utah, 142 Box, Edward Bent, Sr., 131 Bradley, Martha, 176 
Brady, Margaret K., 12, 15, 104 … Page numbers in boldface type refer to chapters or sections 
of chapters that focus on the topic indexed. Numbers in italics refer to photographs and 
captions … This content downloaded from 66.249.66.211 on Thu, 26 Sep 2019 … ",John C Abramson and Jack Adamson and African Americans and Thomas G Alexander and Allen Park and John R Alley Jr and David Allred and Cecil J Alter and Barry Ancelet and Jay Anderson and Nels Anderson and Niels Anderson and Laurel Blank Andrew and Chris Rigby Arrington and Leonard J Arrington and Asian Pacific Festival and Dennis H Atkins and Louie W Attebery and Elias Baca and Cinda Baldwin and Marilyn Barker and Bear Dance and Beehive Band and E Ferol Benavides and Keith Bennett and Bingham Canyon and Hoffman Birney and Mary Holiday Black and Mollie Bonamont and Linda Bonar and Bertha Booth and Edward Bent Box Sr and Martha Bradley and Walter Briggs and Fawn Brodie and Simon Bronner and Vanessa Brown and Bruce Buckley and Grant Bullethead,0,,children’s literature,65,123,,Page numbers in boldface type refer to chapters or sections of chapters that focus on the topic indexed. Numbers in italics refer to photographs and captions.,https://www.jstor.org/stable/pdf/j.ctt46nxj8.40.pdf,26,,,6NjbexEAAAAJ:q3SxJD15z-gC

1010426,"Barron, JL, Fleet, DJ and Beauchemin, SS, Performance of optical flow techniques, International 
Journal of Computer Vision, 12(1):43-77, 1994 … ~10-60 frames/seq. 12 seqs ~300 frames 
total ~30 flow fields total … 10 20 30 40 50 60 70 … • Can an animated movie teach us about   … • Image statistics are only half the problem … – Harder since we do not have ground truth 
flow … • However, it does pass some sanity checks … Meister and Kondermann, Conference 
on Electronic Media Technology (CEMT), 2011 … CG data is not just “good enough” … • 
Our goal: define places where current flow … • People could compute the flow of the test … 
• As a fraud check, we generate two … – One where the camera motion is different … – One 
where the object motions are changed … They disappear at the top of the pyramid and never 
come back … ~45px error (vs. ~5px in matched regions) … • High speeds (>40 ppf) … ",Jonas Wulff and Michael Black and Garrett Stanley,0,,,,,,Collaborators,https://pdfs.semanticscholar.org/ce18/b4882c85e14c40b11ab1e88401c2bf1df231.pdf,,,,6NjbexEAAAAJ:joW6AvqysxAC

1010427,"Infants and adults have different body proportions. Thus, simply scaling the SMPL [6] model-which was learned from adult subjects-to infant size does not provide satisfactory results. This becomes obvious by processing an rgb image of an infant with the publicly available Keep it SMPL [2] method (see Fig. 1a). As our new SMIL model is compatible with SMPL, we can replace the SMPL model in [2] with our SMIL model-Keep it SMIL-thus obtaining the results shown in Fig. 1b.",Nikolas Hesse and Sergi Pujades and Javier Romero and Michael J Black and Christoph Bodensteiner and Michael Arens and Ulrich G Hofmann and Uta Tacke and Mijna Hadders-Algra and Raphael Weinberger and Wolfgang Müller-Felber and A Sebastian Schroeder,0,,,,,,Supplementary Material: Learning an Infant Body Model from RGB-D Data for Accurate Full Body Motion Analysis,https://www.iosb.fraunhofer.de/servlet/is/82920/smil_supp.pdf,,,,6NjbexEAAAAJ:Kb2XK_T5ZYAC

1010428,"This document contains additional experiments to the paper” Recovering Accurate 3D Human Pose in The Wild Using IMUs and a Moving Camera”[1]. These experiments validate different aspects of VIP, our proposed method for combining IMU-based tracking with a single hand-held camera, and provide further details to the proposed 3DPW.In Section 1, we validate that the explicit modeling of IMU heading errors is an important ingredient of the proposed method. In Section 2 we evaluate tracking accuracy of VIP for an additional IMU sensor setup. In order to demonstrate the challenges of our newly recorded dataset in comparison to existing datasets, we evaluate three monocular 3D pose estimation methods in Section 3.",Timo von Marcard and Roberto Henschel and Michael J Black and Bodo Rosenhahn and Gerard Pons-Moll,0,,,,,,Supplementary Material to: Recovering Accurate 3D Human Pose in The Wild Using IMUs and a Moving Camera,https://virtualhumans.mpi-inf.mpg.de/papers/vonmarcardECCV18/vonmarcardECCV18_supp.pdf,,,,6NjbexEAAAAJ:kF4WlwDc9qcC

1010429,"In this paper we provide an overview of recent research conducted at the University of Maryland's Computer Vision Laboratory on problems related to surveillance of human activities. Our research is motivated by considerations of a ground-based mobile surveillance system that monitors an extended area for human activity. During motion, the surveillance system must detect other moving objects and identify them as humans, animals, vehicles. When one or more persons are detected, their movements need to be analyzed to recognize the activities that they are involved in. Ideally, the surveillance system would be able to accomplish this even while continuing to move; alternatively, the system could stop and stare at that part of the scene containing people. In Section 1 we describe a novel approach to the problem of detecting independently moving objects from a moving ground camera, and illustrate the approach on sequences taken in very cluttered environments. Current research focuses on the problem of classifying those independently moving objects as people based on a combination of their appearance and movement. In Section 2 we describe a system that can track multiple moving people using sequences taken from a stationary camera. This system of algorithms, which has been implemented on a PC and can process 10-30 frames per second (depending on the number of people within the eld of view and the resolution of the imagery) uses a hierarchy of tracking modules to identify and follow people's heads, torsos, feet,... Finally, in Section 4 we explain how the recovered motion of these people can be classi ed into various activity …",Larry Davis1 Sandor Fejes1 David Harwood,0,,,,,,Visual Surveillance of Human Activity,http://www.umiacs.umd.edu/~yaser/accv_paper.pdf,,,,6NjbexEAAAAJ:kPzzr9KoCG0C

1010430,"A Abraham, Rajesh Joseph FrC2.1 Adhy Sasongko, Rianto ThB3.3 Afshar, Ahmad FrB5.1 
Ahmed, Qadeer FrB1.1 Akmeliawati, Rini ThC1.3 Albertos, Pedro ThA7.6 Ambrosino, Roberto 
ThB7.2 An, Jianqi FrB6.6 Anderson, Brian DO FrB1.6 Andreas, NA SaB5.4 Ao, Dun … FrB4 
FrB4.3 Araki, Nozomu ThB1.3 Araujo, Jose FrB7.6 Attarwala, Fakhruddin T FrC5.4 Azizi, Seyyedmohsen 
ThB5.4 FrB6.4 B Top … Badreddin, E. SaB3.3 Badreddin, Essam SaB3.4 Bae, Hyeon FrA6.2 
Bae, Jong-Il FrA6.2 Balikci, Abdulkadir SaB2.1 Bals, Johann ThA3.5 Bando, Mai ThA3.1 
Banjerdpongchai, David FrA1.4 Bao, Jie … FrA5 FrA5.4 FrA5.6 Baron, Luc ThC2.3 Beghi, Alessandro   … SaB4 SaB4.4 Belavy, Cyril SaA1.5 Bèle, Bertrand FrB5.4 Bertinato, Marco SaB4.4 Bhatti, 
Aamer Iqbal FrA6.3 FrB1.1 Bi, Shuhui FrB1.3 Black, Michael FrB2.4 Boukas, El-Kebir ThA6.2 
ThC2.3 Bretthauer, Georg FrA2.6 Bu, Ni FrA4.4 Bu, Yanlong ThB3.1 Bucek, Pavol … ",Rajesh Joseph FrC Abraham and Adhy Sasongko and Rianto ThB and Ahmad FrB Afshar and Qadeer FrB Ahmed and Rini ThC Akmeliawati and Pedro ThA Albertos and Roberto ThB Ambrosino and Jianqi FrB An and Brian Anderson and DO FrB and NA Andreas and Dun FrB Ao and Nozomu ThB Araki and Jose FrB Araujo and Fakhruddin T Attarwala and Seyyedmohsen ThB Azizi and E Badreddin and Essam SaB Badreddin and Hyeon FrA Bae and Jong-Il FrA Bae and Abdulkadir SaB Balikci and Johann ThA Bals and Mai ThA Bando and David FrA Banjerdpongchai and Jie FrA Bao and Luc ThC Baron and Alessandro SaB Beghi and Cyril SaA Belavy and Bertrand FrB Bèle and Marco SaB Bertinato and Aamer Iqbal FrA Bhatti and Shuhui FrB Bi and Michael FrB Black and El-Kebir ThA Boukas and Georg FrA Bretthauer and Ni FrA Bu and Yanlong ThB Bu and Pavol SaA Bucek and Quyen TT Bui and Chenxiao FrC Cai and Guowei ThC Cai and Ning ThC Cai and Hueseyin FrA Cakmak and Hu SaA Cao and Jinde FrC Cao and Xi-Ren ThPP Cao and Luca SaB Cecchinato and Lihui FrC Cen and Sung Han FrB Cha,0,,,,,,ASCC09 Author index,https://ieeexplore.ieee.org/abstract/document/5276159/,,,,6NjbexEAAAAJ:dnWPDgH667kC

1010431,"We propose a model for the incremental estimation of visual motion fields from image sequences. Our model exploits three standard constraints on image motion within an optimization framework: i) Data Conservation: the intensity structure of a surface patch changes gradually over time; ii) Spatial Coherence: neighboring points have sim-ilar motions; iii) Temporal Coherence: the im-age velocity of a surface patch changes gradually. Our formulation takes into account the possibility of multiple motions at a particular location. We present an incremental scheme for the minimiza-tion of our objective function, based on simulated annealing. All computations are parallel, local, and incremental, and occlusion and disocclusion boundaries are estimated..,",Michael J Black and P Anandan,0,,,,,,To appear: Proceedings of the International Conference on Computer,http://128.148.32.110/people/mjblack/Papers/iccv90.pdf,,,,6NjbexEAAAAJ:tp0eXr8pwPYC

1010432,"Using styles derived from existing popular character designs, we present a novel automatic stylization technique for body shape and colour information based on a statistical 3D model of human bodies. We investigate whether such stylized body shapes result in increased perceived appeal with two different experiments: One focuses on body shape alone, the other investigates the additional role of surface colour and lighting. Our results consistently show that the most appealing avatar is a partially stylized one. Importantly, avatars with high stylization or no stylization at all were rated to have the least appeal. The inclusion of colour information and improvements to render quality had no significant effect on the overall perceived appeal of the avatars, and we observe that the body shape primarily drives the change in appeal ratings. For body scans with colour information, we found that a partially stylized avatar was perceived as most appealing.",Reuben Fleming and Betty J Mohler and Javier Romero and Michael J Black and Martin Breidt,0,,,,,,Appealing Avatars from 3D Body Scans,http://scholar.google.com/scholar?cluster=16877248775056481509&hl=en&oi=scholarr,,,,6NjbexEAAAAJ:C-GuzCveMkwC

1010433,Method Classification rate Data (1.6 s) 0.76 PCA 0.73 Lower Layer Middle Layer Upper Layer DSAE [3] 0.72 0.65 0.62 S-TE 0.78 0.74 0.67 C-TE 0.78 0.74 0.73 H-TE 0.77 0.73 0.69,Judith Bütepage and Michael J Black and Danica Kragic and Hedvig Kjellström,0,,,,,,Deeprepresentationlearning forhumanmotionpredictionandclassification,http://openaccess.thecvf.com/content_cvpr_2017/poster/2714_POSTER.pdf,,,,6NjbexEAAAAJ:Qo9Q-PfIzZ0C

1010434,"This review describes the rationale, early stage development, and initial human application of neural interface systems (NIS) for humans with paralysis. NIS are an emerging medical device designed to allow persons with paralysis to operate assistive technologies or to reanimate muscles based upon a command signal that is obtained directly from the brain. Such systems require the development of sensors to detect brain signals, decoders to transform signals neural activity into a useful command, and an",John P Donoghue and Arto Nurmikko and Michael Black and Leigh Hochberg,0,,,,,,Physiology in Press,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.70.2766&rep=rep1&type=pdf,,,,6NjbexEAAAAJ:3_iODIlCio4C

1010435,"We propose a model for the incremental estimation of visual motion fields from image sequences. Our model exploits three standard constraints on image motion within an optimization framework: i) Data Conservation: the intensity structure of a surface patch changes gradually over time; ii) Spatial Coherence: neighboring points have sim-ilar motions; iii) Temporal Coherence: the im-age velocity of a surface patch changes gradually. Our formulation takes into account the possibility of multiple motions at a particular location. We present an incremental scheme for the minimization of our objective function, based on simulated annealing. All computations are parallel, local, and incremental, and occlusion and disocclusion boundaries are estimated.",Michael J Black and P Anandan,0,,,,,,Department of Computer Science Yale University,https://www.researchgate.net/profile/Michael_Black6/publication/3504725_A_model_for_the_detection_of_motion_over_time/links/0deec521b8fd888718000000/A-model-for-the-detection-of-motion-over-time.pdf,,,,6NjbexEAAAAJ:YW9K3tL-BTUC

1010436,,Jane Acquaviva and Jill Anderson and Reba L Anderson and Maureen M Black and Tone F Blecher and Chestina Brollier and Sandra Burnett-Beaulieu and Diana P Burnell and Pamela A Buss and Anne D Callahan and Lynn A Caruso and Charles Christiansen and Yong-Iob Chung and Georgia A DeGangi and Mary Dimick and Winifred Dunn and Cynthia Epstein and Rhoda P Erhardt and Julie Evans and Charlotte E Exner and Gordon Muir Giles and Ruth Ann Hansen and Rita Hohlstein and Debbie Holmes and Janet Bower Hulme and Barbara Joe and Marjorie Kircher and Barbara B Lucas and Mary Lee McCarthy and William C Mann and Virgil Mathiowetz and Maureen E Neistadt and David L Nelson and Rick Parente and L Diane Parham and Richard Schwanz and Marilyn Sidler and Kathy B Simon and Roger O Smith and Deborah Sorenson and Karen M Stallons and Barbara Sussenberger and Valerie L Takai and Elaine Trefler and Susan M Tribuzi and Judith C Vestal and Christine Lepley Zander and Barbara Zoltan,0,,,,,,"Thanks, Kind Colleagues",http://scholar.google.com/scholar?cluster=4268031080625083630&hl=en&oi=scholarr,,,,6NjbexEAAAAJ:OBae9N4Z9bMC

1010437,"In this document, we present details of our inference algorithm and additional results. First, we present derivations of the sum-product belief propagation equations. We also present pseudo-code for the inference algorithm. We then present several additional experiments. Our first experiment evaluates the proposed approach with varying model parameters. Second, we present visualizations from our experiment with a small number of images, where our approach significantly improves upon baseline methods. Finally, we present visualizations of the robustness of our approach to approximate input shapes as well as it’s ability to combine image and object shape evidence to produce detailed reconstructions.",Ali Osman Ulusoy and Michael J Black and Andreas Geiger,0,,,,,,Supplementary Material for Semantic Multi-view Stereo: Jointly Estimating Objects and Voxels,http://scholar.google.com/scholar?cluster=11458850134311062370&hl=en&oi=scholarr,,,,6NjbexEAAAAJ:8s_vhd3wPlUC

1010438,"We have obtained human segmentation labels to integrate shape information into the SMPLify 3D fitting procedure and for the evaluation of methods introduced in the main paper. The labels consist of foreground segmentation for multiple human pose datasets and six body part segmentation for the LSP dataset. Whereas we discuss their use in the context of the UP dataset in the main paper, we discuss the annotation tool that we used for the collection (see Sec. 2.1) as well as the direct use of the human labels for model training (see Sec. 2.2) in this document. In Sec. 3.1, we show additional evaluation data of our fine-grained models and conclude with further examples for the applications showcased in the paper in 3.2.",Christoph Lassner and Javier Romero and Martin Kiefel and Federica Bogo and Michael J Black and Peter V Gehler,0,,,,,,Unite the People: Closing the loop between 3D and 2D Human Representations Supplementary Material,https://pdfs.semanticscholar.org/a48c/71153265d6da7fbc4b16327320a5cbfa6cba.pdf,,,,6NjbexEAAAAJ:S_0nULq340kC

1010439,"On INRIA dataset, since texture information is not available, we consider all vertices as cloth and therefore set λskin= 0. We decreased λfit= 1 to be more robust to wide clothing, and keep other weights unchanged. To make a fair comparison in this dataset, we initialize the pose using the exact same Stitched Puppet [4] landmarks computed in [3].",Chao Zhang and Sergi Pujades and Michael Black and Gerard Pons-Moll,0,,,,,,"Supplemental Material: Detailed, accurate, human shape estimation from clothed 3D scan sequences",http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Zhang_Detailed_Accurate_Human_2017_CVPR_supplemental.pdf.pdf,,,,6NjbexEAAAAJ:gFcjaLVeiroC

1010440,"In this supplementary document, we first give some details on the normalization of the data terms used in our Flowlets in Section 1 and the derivation of the Markov random field used for the dense tracking problem in Section 2. In addition, we show with an additional experiment the impact of the frame rate on the estimation error in Section 3, we give more details on the 3D reconstruction dataset (Section 4) and on the comparison of the state-of-the-art methods with our reference data (Section 5). Finally, we show some qualitative results of our dense tracking approach, of the motion blur synthesized with the help of our method and of three state-of-the-art methods in Section 6.",Joel Janai and Fatma Güney and Jonas Wulff and Michael Black and Andreas Geiger,0,,,,,,Supplementary Material for Slow Flow: Exploiting High-Speed Cameras for Accurate and Diverse Optical Flow Reference Data,http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Janai_Slow_Flow_Exploiting_2017_CVPR_supplemental.pdf,,,,6NjbexEAAAAJ:S1WaUgt8gYIC

1010441,"Page 1. Contour People: A Parameterized Model of 2D Articulated Human Shape O. Freifeld
S. Zuffi A. Weiss MJ Black Brown University CVPR 2010 Page 2. 2D generative models of humans
• In wide use in Computer Vision Pose estimation; tracking; gesture analysis • Go back a long
way [Fischler & Elschlager 73, Hinton 76, Hogg 76, Ju et al. 96] • Computationally efficient
Pictorial Structure (PS) and Belief Propagation (BP) [Felzenszwalb & Huttenlocher, IJCV '05]
[Andriluka et al. CVPR '09] Page 3. Problem • Lack of realism (no detailed shape) • Body shape
estimation has many applications Gaming, clothing industry, security • A good model of shape
can improve pose estimation Page 4. Possible solution: SCAPE • A 3D graphics model [Anguelov
et al. Siggraph '05] • Used in computer vision for shape and pose estimation from multiple
calibrated cameras [Balan et al. '07] Page 5. Problem … 
",O Freifeld S Zuffi A Weiss and MJ Black,0,,,,,,Contour People,http://static.cs.brown.edu/people/mjblack/Talks/CVPR2010slides.pdf,,,,6NjbexEAAAAJ:ca9ekAySLm4C

1010442,"This supplementary document presents derivations for the proposed sum-product belief propagation algorithm, pseudocode of the inference algorithm, the derivations of our depth-map prediction method as well as additional experiments. First, we present the message derivations of the sum-product belief propagation algorithm which were omitted in the original document. We then present the pseudocode of our inference algorithm, and in particular the message passing scheme. Besides, we show how Bayes optimal depth predictions can be obtained under our probabilistic model. Finally, we present a number of additional experiments. In particular, we present results by varying the parameters for the model with pairwise smoothness potentials. Next, we present an evaluation for the BARUS&HOLLEY dataset which excludes the tree regions where the LIDAR ground truth is not accurate and show that our algorithm outperforms previous algorithms. Finally, we present an experiment using a uniform prior over plane orientations as opposed to the Manhattan world prior that we utilize in the paper.",Ali Osman Ulusoy and Michael J Black and Andreas Geiger,0,,,,,,"Supplementary Document for Patches, Planes and Probabilities: A Non-local Prior for Volumetric 3D Reconstruction",http://ps.is.tue.mpg.de/uploads_file/attachment/attachment/301/supplementary.pdf,,,,6NjbexEAAAAJ:m1cs02wJCiwC

1010443,"Croux, C. & Filzmoser., P.(1981). Robust factorization of data matrix. Proc. in Computational Statistics (pp. 215–219). dAspremont, A., Ghaoui, LE, Jordan, M., & Lanckriet, G.(2001). A direct formulation for sparse pca using senidefinite programming. Neural linformation l'rocessing Systerns. de la Torre, F.(2006). Coordinating component analysis. tech. report ('ll U-RI-TI-06-08, l'obotics Institute, Carnegie Mellon University. de la Torre, F., & Black, MJ (2001a). Dynamic coupled component analysis. Cornputer Vision and Pattern l'ecognition (pp. 613-650). de la Torre, F., & Black, MJ (2001 b). Robust principal component analysis for computer vision. International Conference on Computer Vision (pp. 362-369). de la Torre, F., & Black, MJ (2002). Robust parameterized component anal-ysis: Theory and applications to 2d facial modeling. European ('onf. on Computer Vision (pp. 653-669). de la Torre, F., & Black, MJ (2003a …",H Aans and R Fisker and K Aastrom and JM Carstensen and MJ Black and Y Yacoob and D Fleet,0,,learning,,117-112,,"on Computer Vision and Pattern l'ecognition (pp. 178–181). Avidan, S.(2001). Support vector tracking.(''onference on Computer Vision",http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.176.5200&rep=rep1&type=pdf,5,,,6NjbexEAAAAJ:zMY8q35v6VMC

1010444,"Increased emphasis on circuit level activity in the brain makes it necessary to have 16 methods to visualize and evaluate large scale ensemble activity, beyond that revealed 17 by raster-histograms or pairwise correlations. We present a method to evaluate the rel-18 ative similarity of neural spiking patterns by combining spike train distance metrics 19 with dimensionality reduction. Spike train distance metrics provide an estimate of sim-20 ilarity between activity patterns at multiple temporal resolutions. Vectors of pair-wise 21 distances are used to represent the intrinsic relationships between multiple activity pat-22 terns at the level of single units or neuronal ensembles. Dimensionality reduction is 23 then used to project the data into concise representations suitable for clustering analysis 24 as well as exploratory visualization. Algorithm performance and robustness are eval-25 uated using multielectrode ensemble activity data recorded in behaving primates. We 26 demonstrate how Spike train SIMilarity Space (SSIMS) analysis captures the relation-27 ship between goal directions for an 8-directional reaching task and successfully segre-28 gates grasp types in a 3D grasping task in the absence of kinematic information. The 29 algorithm enables exploration of virtually any type of neural spiking (time series) data, 30 providing similarity-based clustering of neural activity states with minimal assumptions 31 about potential information encoding models. 32",Carlos E Vargas-Irwin and David M Brandman and Jonas B Zimmermann and John P Donoghue and Michael J Black,0,,,,,,Spike Train SIMilarity Space (SSIMS): a frame,http://files.is.tue.mpg.de/black/papers/neco_a_00684_proof.pdf,,,,6NjbexEAAAAJ:1xqo9R7SDZkC

1010445,"Consider a single ray r associated with ray factor ψr. Since we’re dealing with a single ray, we drop the index r for brevity. The ray factor ψ is connected to N occupancy and N appearance variables. The potential equation for the ray factor (see Eq. 4 in the submission) is as follows: ψ (o, a)=",Ali Osman Ulusoy and Andreas Geiger and Michael J Black,0,,,,,,Supplementary Document for Towards Probabilistic Volumetric Reconstruction using Ray Potentials,http://m.cvlibs.net/publications/Ulusoy2015THREEDV_supplementary.pdf,,,,6NjbexEAAAAJ:vq25oHwZT-8C

1010446,"In this supplementary material, we first show results on extra synthetic and real test sequences (Section 1). We also show that the method deals with violations of our assumptions; for example, non-Lambertian surfaces (Section 2). We perform a sensitivity analysis and find that the results are quite insensitive to the parameter settings (Section 3). We explain the error metrics used to compare our estimated intrinsic video to ground truth (Section 4). We next provide more details on our optimization scheme (Section 5). We then depict more examples of non-local weights that are important to improve shading estimation (Section 6). Finally, we explain how our input data was created, and show the full results in addition to optical flow, occlusion and boundary intrinsic images for each example (Section 7).We overview our test procedure in Fig. 1: The input is a video sequence and optical flow estimated from the sequence. We used the Classic+ NL method [5] with its default settings to compute the optical flow. Occlusion maps and motion boundary maps detected from the flow are used in our coarse-to-fine decomposition algorithm. The output is the estimated albedo and shading sequences. These sequences of optical flow, occlusion, motion boundaries, albedo and shading define intrinsic video. We measure an LMSE (local mean squared error)[3] of the reconstructed albedo and shading images, which is a standard error measure in the field. We also introduce a new measure of temporal incoherence, which assesses how consistent the albedo is over time. Details of the LMSE and incoherence metrics are given below in Sections 4.1 and 4.2, respectively.",Naejin Kong and Peter V Gehler and Michael J Black,0,,,,,,Intrinsic Video (Supplementary Material),http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.495.7039&rep=rep1&type=pdf,,,,6NjbexEAAAAJ:JmU_-KX0ghQC

1010447,"Most renderers are not designed to be inverted: their forward process produces pixels from parameters without introspection into the relationship between them. We propose an approximate differentiable renderer (DR) that models how parameters affect image observations. Our publicly-available OpenDR framework makes it easy to express a forward graphics model, automatically obtain derivatives with respect to the model parameters, and optimize them.",Matthew M Loper and Michael J Black,0,,,,,,ECCV'14,http://files.is.tue.mpg.de/mloper/opendr/poster.pdf,,,,6NjbexEAAAAJ:bJZ_LSxkz4EC

1010448,"This paper examines how portrayals of technologies that evoke the “medium as social actor” and other types of social telepresence contemplate and prophesize the causes and consequences of the ability of technology to convey romantic and/or sexual desire.“According to the most extreme form of this view the only way which one could be sure that a machine thinks is to be the machine and to feel oneself thinking... Likewise according to this view the only way to know that a man thinks is to be that particular man.” Alan M. Turing,“Computing Machinery and Intelligence”(p. 446)[1].",Michael Black and Bonnie Friel and Joan Jasak and Matthew Lombard and Anne Russ,0,,,,,,An Evaluation of Portrayals of Telepresence and Romantic Relationships in Film and Television,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.485.8444&rep=rep1&type=pdf,,,,6NjbexEAAAAJ:qdelZCX8GBYC

1010449,"This document contains the supplementary material for Grassmann Averages for Scalable Robust PCA [4]. Here we provide• pseudo-code for the different algorithms (Sec. B);• a proof of convergence (Sec. C);• a more detailed look at the impact of the trimming parameter in TGA (Sec. D);• some thoughts on statistical efficiency in the context of Fig. 6 in the paper (Sec. E);• an empirical verification of Theorem 2 stating that the Grassmann Average conincides with PCA for Gaussian data (Sec. F);• an empirical study of the influence of outliers when the inliers are Gaussian (Sec. G);• an investigation on the impact of robustness in projections (Sec. H);• some notes on the comparison with Inexact ALM [2, 10](Sec. I);• a brief discussion of the use of extrinsic averages (Sec. J); and• the images of the 20 leading components of Star Wars IV as estimated by EM PCA [9] and TGA (Sec. K).",Søren Hauberg and Aasa Feragen and Michael J Black,0,,,,,,Grassmann Averages for Scalable Robust PCA—Supplementary Material—,http://files.is.tue.mpg.de/shauberg/papers/CVPR_2014/Hauberg_CVPR_2014_Supplements.pdf,,,,6NjbexEAAAAJ:seU1ZbiIO-YC

1010450,"1Department of Computer Science, Brown University, {sghosh,sudderth}@cs.brown.edu 2Perceiving 
Systems Department, Max Planck Institute for Intelligent Systems, {mloper,black}@tuebingen.
mpg.de … The part likelihood is then given by … [1] EB Fox. Bayesian Nonparametric Learning 
of Complex Dynamical Phenomena. PhD thesis, Massachusetts Institute of Technology, 
Cambridge, MA, 2009.  ",Soumya Ghosh and Erik B Sudderth and Matthew Loper and Michael J Black,0,,,,,,Supplement–From Deformations to Parts: Motion-based Segmentation of 3D Objects,http://files.is.tue.mpg.de/black/papers/GhoshSudderthLoperBlack12NIPSsupplement.pdf,,,,6NjbexEAAAAJ:ObAD8Md4PD8C

1010451,"Sec. 1 provides the detailed formulas for the mean field approximation algorithm and discusses 
alternative temporal update schemes. Sec. 2 provides screen shots of the evaluation tables on 
Middlebury and MPI Sintel datasets … Given the flow fields for each layer, the distribution for 
the binary masks is … P(g) = 1 Z exp {−E(g)} … { 2 ∑ k=1 φk data(g p t ,g q t+1) + 
λcφtime(g p t ,g q t+1) } + λb T ∑ t=1 ∑ p ∑ q=p φspace(g p t ,g q t ). (2) … The potential function 
for the spatial term is … The potential function for the temporal term is … The mean field approximation 
solves for an approximate distribution that minimizes the KL divergence … = − ∑ g Q(g) 
log(P(g)) + ∑ g Q(g) log(Q(g)) (8) … = ∑ g Q(g)E(g) + ∑ g Q(g) log(Q(g)) + log(Z) … = 
EQ[E(g] + EQ[log(Q(g))] + log(Z) … The mean field approximation assumes that the approximate 
distribution can be factorized as … Q(g) = T ∏ t=1 ∏ p Q p t (g p t ). (11)  ",Deqing Sun and Jonas Wulff and Erik B Sudderth and Hanspeter Pfister and Michael J Black,0,,,,,,A Fully Connected Layered Model of Foreground and Background Flow: Supplemental Material,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.295.2291&rep=rep1&type=pdf,,,,6NjbexEAAAAJ:9sMhslCZ7ZMC

1010452,"A standard paradigm in decoding motor-cortical population activity, in particular in the context of neuromotor prostheses (NMP), is to infer from the recorded neural signal the kinematics of the movement: position, velocity, and/or acceleration. The movement has been traditionally associated with a moving computer cursor, with no mass and no medium. This is in contrast to natural tasks of the motor system, and to the future prosthesis devices, in which movement is subject to constraints imposed by the laws of physics. Here we propose a model that makes a first step toward addressing the neural control of novel artificial motor systems. This provides an important proof-of-concept for human NMPs. Our approach is to decode the dynamics of hand movement directly from the neural activity. We do not attempt to accurately model the musculoskeletal structure of the arm. Instead, we propose a computationally effective framework to represent the dynamics of the limb moving in two dimensional plane. Our approach is inspired by the generative model for hand-written digits in [1], sketched out in Figure 1. The endpoint of the limb (wrist) is assumed to be connected to one end of four imaginary springs, the other end of which is sliding with no friction along rails forming the boundaries of the 2L× 2L “work area”. Thus, according to Newton’s second law, the acceleration of the hand at time t along x axis is given by max (t)= kA (t)(L− x (t))− kB (t)(L+ x (t))− βvx (t),(1) where vx (t) is the instantaneous velocity of the wrist at time t along the x axis, m is the point mass assumed at the wrist location, and β is the viscosity coefficient that represents the medium resistance …",Gregory Shakhnarovich Sung-Phil Kim Michael and J Black,0,,,,,,Physically-based model for decoding motor-cortical activity,https://www.researchgate.net/profile/Michael_Black6/publication/249880077_Physically-based_model_for_decoding_motor-cortical_activity/links/5417e1d90cf2218008bef3ec/Physically-based-model-for-decoding-motor-cortical-activity.pdf,,,,6NjbexEAAAAJ:3yMDF_cvnR8C

1010453,"It has been a great pleasure and honor for us to organize the Fifth IEEE International Conference 
on Face and Gesture Recognition in Washington, DC This bi-annual conference has provided 
a scholarly forum for exchange of ideas related to face and gesture recognition, and we … Chair 
and the Program Chairs selected the oral and poster papers to be presented at the … In the 
two-day program, we have included two invited talks by world-renowned researchers … Professor 
Dominic Massaro (University of California, Santa Cruz) and Professor Tomaso Poggio (Massachusetts 
Institute of Technology). In addition, we have seven oral sessions and two poster … 
Duraiswami, Nitin Anand, Anurag Mittal, Yang Wang, and Cecilia Kullman … We extend you 
a cordial welcome to the Fifth AFGR Conference and to Washington, DC … Pascal Fua Ecole 
Polytechnique Fédérale de Lausanne, Switzerland … Aaron Bobick, Georgia Inst. of … ",Ramani Duraiswami and Nitin Anand and Yang Wang and Anurag Mittal,0,,,,,,Submissions Chair,https://ieeexplore.ieee.org/iel5/7862/21655/x0556778.pdf,,,,6NjbexEAAAAJ:nrtMV_XWKgEC

1010454,"Section 1 provides additional details for each of the “cooperative” moves used in optimizing the discrete layered model. Section 2 provides a high-level description of the algorithms for determining the depth ordering and the number of layers. Section 3 provides the full set of images illustrating the experimental results. The results include the screen shots of the Middlebury AAE and EPE evaluation tables at the time of writing (April 2012), as well as all experimental results on the Middlebury flow dataset and the MIT layer segmentation dataset.",Deqing Sun and Erik B Sudderth and Michael J Black,0,,,,,,Layered Segmentation and Optical Flow Estimation Over Time: Supplemental Material,https://core.ac.uk/download/pdf/192449671.pdf,,,,6NjbexEAAAAJ:j8SEvjWlNXcC

1010455,"We propose a model for the incremental estimation of visual motion ﬁelds from image sequences. Our model exploits three standard constraints on image motion within an optimization framework: i) Data Conservation: the intensity structure of a surface patch changes gradually over time; ii)Spatial Coherence: neighboring points have similar motions; iii) Temporal Coherence: the image velocity of a surface patch changes gradually. Our formulation takes into account the possibility of multiple motions at a particular location. We present an incremental scheme for the minimization of our objective function, based on simulated annealing. All computations are parallel, local, and incremental, and occlusion and disoccluslion boundaries are estimated.. V-",Michael J Black and P Anandan,0,,,,,,"To appear: Proceedings of the International Conference on Computer ll. l_SlO11, Osaka, Japan, Dec. 1990.",http://scholar.google.com/scholar?cluster=830039302186895701&hl=en&oi=scholarr,,,,6NjbexEAAAAJ:kzcrU_BdoSEC

1010456,"Page 1. x Organizing Committee General Chair Terrence E. Boult, University Colorado at Colorado
Springs, USA Program Chairs Isaac Cohen, University of Southern California, USA Stefano Soatto,
University of California at Los Angeles, USA Program Committee Jake Aggarwal, University of
Texas, USA Michael Black, Brown University, USA Rama Chellappa, University of Maryland, USA
Daniel Cremers, Siemens Corporate Research, Princeton, USA Larry Davis, University of Maryland,
USA Ahmed El-Gammal, Rutgers, State University of New Jersey, USA Irfan Essa, Georgia Institute
of Technology, USA Bogdan Georgescu, Siemens Corporate Research, Princeton, USA Ismael
Haritaoglu, IBM Almaden Research Center, USA Radu Horaud, INRIA, France Roberto Manduchi,
University of California, Santa Cruz, USA Gerard Medioni, University of Southern California, USA
Vittorio Murino, University of Verona, Italy … 
",Isaac Cohen and Stefano Soatto and Jake Aggarwal and Michael Black and Rama Chellappa and Daniel Cremers and Larry Davis and Irfan Essa and Bogdan Georgescu and Ismael Haritaoglu and France Roberto Manduchi and Gerard Medioni and Vittorio Murino and Ram Nevatia and David Nister and John Oliensis and Paco Perales and Marc Pollefeys and Mubarak Shah and Cristian Sminchisescu and Chris Stauffer and Carlo Tomasi and Matthew Turk,0,,,,,,"Terrence E. Boult, University Colorado at Colorado Springs, USA",https://www.computer.org/csdl/proceedings-article/wacv-motion/2005/22712x/12OmNApLGz6,,,,6NjbexEAAAAJ:uLbwQdceFCQC

1010457,"Background• The on-going human neural interface system (NIS) clinical study1 has demonstrated 2D cursor control (point & click) from motor cortical signals recorded by microelectrodes in two participants with tetraplegia. 2, 3• At the core of an NIS, a decoder translates neural activity into control signals. Building a decoder requires training examples of neural activity and movement. However, actual limb movement is unobservable in paralyzed persons.• Among many possible solutions to create training examples, we present a “training cursor” moving on screen and ask the participant to imagine moving it. 1, 2",Sung-Phil Kim and John D Simeral and Leigh R Hochberg and Wilson Truccolo and Gerhard M Friehs and John P Donoghue and Michael J Black,0,,,,,,Tuning Analysis of Motor Cortical Neurons in a Person with Tetraplegia During Performance of Visually Instructed Cursor Control Tasks,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.186.2508&rep=rep1&type=pdf,,,,6NjbexEAAAAJ:JQOojiI6XY0C

1010458,"We propose a model for the incremental estimation of visual motion ﬁelds from image sequences. Our model exploits three standard constraints on image motion within an optimization framework: i) Data. Conservation: the intensity structure of a surface patch changes gradually over time; ii)Spatial Coherence: neighboring points have similar motions; iii) Temporal Coherence: the image velocity of a surface patch changes gradually. Our formulation takes into account the possibility of multiple motions at a particular location. We present an incremental scheme for the minimization of our objective function, based on simulated annealing. All computations are parallel, local, and incremental, and occlusion and disoccluslion boundaries are estimated..'",Michael J Black and P Anandan,0,,,,,,"To appear: Proceedings of the International Conference on Computer Vision, Osaka, Japan, Dec. 1990.",http://files.is.tue.mpg.de/black/papers/iccv90.pdf,,,,6NjbexEAAAAJ:dQ2og3OwTAUC

1010459,"A large literature on natural image statistics suggests the modeling of images in terms of a linear combination of Gabor-like filters. A variety of sparse image coding methods all arrive at similar filters and it has been often noted how these filters resemble the observed spatial receptive fields of V1 simple cells. Related recent work by Welling et al (2002) proposes a probabilistic model of image patches as a product of Student t distributions. As with standard sparse coding methods, this approach defines a model of image patches and not images. To model the probability of an entire image one must account for spatially overlapping receptive fields. Previous sparse coding methods fail to model the correlated image structure present in overlapping image regions.Recently we proposed a"" field of experts""(FOE) model (Roth and Black 2005) that defines a probability density over images by learning a Markov random field …",Michael J Black and Stefan Roth,0,,,,,,On the Receptive Fields of Markov Random Fields: Predictions from a Probabilistic Model of Scene Statistics,http://scholar.google.com/scholar?cluster=12670996877286534645&hl=en&oi=scholarr,,,,6NjbexEAAAAJ:ZuybSZzF8UAC

1010460,"Provides a listing of current committee members and society officers.
",David Forsyth and Andrew Fitzgibbon and Camillo J Taylor and Yann LeCun and Charles Stewart and Bruce Maxwell and Terry Boult and Ioannis A Kakadiaris and Simon Baker and Ronen Basri and Serge Belongie and Michael Black and Andrew Blake and Leon Bottou and Dorin Comaniciu,0,,,,,,"Daniel Huttenlocher, Cornell University",https://www.computer.org/csdl/proceedings-article/cvpr/2006/01640908/12OmNAYoKiS,,,,6NjbexEAAAAJ:PELIpwtuRlgC

1010461,,MJ Black and T Hastie,0,,,,,,CVAP/NADA,http://scholar.google.com/scholar?cluster=6500383350884879469&hl=en&oi=scholarr,,,,6NjbexEAAAAJ:AXPGKjj_ei8C

1010462,,Mario Fritz and Michael Black and Gary Bradski and Willow Garage and Trevor Darrell and Sergey Karayev,0,,,,,,An Addi ve Latent Feature Model for Transparent Object Recogni on,http://scholar.google.com/scholar?cluster=5493849493443558331&hl=en&oi=scholarr,,,,6NjbexEAAAAJ:WA5NYHcadZ8C

1010463,"This paper explores the estimation of surface shape from texture when multiple textures are present in an image region due to texture discontinuities, occlusion, or pseudo-transparency (eg grass seen through a fence). We present both a theoretical analysis of the multiple texture problem and an algorithm that relaxes thesingle texture assumption. Using an analogy between shape-from-texture and motion, we exploit a robust mixture model to recover multiple surface shape estimates in the presence of multiple textured surfaces. The accuracy of the method is comparable that of shape-from-texture algorithms applied to a single texture.",Michael J Black and Ruth Rosenholtz,0,,,,,,"Shape from Multiple, Transparent, and Occluded Textures",http://cs.brown.edu/people/mjblack/Papers/texture-pami.ps.Z,,,,6NjbexEAAAAJ:HE397vMXCloC

1010464,"The tracking and reconstruction of articulated human motion in 3D is a problem that has attracted a great deal of interest in the last years. A system that recovers 3D body pose from video sequences has applications in vision-based human-computer interaction, marker-less motion capture, animation, surveillance and entertainment such as computer games. The fast, nonlinear motion and complicated appearance of humans and the large number degrees of freedom of the human body make the tracking problem a difficult one. To address these problems, a system for tracking and reconstruction of human motion in 3D should possess the following: A strong model for the appearance of humans in images; a model of how people move; and an effective strategy for searching for the right pose in each time step. In previously presented systems, the most common way of addressing these issues has been to constrain the problem domain. The appearance of humans could be constrained by assuming certain clothing and a large contrast between the human and the background. Furthermore, by adding more camera views, more information about the 3D pose of the human can be extracted and ambiguities reduced, thus making the problem easier. The goal of the work presented here is to investigate to which extent the general problem of tracking and reconstructing human motion can be solved, using only a monocular camera view. Thus, no assumptions of the appearance of either the human or the background are introduced. A probabilistic, Bayesian framework for tracking of articulated human motion in 3D is presented. The tracking makes use of a …",Hedvig Sidenbladh and Michael J Black and David J Fleet,0,,,,,,A Probabilistic Framework for Tracking of Articulated Human Motion,ftp://ftp.cs.brown.edu/u/black/pami.pdf.gz,,,,6NjbexEAAAAJ:XiVPGOgt02cC

1010465,"Relations betweenanisotropic di usion and robuststatistics are described in this paper. We show that anisotropic di usion can be seen as a robust estimation procedure that estimates a piecewise smooth image from a noisy input image. The\edge-stopping"" function in the anisotropic di usion equation is closely related to the error norm and in uencefunction intherobust estimation framework. This connection leads to a new\edge-stopping"" function based on Tukey's biweight robust estimator, that preserves sharper boundaries than previous formulations and improves the automatic stopping of the di usion. The robust statistical interpretation also provides a means for detecting the boundaries (edges) between the piecewise smooth regions in the image. We extend the framework to vector-valued images and show applications to robust image sharpening.",Michael Black and Guillermo Sapiro,0,,,,,,"black, marimont",http://scholar.google.com/scholar?cluster=3850905126884683161&hl=en&oi=scholarr,,,,6NjbexEAAAAJ:bnK-pcrLprsC

1010466,"Neural decoding of motor control of hand and arm movements in primates is a challenging task that requires developing statistical models that explain how the recorded neural population activity relates to motor behavior. Until recently, much of the work in this area has focused on learning linear models of decoding for low-dimensional motor control, such as 2D control of a computer cursor. Capturing a richer set of motor behaviors such as hand and arm posture during object grasping and manipulation tasks introduces much higher dimensional representations of motor control. Understanding the underlying degrees of freedom in complex kinematics that are explained by the neural activity is a central question. One way of learning these “effective” degrees of freedom has been to employ dimensionality reduction techniques, such as Principal Component Analysis, to find a linear kinematic subspace that accounts for the observed motor behavior, separate from the observed neural activity. The orthonormal basis vectors that span this subspace are then considered as the underlying latent variables, or “motor primitives” that describe behavior. These motor primitives are not guaranteed to be optimally correlated with the observed neural activity however. In this paper we devise an objective function and optimize it to learn a linear subspace of the motor activity that tries to maximize the correlation between the latent variables of this subspace and the neural activity, while still explaining the motor behavior with reasonable fidelity.",Payman Yadollahpour and Greg Shakhnarovich and Carlos Vargas-Irwin and John Donoghue and Michael Black,0,,,,,,Neurally Constrained Subspace Learning of Reach and Grasp,http://128.148.32.110/research/pubs/theses/masters/2009/payman.pdf,,,,6NjbexEAAAAJ:5ugPr518TE4C

1010467,"Surface discontinuities are detected in a sequence of images by exploiting physical constraints at early stages in the processing of visual motion. To achieve accurate early discontinuity detection we exploit five physical constraints on the presence of discontinuities: i) the shape of the sum of squared differences (SSD) error surface in the presence of surface discontinuities; G) the change in the shape of the SSD surface due to relative surface motion; G) distribution of optic flow in a neighborhood of a discontinuity; iv) spatial consistency of discontinuities; V) temporal consistency of discontinuities. The constraints are described, and experimental results on sequences of real and synthetic images are presented. The work has applications in the recovery of environmental structure from motion and in the generation of dense optic flow fields.",Michael J Black and P Anandan,0,,,,,,Constraints for the iscontinuity fro Mot ion,https://www.aaai.org/Papers/AAAI/1990/AAAI90-158.pdf,,,,6NjbexEAAAAJ:wbdj-CoPYUoC

1010468,"The modeling of spatial discontinuities for problems such as surface recovery, segmentation, image reconstruction, and optical flow has been intensely studied in computer vision. While “line-process” modelsofdiscontinuitieshave receiveda great dealof attention, therehas beenrecentinterestintheuseofrobuststatisticaltechniquestoaccountfordiscontinuities. This paper unifies the two approaches. To achieve this we generalize the notion of a “line process” to that of an analog “outlier process” and show how a problem formulated in terms of outlier processes can be viewed in terms of robuststatistics. We also characterize a class of robuststatisticalproblems for which an equivalentoutlier-processformulationexistsand give a straightforwardmethodfor convertinga robustestimationproblemintoanoutlier-processformulation. We show how prior assumptionsabout the spatialstructure of outlierscan be expressed as …",Michael J Black,0,,,,,,"Xerox Palo Alto Research Center, Palo Alto, CA 94304 y Department of Computer Science, Yale University, New Haven, CT 06520–8285",http://scholar.google.com/scholar?cluster=2214257299099418116&hl=en&oi=scholarr,,,,6NjbexEAAAAJ:1qzjygNMrQYC

1010469,"Neural Engineering Isomap Approach to EEG-Based Assessment of Neurophysiological Changes 
During Anesthesia ......................... .................................................................................J.Kortelainen,E
.Väyrynen,andT.Seppänen … Statistical Inference for Assessing Functional Connectivity of Neuronal 
Ensembles With Sparse Spiking Data ........... . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. . . . . . . . . . . . . . . . . . Z. Chen, DF Putrino, S. Ghosh, R. Barbieri, and EN Brown … Taking 
NIRS-BCIs Outside the Lab: Towards Achieving Robustness Against Environment Noise .......
.................. ............................................................................... TH Falk, M. Guirgis, S. Power, and TT 
Chau … Use of an Experimentally Derived Leadfield in the Peripheral Nerve Pathway Discrimination 
Problem ................... ................................... J. Zariffa, MK Nagai, M. Schuettler, T. Stieglitz, ZJ 
Daskalakis, and MR Popovic … Rehabilitation Engineering A 3-DOF Parallel Robot With … ",F PatanèandP Cappa and BK Park and Y Kwon and JW Kim and JH Lee and GM Eom and SB Koh and JH Jun and J Hong and APL Bó and P Poignet and C Geny and SP Kim and JD Simeral and LR Hochberg and JP Donoghue and GM Friehs and MJ Black,0,,,,,,A 3-DOF Parallel Robot With Spherical Motion for the Rehabilitation and Evaluation of Balance Performance..........,https://ieeexplore.ieee.org/abstract/document/5745719/,,,,6NjbexEAAAAJ:V3AGJWp-ZtQC

