id,abstract,author,cites,cites_id,journal,number,pages,publisher,title,url,volume,year,citation_link,id_citations
1021000,"Energy-efficiency in target tracking applications has been extensively studied in the literature of Wireless Sensor Networks (WSN). However, there is little work which has been done to survey and summarize this effort. In this paper, we address the lack of these studies by giving an up-to-date State-of-the-Art of the most important energy-efficient target tracking schemes. We propose a novel classification of schemes that are based on the interaction between the communication subsystem and the sensing subsystem on a single sensor node. We are interested in collaborative target tracking instead of single-node tracking. In fact, WSNs are often of a dense nature, and redundant data that can be received from multiple sensors help at improving tracking accuracy and reducing energy consumption by using limited sensing and communication ranges. We show that energy-efficiency in a collaborative WSN-based target …",Oualid Demigha and Walid-Khaled Hidouci and Toufik Ahmed,177,10832222625796765345,IEEE Communications Surveys & Tutorials,3,1210-1222,IEEE,On energy efficiency in collaborative target tracking in wireless sensor network: A review,https://ieeexplore.ieee.org/abstract/document/6196144/,15,2012,/scholar?cites=10832222625796765345,q3KEGmAAAAAJ:aqlVkmm33-oC
1021001,"Arabic is the official language overall Arab coun-tries, it is used for official speech, news-papers, public adminis-tration and school. In Parallel, for everyday communication, non-official talks, songs and movies, Arab people use their dialects which are inspired from Standard Arabic and differ from one Arabic country to another. These linguistic phenomenon is called disglossia, a situation in which two distinct varieties of a language are spoken within the same speech community. It is observed Throughout all Arab countries, standard Arabic widely written but not used in everyday conversation, dialect widely spoken in everyday life but almost never written. Thus, in NLP area, a lot of works have been dedicated for written Arabic. In contrast, Arabic dialects at a near time were not studied enough. Interest for them is recent. First work for these dialects began in the last decade for middle-east ones. Dialects of the Maghreb are just beginning to be studied. Compared to written Arabic, dialects are under-resourced languages which suffer from lack of NLP resources despite their large use. We deal in this paper with Arabic Algerian dialect a non-resourced language for which no known resource is available to date. We present a first linguistic study introducing its most important features and we describe the resources that we created from scratch for this dialect.",Salima Harrat and Karima Meftouh and Mourad Abbas and Walid-Khaled Hidouci and Kamel Smaili,24,4596104491564547419,,,,,An algerian dialect: Study and resources,https://hal.archives-ouvertes.fr/hal-01297415/,,2016,/scholar?cites=4596104491564547419,q3KEGmAAAAAJ:eQOLeE2rZwMC
1021002,"In this paper, we evaluate our automatic text summarization system in multilingual context. We participated in both single document and multi-document summarization tasks of MultiLing 2015 workshop.Our method involves clustering the document sentences into topics using a fuzzy clustering algorithm. Then each sentence is scored according to how well it covers the various topics. This is done using statistical features such as TF, sentence length, etc. Finally, the summary is constructed from the highest scoring sentences, while avoiding overlap between the summary sentences. This makes it language-independent, but we have to afford preprocessed data first (tokenization, stemming, etc.).",Abdelkrime Aries and Djamel Eddine Zegour and Khaled Walid Hidouci,14,8885202104066502588,,,237-244,,AllSummarizer system at MultiLing 2015: Multilingual single and multi-document summarization,https://www.aclweb.org/anthology/W15-4634.pdf,,2015,/scholar?cites=8885202104066502588,q3KEGmAAAAAJ:e5wmG9Sq2KIC
1021003,"Summaries are important when it comes to process huge amounts of information. Their most important benefit is saving time, which we do not have much nowadays. Therefore, a summary must be short, representative and readable. Generating summaries automatically can be beneficial for humans, since it can save time and help selecting relevant documents. Automatic summarization and, in particular, Automatic text summarization (ATS) is not a new research field; It was known since the 50s. Since then, researchers have been active to find the perfect summarization method. In this article, we will discuss different works in automatic summarization, especially the recent ones. We will present some problems and limits which prevent works to move forward. Most of these challenges are much more related to the nature of processed languages. These challenges are interesting for academics and developers, as a path to follow in this field.",Abdelkrime Aries and Walid Khaled Hidouci,10,6511768306655164815,arXiv preprint arXiv:1904.00688,,,,Automatic text summarization: What has been done and what has to be done,https://arxiv.org/abs/1904.00688,,2019,/scholar?cites=6511768306655164815,q3KEGmAAAAAJ:roLk4NBRz8UC
1021004,"Massive and large scale content distribution over Internet is attracting a lot of research efforts as many challenges remain to be solved. Recent studies show that Internet video including video-to-TV and video calling is dominating the Internet traffic. As Internet becomes widely accessible to wired, mobile and wireless users, it is important to design a system that can ensure video streaming across variable network conditions while simultaneously handling devices and end-user heterogeneities. Most of the proposed solutions, such as CDN and peer-to-peer (P2P), solve the scalability problem but fail to handle receiver's heterogeneity. In this paper, we combine P2P network and SVC (Scalable Video Coding) to provide an efficient video sharing and streaming system. Our solution consists of an SVC layered extension of the widely used Bittorrent protocol to support real-time content delivery with different video qualities …",Amer Abdelhalim and Touflk Ahmed and Hidouci Walid-Khaled and Satoshi Matsuoka,10,10060170591984185763,,,000537-000543,IEEE,Using Bittorrent and SVC for efficient video sharing and streaming,https://ieeexplore.ieee.org/abstract/document/6249352/,,2012,/scholar?cites=10060170591984185763,q3KEGmAAAAAJ:0EnyYjriUFMC
1021005,"In this paper, we propose a dynamic clustering protocol coupled with a consensus-based Kalman filter algorithm to self-organize Wireless Sensor Networks for localized tracking of a single moving target. Our proposed scheme takes opportunity from the fact that the target presence is a localized event. Therefore, We consider a WSN with limited sensing range to design a target tracking scheme using low-cost limited-energy nodes. Simulation results show a clear improvement in the network energy consumption, however state estimation quality degrades slightly compared with centralized approaches and other tracking schemes with limited sensing range that do not limit the set of tracking nodes. Our tracking scheme reduces the number of tasking nodes which reduces the network energy consumption.",Oualid Demigha and Hamza Ould Slimane and Abderahim Bouziani and Walid-Khaled Hidouci,10,18088132360691913973,Proc. ICSNC,,,,Energy efficient target tracking in wireless sensor networks with limited sensing range,https://www.researchgate.net/profile/Oualid_Demigha/publication/267249692_Energy_Efficient_Target_Tracking_in_Wireless_Sensor_Networks_with_Limited_Sensing_Range/links/54bcc32e0cf24e50e9408ce4/Energy-Efficient-Target-Tracking-in-Wireless-Sensor-Networks-with-Limited-Sensing-Range.pdf,,2011,/scholar?cites=18088132360691913973,q3KEGmAAAAAJ:qUcmZB5y_30C
1021006,"Skew detection is a crucial step for document analysis systems. Indeed, it represents one of the basic challenges, especially in case of historical documents analysis. In this paper, we propose a novel robust skew angle detection and correction technique. Morphological Skeleton is introduced to significantly reduce the amount of data to treat by removing the redundant pixels and keeping only the central curves of the image components. The proposed method then uses Progressive Probabilistic Hough Transform (PPHT) to identify image lines. A special procedure is finally applied in order to estimate the global skew angle of the document image from these detected lines. Experimental results prove the accuracy and the efficiency of our approach on skew angle detection over three popular datasets containing various types of document of different linguistic writings (such as Chinese, English and Greek) and diverse …",Omar Boudraa and Walid Khaled Hidouci and Dominique Michelucci,8,13848986440566035195,,,1-6,IEEE,An improved skew angle detection and correction technique for historical scanned documents using morphological skeleton and progressive probabilistic Hough transform,https://ieeexplore.ieee.org/abstract/document/8192043/,,2017,/scholar?cites=13848986440566035195,q3KEGmAAAAAJ:qxL8FJ1GzNcC
1021007,We present in this paper the new concept of 'actor databases' (DB-Act) being studied at the INI institute (Act21 project) where we are developing a parallel DBMS based on an actor like data model. To achieve data distribution we use a Scalable Distributed Data Structures (SDDS) called 'distributed Compact Trie Hashing' (CTH*) currently in developmentat the same project. Processing distribution is made through actors (dynamic autonomous objects) implemented with the PVM (Parallel Virtual Machine) library. A database isthen a collection of actors that maintain and manage data over a multi-computer and collaborate with each other to evaluate user queries and application programs.,WK Hidouci and DE Zegour,8,10629711748059516446,WSEAS Transactions on Computers,3,653-660,,Actor oriented databases.,http://scholar.google.com/scholar?cluster=10629711748059516446&hl=en&oi=scholarr,3,2004,/scholar?cites=10629711748059516446,q3KEGmAAAAAJ:MXK_kJrjxJIC
1021008,"This paper proposes a feedback scheduler for energy harvesting systems (FS-EH) in a soft real-time context on a DVFS processor. This scheduler reduces the processor speed in proportion to the available energy in the batteries and the processor utilization. The goal is to experimentally maximize the battery life while minimizing the deadline miss ratio. When the battery is full, the harvested energy is wasted, therefore the system could use the processor at full speed. This is accounted for in FS-EH by using the processor at full speed when the available energy is over a given threshold. Otherwise, the processor speed is set proportionally to the available energy and instantaneous processor utilization. We experimentally show that FS-EH performs better, in terms of energy consumption, quality of control and deadline miss rate than other scheduling algorithms proposed in this context.",Akli Abbas and Malik Loudini and Emmanuel Grolleau and Driss Mehdi and Walid-Khaled Hidouci,7,3194264266436223996,Computer Standards & Interfaces,,264-273,North-Holland,A real-time feedback scheduler for environmental energy with discrete voltage/frequency modes,https://www.sciencedirect.com/science/article/pii/S0920548915001002,44,2016,/scholar?cites=3194264266436223996,q3KEGmAAAAAJ:UeHWp8X0CEIC
1021009,"Multi-table indexes boost the performance of extremely large databases by reducing the cost of joins involving several tables. The bitmap join indexes () are one of the most popular examples of this category of indexes. They are well adapted for point and range queries. Note that the selection of multi-table indexes is more difficult than the mono-table indexes, considered as the pioneer of database optimisation problems. The few studies dealing with the  selection problem in the context of relational data warehouses have three main limitations: (i) they consider  defined on only two tables (a fact table and a dimension table) by the use of one or several attributes of that dimension table, (ii) they use simple greedy algorithms to pick the right indexes and (iii) their algorithms are static. In this paper, we propose genetic algorithms for selecting  using a large number of attributes belonging to n …",Rima Bouchakri and Ladjel Bellatreche and Khaled-Walid Hidouci,7,11097102644473702597,,,43-56,"Springer, Berlin, Heidelberg",Static and incremental selection of multi-table indexes for very large join queries,https://link.springer.com/chapter/10.1007/978-3-642-33074-2_4,,2012,/scholar?cites=11097102644473702597,q3KEGmAAAAAJ:_Qo2XoVZTnwC
1021010,"Area monitoring using Internet and barrier coverage is a typical application of wireless sensor networks. The main concerns in this type of applications are coverage efficiency and sensor energy conservation. For that, many activities scheduling algorithms are proposed in the literature. Unlike prior efforts based on an unrealistic binary sensor coverage model, this paper proposes three efficient activities scheduling algorithms based on realistic sensor coverage models. The first algorithm (C1L-PBC) is centralized and it is based on a coverage graph. The second algorithm (D1L-PBC) is distributed and it ensures 1-barrier coverage; whereas, the third one (D2L-PBC) is also distributed and it guarantees 2-barrier coverage. The obtained experimental results show that the proposed algorithms can effectively guarantee the barrier coverage and prolong the sensor network lifetime.",Mohammed Boudali and Mustapha Reda Senouci and Mohamed Aissani and Walid-Khaled Hidouci,5,17629024701907515562,Annals of Telecommunications,3-4,221-232,Springer Paris,Activities scheduling algorithms based on probabilistic coverage models for wireless sensor networks,https://link.springer.com/content/pdf/10.1007/s12243-017-0564-9.pdf,72,2017,/scholar?cites=17629024701907515562,q3KEGmAAAAAJ:IWHjjKOFINEC
1021011,"Our last decade has experienced significant growth in terms of data generated by billions of people connected to the Internet. Recent prognoses about Big Data, Internet of Thing, Cloud Computing show growing demand for an efficient processing of huge amount of data with strict time limits. The Best data distribution on Shared Nothing Architecture (SN) is a major issue. SDDS (Scalable Distributed Data Structure) is one of the most important data structure family that is able to store, manage a huge amount of data in distributed environments. In this paper, we present an SDDS driven approach in which data is partitioned using the dynamic intervals. We are targeting any application that handles a large volume of data to be distributed over a cluster of parallel processing. This volume of data is continuously supplied in real time from multiple sources. In such situation, to face the risk of major data imbalances (Data …",Djahida Belayadi and Walid Hidouci,5,8586332999485875039,,,1214-1220,IEEE,Dynamic range partitioning with asynchronous data balancing,https://ieeexplore.ieee.org/abstract/document/7816981/,,2016,/scholar?cites=8586332999485875039,q3KEGmAAAAAJ:UebtZRa9Y70C
1021012,"Snapshot Isolation (SI) is a multiversion concurrency control protocol, allowing the concurrent transactions to consult older versions of the database while generating new versions using write operation. Its main advantage is to avoid the read-write conflicts, i.e. a read operation will never be blocked by a write operation and vice versa. Among existing concurrency control protocols, SI offers the highest degree of concurrency. But SI is known to be non-serializable, that is, in some situations data consistency can be violated through concurrency, even between correct applications. Recently, some extensions of SI protocol have been proposed to make it serializable. However, each of these extensions of SI admits an additional overhead to strengthen serializability. In this work, we explore the impact of the approach based on changing the SI concurrency control mechanism to ensure serializability of executions on …",Fairouz Zendaoui and Walid Khaled Hidouci,5,3785572546935237389,,,1-11,IEEE,Performance evaluation of serializable snapshot isolation in PostgreSQL,https://ieeexplore.ieee.org/abstract/document/7244971/,,2015,/scholar?cites=3785572546935237389,q3KEGmAAAAAJ:zYLM7Y9cAGgC
1021013,"In this letter, we propose a binary integer linear programming (BILP) model of the problem of Energy Minimization under the constraint of Data Precision in the context of correlated data collection in wireless sensor networks, called EMDP. The exact solution of our BILP model determines, in each round of data collection, the role of each node in terms of sensing, data relaying, and processing. It gives the baseline for optimal network operations and helps characterizing the complexity of EMDP problem. Moreover, we propose a heuristic solution, namely, CORAD, which is an energy-aware correlation-based adaptive dynamic clustering algorithm for data collection.",Oualid Demigha and Walid-Khaled Hidouci and Toufik Ahmed,5,1714917760257564279,IEEE Communications Letters,12,2185-2188,IEEE,A novel BILP model for energy optimization under data precision constraints in wireless sensor networks,https://ieeexplore.ieee.org/abstract/document/6933864/,18,2014,/scholar?cites=1714917760257564279,q3KEGmAAAAAJ:9yKSN-GCB0IC
1021014,"As a main part of several document analysis systems, Skew estimation represents one of the major research challenges, particularly in case of historical documents exploration. In this paper, we propose an original skew angle detection and correction technique. Morphological Skeleton is introduced to considerably diminish the amount of data by eliminating the redundant pixels and preserving only the central curves of the image components. Next, the proposed method uses Progressive Probabilistic Hough Transform (PPHT) to find image lines. At the end, a specific procedure is applied in order to measure the global skew angle of the document image from these identified lines. Experimental results demonstrate the accuracy and the effectiveness of our approach on skew angle detection upon three popular datasets covering many types of documents of diverse linguistic writings (Chinese, Greek and English) and …",Omar Boudraa and Walid Khaled Hidouci and Dominique Michelucci,4,2912806273957985183,Mathematics and Computers in Simulation,,389-403,North-Holland,Using skeleton and Hough transform variant to correct skew in historical documents,https://www.sciencedirect.com/science/article/pii/S0378475419301739,167,2020,/scholar?cites=2912806273957985183,q3KEGmAAAAAJ:Wp0gIr-vW9MC
1021015,"Document image binarization is a central problem in many document analysis systems. Indeed, it represents one of the basic challenges, especially in case of historical documents analysis. In this paper, we propose a novel robust multi stage framework that combines different existing document image thresholding methods for the purpose of getting a better binarization result. CLAHE technique is introduced to significantly enhance contrast in some poor images. The proposed method then uses a hybrid algorithm to partition image into foreground and background. A special procedure is finally applied in order to remove small noise and correct characters morphology. Experimental results prove the accuracy and the efficiency of our approach on document images binarization over three popular datasets compared to some well-known methods in literature.",Omar Boudraa and Walid Khaled Hidouci and Dominique Michelucci,4,17143392434945144658,,,1-6,IEEE,A robust multi stage technique for image binarization of degraded historical documents,https://ieeexplore.ieee.org/abstract/document/8192044/,,2017,/scholar?cites=17143392434945144658,q3KEGmAAAAAJ:7PzlFSSx8tAC
1021016,"In this paper, we investigate a decentralized approach to timestamping transactions in a replicated database, under partial replication in Peer-To-Peer (P2P) environments. In order to solve problems of concurrent updates and node failures, we propose an architecture based on quorums, this architecture allows assigning a unique timestamp to each distributed transaction, to select the servers replicas and to coordinate the distributed execution of the transaction.",Sofiane Mounine Hemam and Khaled Walid Hidouci,4,1033600295594434356,,,185-189,IEEE,A fully decentralized algorithm to timestamping transactions in a peer-to-peer environments,https://ieeexplore.ieee.org/abstract/document/5647903/,,2010,/scholar?cites=1033600295594434356,q3KEGmAAAAAJ:-f6ydRqryjwC
1021017,"A high SLA is a big challenge for the Cloud providers as they have to ensure the sustainability of their customers’ workloads that depend closely on the undelying OS. The kernels are the cores of the OS, and the monolithic kernels are still the most performant despite of their fragility and unreliability. We think that the superposition of the kernels in such way that a healthy kernel replaces the vulnerable services of another kernel is a good track to operate. This replacement is accomplished via the transfer of system calls from the vulnerable kernel to a more reliable and efficient remote discovered kernel. We propose the architecture of a Meta-OS based on heterogeneous monolithic kernels in order to ensure reliability and performance. The features of this Meta-OS are encapsulated in microservices hosted on containers. Two technologies are used to implement our solution: Virtualization (hardware and OS based) and Web Services.",Ramzi Debab and Walid-Khaled Hidouci,3,11159067862438573735,Journal of Engineering Science & Technology Review,1,,,Boosting the Cloud Meta-Operating System with Heterogeneous Kernels. A Novel Approach Based on Containers and Microservices.,https://www.researchgate.net/profile/Ramzi_Debab2/publication/323895062_Boosting_the_Cloud_Meta-Operating_System_with_Heterogeneous_Kernels_A_Novel_Approach_Based_on_Containers_and_Microservices/links/5ba9f11145851574f7e41283/Boosting-the-Cloud-Meta-Operating-System-with-Heterogeneous-Kernels-A-Novel-Approach-Based-on-Containers-and-Microservices.pdf,11,2018,/scholar?cites=11159067862438573735,q3KEGmAAAAAJ:KlAtU1dfN6UC
1021018,"The join queries are operations that require more energy for their execution. In wireless sensor networks, energy is a determinant factor for the network survival. However, high energy consumption caused by such requests needs the implementation of very appropriate techniques for their execution. Research in this field considered especially binary joins. Few studies have addressed n-way joins. In this paper, we propose'Nway Local Join', an energyefficient technique for n-way join operations. We adopt an in-network execution at each step of the join operation. We compare our solution with an execution at the sink. NLJ shows the best performance for low selectivity factor.",Djail Boubekeur and Hidouci Walid Khaled and Loudini Malik,3,4378464559551139039,Database Systems Journal,2,3-9,"Academy of Economic Studies-Bucharest, Romania",A technique for n-way joins in wireless sensor networks,http://www.dbjournal.ro/archive/24/24_1.pdf,7,2016,/scholar?cites=4378464559551139039,q3KEGmAAAAAJ:W7OEmFMy1HYC
1021019,"We propose a decentralized approach to processing transactions in a replicated database, under partial replication in Peer-To-Peer (P2P) environments. In order to solve problems of concurrent updates, we propose an architecture based on quorums, this architecture allows assigning a unique timestamp to each distributed transaction in order to built local precedence order graph is from at each peer, to select the servers replicas and to coordinate the distributed execution of the transaction.",Sofiane Mounine Hemam and Khaled Walid Hidouci,3,3924850119757546173,Journal of Networking Technology,2,63-72,,Replicated database transactions processing in peer-to-peer environment,http://www.dline.info/jnt/fulltext/v2n2/3.pdf,2,2011,/scholar?cites=3924850119757546173,q3KEGmAAAAAJ:hFOr9nPyWt4C
1021020,"The digital humanities are a field of research, teaching and engineering at the crossroads of computer science and the arts, literature, human and social sciences. Historical disciplines focus on digital tools, especially databases. Current interests and efforts focus on the representation of historical knowledge in order to facilitate the diffusion, sharing and exploitation of collective knowledge. In this context, we propose in this article a representation model of historical event. The particularity of our model is to represent simultaneously multiple versions of the same event from different sources. Furthermore, we discuss our model as a field of expertise for new research and investigation problems.",Fairouz Zendaoui and Walid Khaled Hidouci,2,1320168314033539588,Periodicals of Engineering and Natural Sciences,1,141-147,,Multi-version representation of historical event,http://pen.ius.edu.ba/index.php/pen/article/view/329,7,2019,/scholar?cites=1320168314033539588,q3KEGmAAAAAJ:d1gkVwhDpl0C
1021021,"Works done in the context of the relational division for DBMS led to several approaches. Among which, the Hash-Division algorithm proved its superiority compared to the other approaches in the most of the cases. Nowadays, current trends of division are been oriented towards flexible queries and those involving preferences. However, the emphasis was always on proposing new operators which provide more flexibility and tolerance than the classical division operator. The performance aspect has not been adequately addressed. The proposed approaches in the literature suffer from a lack of performance, especially in a large volume of data. In this paper, we attempt to address this problem. Our idea consists in exploiting the advantages offered by the classical Hash-Division algorithm to propose new variants tailored for the flexible context. We paid a special attention to the improvement of some extended …",Noussaiba Benadjmi and Khaled Walid Hidouci,2,6131604844032982607,,,99-111,"Springer, Cham",New variants of hash-division algorithm for tolerant and stratified division,https://link.springer.com/chapter/10.1007/978-3-319-59692-1_9,,2017,/scholar?cites=6131604844032982607,q3KEGmAAAAAJ:HDshCWvjkbEC
1021022,"Since nodes in wireless sensor networks (WSN) are energy-limited, energy-efficiency in collaborative applications is a technological barrier to expand them. One possible solution is to exploit data reported by nodes because they are in most cases correlated in time and space. In this paper, we define a novel binary integer linear program to resolve the problem of energy minimisation under data precision constraints (EMDP). This program helps us determine the most appropriate nodes and give each one of them a specific role in data collection based on data correlation. Given the complexity of EMDP, we propose a heuristic solution (CORAD) to structure the network topology into multi-hop reconfigurable clusters. Supported by numerical simulations, CORAD is shown to be an acceptable solution to the EMDP problem.",Oualid Demigha and Walid-Khaled Hidouci and Toufik Ahmed,2,5765969136119687382,International Journal of Sensor Networks,1,11-28,Inderscience Publishers (IEL),Energy-efficient data collection under precision constraints in wireless sensor networks,https://www.inderscienceonline.com/doi/abs/10.1504/IJSNET.2017.080661,23,2017,/scholar?cites=5765969136119687382,q3KEGmAAAAAJ:_FxGoFyzp5QC
1021023,"Web sites are exposed to high rates of incoming requests. During temporary traffic peaks, web servers may become overloaded and their services deteriorate drastically. In this paper, we propose a method for admission control to prevent and control overloads in web servers by utilizing neural network (NN). The control decision is based on the desired web server performance criteria: average response time, blocking probability and throughput of web server. We have designed and developed a NN model able to predict web server performance metrics based on the parameters of the Apache server, the core of the Linux system and arrival traffic. The model predictor captures the complex relationship between web server performance and its configuration. This avoids an ad-hoc web server configuration, which poses significant challenges to the server performance and quality of service (QoS).",Lahcene Aid and Malik Loudini and Walid-Khaled Hidouci,2,233613390420284837,International Journal of Computer Applications,5,,"International Journal of Computer Applications, 244 5 th Avenue,# 1526, New York, NY 10001, USA India",An Admission Control Mechanism for Web Servers using Neural Network,https://www.academia.edu/download/49216812/An_Admission_Control_Mechanism_for_Web_S20160929-14972-18pwq0g.pdf,15,2011,/scholar?cites=233613390420284837,q3KEGmAAAAAJ:u5HHmVD_uO8C
1021024,"Simplifying and structuring qualitatively complex knowledge, quantifying it in a certain way to make it reusable and easily accessible are all aspects that are not new to historians. Computer science is currently approaching a solution to some of these problems, or at least making it easier to work with historical data. In this paper, we propose a historical knowledge representation model taking into consideration the quality of imperfection of historical data in terms of uncertainty. To do this, our model design is based on a multilayer approach in which we distinguish three informational levels: information, source, and belief whose combination allows modeling and modulating historical knowledge. The basic principle of this model is to allow multiple historical sources to represent several versions of the history of a historical event with associated degrees of belief. In our model, we differentiated three levels of granularity …",Fairouz Zendaoui and Walid Khaled Hidouci,1,7154712588717010151,ISeCure-The ISC International Journal of Information Security,3,59-65,"Tehran, Iranian Society of Cryptology",Considering Uncertainty in Modeling Historical Knowledge,http://scholar.google.com/scholar?cluster=7154712588717010151&hl=en&oi=scholarr,11,2019,/scholar?cites=7154712588717010151,q3KEGmAAAAAJ:iH-uZ7U-co4C
1021025,"We address load balancing and data locality problems in Hadoop. These two problems limit its performance, especially, during a reduce phase where the partitioning function assigns the keys to the reducers based on a hash function. We propose in this paper a new approach to assign the keys based on the reducers’ processing capability in order to ensure a good load balancing. In addition, our proposed approach called RTSBL takes into consideration the data locality during the partition. Our experiments prove that RTSBL achieves to up 87% improvements in the load balancing and 3 improvements of the data locality during the reduce phase in the standard Hadoop.",Khadidja Midoun and Walid-Khaled Hidouci and Malik Loudini and Djahida Belayadi,1,9914719197688577443,,,271-280,"Springer, Cham",RTSBL: Reduce Task Scheduling Based on the Load Balancing and the Data Locality in Hadoop,https://link.springer.com/chapter/10.1007/978-3-319-98352-3_29,,2018,/scholar?cites=9914719197688577443,q3KEGmAAAAAJ:hqOjcs7Dif8C
1021026,"Modern database systems can achieve high throughput main-memory query execution by being aware of the dynamics of highly parallel hardware. In such systems, data is partitioned into smaller pieces to reach a better parallelism. Unfortunately, data skew is one of the main problems faced during parallel processing in a parallel main memory database. In some data-intensive applications, parallel range queries over a dynamic range partitioned system are important. Continuous insertions/deletions can lead to a very high degree of data skew and consequently a poor performance of parallel range queries. In this paper, we propose an approach for maintaining balanced loads over a set of nodes as in a system of communicating vessels, by migrating tuples between neighboring nodes. These frequent (or even continuous) data transfers inevitably involve dynamic changes in the partition statistics. To avoid the performance degradation typically associated with this dynamism, we provide a solution based on an approximate Partition Statistics Table. The basic idea behind this table is that both clients and nodes may have an imperfect knowledge about the effective load distribution. They can nevertheless locate any data with almost the same efficiency as using exact partition statistics. Furthermore, maintaining load distribution statistics do not require exchanging additional messages as opposed to the cost of efficient solutions from the state-of-art (which requires at least O(logn) messages). We show through intensive experiments that our proposal supports efficient range queries, while simultaneously guaranteeing storage balance even in the …",Djahida Belayadi and Khaled-Walid Hidouci and Ladjel Bellatreche,1,8709818980715206117,Computer Science and Information Systems,2,393-419,,OLAPS: Online load-balancing in range-partitioned main memory database with approximate partition statistics,http://www.doiserbia.nb.rs/Article.aspx?ID=1820-02141800007B,15,2018,/scholar?cites=8709818980715206117,q3KEGmAAAAAJ:R3hNpaxXUhUC
1021027,"Several studies were interested in social shared content as rewarding source to enrich user's profile. In this context, we highlight the importance of considering the user's relationship strength to derive relevant social profile. We focus on egocentric network community-based user profiling process (CoBSP) which considers only binary connections between people. In real life, social connections are not merely binary but have associated weights that record people's relation strength. We aim to enhance the effectiveness of CoBSP process by integrating ties strength in the user's profiling process. Our motivation stems from the intuition that people having the strongest relationships with the profiled user may reveal more valuable information about him. The first experiments conducted on scientific publications networks (DBLP/ResearchGate) are promising and show the relevance of our prior premise. However, we …",Asma Chader and Hamid Haddadou and Walid-Khaled Hidouci,1,3249936135293617919,,,482-488,IEEE,All friends are not equal: weight-aware egocentric network-based user profiling,https://ieeexplore.ieee.org/abstract/document/8308326/,,2017,/scholar?cites=3249936135293617919,q3KEGmAAAAAJ:IjCSPb-OGe4C
1021028,"The Operating Systems (OS) provide services to applications via APIs that encapsulate the system calls interface. In the context of critical applications, the SLA is closely dependent on the underlying OS. This SLA is a big challenge for the most Cloud providers as they have to ensure the sustainability of their customers' workloads. The kernel, which is the core of the OS, knew different approaches for its development. However, monolithic kernels are still the most performant despite of their fragility and unreliability. Today, we know a variety of heterogeneous OS developed by different communities."" Two heads are better than one"", applying this principle allows an OS with its benefits to cover the shortcomings of others in a given case. All the known general purpose OS are vulnerable. So, we suppose that the superposition of the OS in such way that a healthy kernel replaces the vulnerable services of another kernel is …",Ramzi Debab and Walid-Khaled Hidouci,1,2112818478331422746,,,1-13,,Towards a more reliable and robust Cloud Meta-Operating System based on heterogeneous kernels: A novel approach based on containers and microservices,https://dl.acm.org/doi/abs/10.1145/3010089.3010092,,2016,/scholar?cites=2112818478331422746,q3KEGmAAAAAJ:2osOgNQ5qMEC
1021029,"This paper addresses a real-time scheduling problem inherent to energy harvesting real-time systems. Traditionally, the energy saving problem is solved mainly by taking into account the tasks scheduling parameters such as worst-case execution time and period. In this work, we construct a feedback control scheduling scheme in which a discrete processor speed is assigned according to the control error and available energy. The real-time control tasks would get high processor speeds when their control errors increase. The experimental evaluation of this solution verifies that the feedback scheduling system based on control error gives a good compromise between available energy and systems performance.",Akli Abbas and Emmanuel Grolleau and Malik Loudini and Walid-Khaled Hidouci,1,6186182042424223713,,,1-9,IEEE,A real-time feedback scheduler based on control error for environmental energy harvesting systems,https://ieeexplore.ieee.org/abstract/document/7483790/,,2015,/scholar?cites=6186182042424223713,q3KEGmAAAAAJ:LkGwnXOMwfcC
1021030,"The embedded systems are characterized by their autonomic functioning whose energy supply is ensured by batteries. Therefore, the reduction of their power consumption and more specifically, the quality of their control becomes the crucial metric optimization in the design of such systems. In this paper, we investigate the integration of precedence, resources sharing and quality of control constraints in the real time scheduling of firm periodic and aperiodic tasks. To study this problem, we start by adapting the analytical conditions of scheduling having been proposed in literature. We also treat the problem of dynamic voltage scaling of the processor in the same context. The community of the researchers have proposed many dynamic voltage-scaling algorithms. However, these algorithms do not consider the precedence, shared resources and quality of control constraints on the scheduling of firm periodic and aperiodic tasks. In this case, we propose two algorithms with the constraints cited above. These algorithms are based on the analytical model adopted in this paper. Experimental results show that the proposed algorithms reduce the energy consumption under earliest deadline first scheduling policy and the stack resource protocol.",Akli ABBAS and Malik LOUDINI and Walid-Khaled HIDOUCI,1,12717783022001958701,Journal of Control Engineering and Applied Informatics,4,86-96,,Energy and quality of control constraints in real-time scheduling of synchronous hybrid tasks,http://ceai.srait.ro/index.php?journal=ceai&page=article&op=view&path%5B%5D=1619,15,2013,/scholar?cites=12717783022001958701,q3KEGmAAAAAJ:_kc_bZDykSQC
1021031,"Scalable and Distributed Data Structures (SDDS) are a class of data structures completely dedicated to distributed environments. They allow the management of large amounts of data while maintaining steady and optimum performances. Several families of SDDS have been proposed: LH*, RP*, DRT*, CTH*. None of these SDDS deals with the mobile environment. In this paper we present a novel architecture that uses a scalable and distributed data structure to manage insert/find/range query operations for mobile clients. We describe the design and the implementation of a mobile CTH* prototype. Our experimental results prove the validity of the design choices and show interesting access performances. The capabilities of the mobile CTH* platform offer new perspectives for high performance and ubiquitous data intensive applications.",Amel Bennaceur and Djamel Eddine Zegour and Walid Hidouci,1,10109269693183747715,,,,,A Novel Architecture for Mobile Distributed Trie Hashing System,https://hal.inria.fr/inria-00424894/,,2008,/scholar?cites=10109269693183747715,q3KEGmAAAAAJ:5nxA0vEk-isC
1021032,"The work described in this paper is related to three areas in the programming world : logic, functional and object programming. The main objective is essentially pedagogical since it is question here to make a synthesis on non procedural languages. To achieve this, we have considered many construction types, each one represents the one of evoked programming. Many fully-documented environments have been developed for writing constructions of any type, transforming them in order to evaluate them by showing the work really accomplished in the least detail.",DE Zegour and WK Hidouci,1,11042632251940866324,Journal of Computer Science & Technology,,,,ECOLE: a pedagogical environment for non procedural languages,http://sedici.unlp.edu.ar/handle/10915/9549,7,2007,/scholar?cites=11042632251940866324,q3KEGmAAAAAJ:3fE2CSJIrl8C
1021033,"We present in this paper the new concept of “actor databases”(DB-Act) being studied at the INI institute (Act21 project) where we are developing a parallel main memory database system based on an actor like data model. To achieve data distribution we use a Scalable Distributed Data Structures (SDDS) called “distributed Compact Trie Hashing”(CTH*) currently in development at the same project. Transaction management and recovery techniques are adapted for the combination of actors and SDDS in Act21. An adaptation of the nested transaction model to the actor paradigm is presented, as well as a recovery techniques using a fuzzy checkpointing tailored to the SDDS needs.",Walid K Hidouci and Djamel E Zegour,1,18294721155283603965,International Journal of Computing and Information Sciences,,,,Act21: a parallel main memory database system,http://zegour.esi.dz/Ftp/Papier_act21.pdf,,2006,/scholar?cites=18294721155283603965,q3KEGmAAAAAJ:hC7cP41nSMkC
1021034,"Docker has revolutionized the cloud by popularizing containerization, changing the habits of developers and their tools, introducing new paradigms such as microservices and serverless computing, facilitating CI/CD pipelines and packaging techniques, inspiring Infrastructure as Code (IaC) and pushing the Software Defined Everything (SDx. Docker is omnipresent, on our laptops, servers, storage arrays and even on IoT devices. Docker had also the merit of defining standards such as the OCI initiative. Despite all this, can we trust this technology and deploy it widely in our private or public clouds? Given the few vulnerabilities of Docker but badly impactful, many Cloud players (Google, Amazon, RedHat, IBM, Intel, VMware among others) have worked on containerized house technologies made public. Four types of releases resulted: containerization based on OS virtualization, containerization based on micro VMs …",Ramzi Debab and Walid Khaled Hidouci,0,,,,135-161,"Springer, Cham",Containers Runtimes War: A Comparative Study,https://link.springer.com/chapter/10.1007/978-3-030-63089-8_9,,2020,,q3KEGmAAAAAJ:M3NEmzRMIkIC
1021035,"Segmentation is one of the critical steps in historical documents images analysis systems that determines the quality of the search, understanding, recognition and interpretation processes. It allows isolating the objects to be considered and separating the regions of interest (paragraphs, lines, words and characters) from other entities (figures, graphs, tables, etc.). This stage follows the thresholding, which aims to improve the quality of the document and to extract its background from its foreground, also for detecting and correcting the skew that leads to redress the document. Here, a hybrid method is proposed in order to locate words and characters in both handwritten and printed documents. Numerical results prove the robustness and the high precision of our approach applied on old degraded document images over four common datasets, in which the pair (Recall, Precision) reaches approximately 97.7% and 97.9%.",Omar Boudraa and Walid Khaled Hidouci and Dominique Michelucci,0,,International Journal of Image and Graphics,,,World Scientific Publishing Company,An Efficient Cooperative Smearing Technique for Degraded Historical Documents Images Segmentation,https://www.worldscientific.com/doi/abs/10.1142/S0219467821500121,,2020,,q3KEGmAAAAAJ:maZDTaKrznsC
1021036,"In wireless sensors networks, data are sensed and recorded as databases, and then acceded by relational queries. Joins are queries that are largely used. Joins collect data from several nodes’ table. These are operations that typically consume a lot of energy because they generate a large number of messages in the network. Researchers worked to decrease this consumed energy. Many strategies were proposed in this way, but most of them addressed only binary joins. N-way joins received few interests. N-way joins perform join operations between more than two tables. They cause greater energy consumption. Additionally, the number of execution order is very important; it grows exponentially with the number of considered tables.",Boubekeur Djail and Walid Khaled Hidouci and Malik Loudini,0,,Pollack Periodica,2,13-24,Akadémiai Kiadó,A comparative evaluation of techniques for N-way joins in wireless sensors networks,https://akjournals.com/view/journals/606/15/2/article-p13.xml,15,2020,,q3KEGmAAAAAJ:k_IJM867U9cC
1021037,"With the emergence of social networking platforms and great amount of generated content, analyzing people interactions and behaviour raises new opportunities for several applications such as user interest profiling. In this context, this paper highlights the importance of considering relationship strength to infer more refined and relevant interests from user’s direct neighbourhood. We propose WeiCoBSP, a Weight-aware Community-Based Social Profiling approach that leverages strength of ego-friend and friend-friend relationships. The former, describing connections with the profiled user, allows to identify most relevant people from whom to infer worthwhile interests. The latter qualifies connections among user’s neighbourhood and enables depicting the most realistic community structure of the network. We present an empirical evaluation performed on real world co-authorship networks, validating our approach …",Asma Chader and Hamid Haddadou and Leila Hamdad and Walid-Khaled Hidouci,0,,Journal of Web Engineering,,457–502-457–502,,The Strength of Considering Tie Strength in Social Interest Profiling,https://journals.riverpublishers.com/index.php/JWE/article/view/1011,,2020,,q3KEGmAAAAAJ:isC4tDSrTZIC
1021038,"The Web has become the most important information source for most of us. Unfortunately, there is no guarantee for the correctness of information on the Web. Moreover, different websites often provide conflicting information on a subject. Several truth discovery methods have been proposed for various scenarios, and they have been successfully applied in diverse application domains. In this paper, we have attempted to answer the question whether the truth is relevant. We conducted an experimental study in which we analyzed and compared the results of two different truth discovery methods: Relevance-based sources ranking and Majority vote. We have found that the truth is not always held by the most relevant sources on the web. Sometimes the truth is given by the majority vote of the crowd. In addition, we have proposed a method of presenting the results of truth discovery with gradual degrees of belief. A method that allows to configure and target the desired level of trust.",Fairouz Zendaoui and Walid Khaled Hidouci,0,,Journal of Information Technology Management,2,1-12,"Faculty of Management, University of Tehran",Exploring Relevance as Truth Criterion on the Web and Classifying Claims in Belief Levels,https://jitm.ut.ac.ir/mobile/article_75786.html,12,2020,,q3KEGmAAAAAJ:TFP_iSt0sucC
1021039,,Dominique Michelucci and Omar Boudraa and Walid-Khaled Hidouci,0,,Mathematics and Computers in Simulation,,,,Using skeleton and Hough transform variant to correct skew in historical documents.,https://hal.archives-ouvertes.fr/hal-02441469/,,2020,,q3KEGmAAAAAJ:bEWYMUwI8FkC
1021040,"Document image binarization is the initial step and a crucial in many document analysis and recognition scheme. In fact, it is still a relevant research subject and a fundamental challenge due to its importance and influence. This paper provides an original multi-phases system that hybridizes various efficient image thresholding methods in order to get the best binarization output. First, to improve contrast in particularly defective images, the application of CLAHE algorithm is suggested and justified. We then use a cooperative technique to segment image into two separated classes. At the end, a special transformation is applied for the purpose of removing scattered noise and of correcting characters forms. Experimentations demonstrate the precision and the robustness of our framework applied on historical degraded documents images within three benchmarks compared to other noted methods.",Omar Boudraa and Walid Khaled Hidouci and Dominique Michelucci,0,,arXiv preprint arXiv:1901.09425,,,,Degraded Historical Documents Images Binarization Using a Combination of Enhanced Techniques,https://arxiv.org/abs/1901.09425,,2019,,q3KEGmAAAAAJ:YOwf2qJgpHMC
1021041,"Purpose–The join operations between data streams need more time and request more energy than traditional joins. In wireless sensor networks, energy is a critical factor. The survival of the network depends on this energy, thus it is necessary to consider, for this type of queries in such networks, the reduction of the sensors’ energy consumption. While works that have been done to treat n-way join operations between data streams are rare so far, we propose a technique, named NSLSJ (N-way Stream Local Semi-Join) to perform this type of join operations. The principal aim is to considerably reduce the consumed energy.Methodology/approach/design–The technique'N-way Stream Local Semi-Join (NSLSJ) proposed in this paper is based on an in-network execution, and on filtering tuples strategy for an important gain in energy. Findings–Compared to NSLJ and Sens-Join techniques, NSLSJ shows better performances in the realized tests as it consumes less energy.",Boubekeur Djail and Walid Khaled Hidouci and Malik Loudini,0,,"Revista de Direito, Estado e Telecomunicações",1,,,A filtering technique for n-way stream joins in wireless sensors networks.,http://periodicos.unb.br/index.php/RDET/article/download/24853/21962,11,2019,,q3KEGmAAAAAJ:u-x6o8ySG0sC
1021042,"Due to the availability of larger RAM capacity, there is a new trend bringing parallel main memory database systems with higher performance, compared to traditional DBMSs. In parallel database systems the most critical aspect is data partitioning, which significantly impacts query processing time. Specifically, unbalanced data partitioning introduces data skew, which ends up decreasing query performance if not managed. In this work, we focus on optimizing range queries, widely used in P2P, decision support systems and spatio-temporal databases. We improve the communication complexity of the state-of-the-art previous algorithm based on skip graphs, which required O(log p) messages between 2 nodes to rebalance load, resulting in a high complexity O(p log p) to rebalance load on the p nodes. With such high cost in mind, we propose to create a global view of data distribution among all processing …",Djahida Belayadi and Khaled-Walid Hidouci and Ladjel Bellatreche and Carlos Ordonez,0,,,,239-249,"Springer, Cham",Cost Effective Load-Balancing Approach for Range-Partitioned Main-Memory Resident Data,https://link.springer.com/chapter/10.1007/978-3-319-98812-2_20,,2018,,q3KEGmAAAAAJ:4JMBOYKVnBMC
1021043,"In this paper, two issues of bipolar division are discussed. First, we outline some new operators dealing with the bipolar division, to enrich the interpretations of bipolar queries. In this context, we propose some extended operators of bipolar division based on the connector “or else”. Besides, we introduce a new bipolar division operator dealing with the “Satisfied-Dissatisfied approach”. Secondly, we highlight the matter of the performance improvement of the considered operators. Thus, we present an efficient method which allows handling several bipolar divisions with a unified processing. Our idea is to design new variants of the classical Hash-Division algorithm, for dealing with the bipolar division. The issue of answers ranking is also dealt with. Computational experiments are carried out and demonstrate that the new variants outperform the conventional ones with respect to performance.",Noussaiba Benadjimi and Walid Hidouci and Allel Hadjali,0,,,,749-761,"Springer, Cham",On Hash Bipolar Division: An Enhanced Processing of Novel and Conventional Forms of Bipolar Division,https://link.springer.com/chapter/10.1007/978-3-319-91473-2_63,,2018,,q3KEGmAAAAAJ:qjMakFHDy7sC
1021044,"Statistical extractive summarization is one of the most exploited approach in automatic text summarization due to its generation speed, implementation easiness and multilingual property. We want to improve statistical sentence scoring by exploring a simple, yet powerful, property of graphs called bushy paths represented by the number of node’s neighbors. A graph of similarities is constructed in order to select candidate sentences. Statistical features such as sentence position, sentence length, term frequency and sentences similarities are used to get a primary score for each candidate sentence. The graph is used again to enhance the primary score by using bushy paths property. Also, we tried to exploit the graph in order to enhance summary’s coherence. We experimented our method using MultiLing’15 workshop’s corpora for multilingual single document summarization. Using graph properties can …",Abdelkrime Aries and Djamel Eddine Zegour and Walid Khaled Hidouci,0,,,,78-89,"Springer, Cham",Exploring Graph Bushy Paths to Improve Statistical Multilingual Automatic Text Summarization,https://link.springer.com/chapter/10.1007/978-3-319-89743-1_8,,2018,,q3KEGmAAAAAJ:QIV2ME_5wuYC
1021045,"Nowadays, current trends of universal quantification-based queries are been oriented towards flexible ones (tolerant queries and-or those involving preferences). In this paper, we are interested in universal quantification-like queries dealing with both positive or negative preferences (requirements or prohibitions), considered separately or simultaneously. We have emphasised the improvement of the proposed operator, by designing new variants of the classical Hash-Division algorithm, presented in [1], for dealing with our context. The parallel implementation is also presented, and the issue of answers ranking is dealt with. Computational experiments are carried out in both sequential and parallel versions. They shows the relevance of our approach and demonstrate that the new operator outperforms the conventional one with respect to performance (the gain exceeds a ratio of 40).",Noussaiba Benadjimi and Walid Hidouci,0,,,,635-647,"Springer, Cham",Unified-Processing of Flexible Division Dealing with Positive and Negative Preferences,https://link.springer.com/chapter/10.1007/978-3-319-89743-1_54,,2018,,q3KEGmAAAAAJ:ULOm3_A8WrAC
1021046,"Data skew can significantly deteriorate query performance in distributed systems. More concretely, when the data is range partitioned, usually it may be unequally distributed across the partitions. When tuples are inserted and deleted continuously, some of these data shall be moved from the hot nodes to the least loaded ones in order to satisfy the storage balance requirement. These movements have an important impact in terms of maintaining the load statistics related to each node, such as the partition boundaries and the load size. Efficient solutions from the state-of-art that address the data skew problem require global load statistics with a cost of O(log n) messages. In this paper, we propose an efficient online load-balancing algorithm for the range-partitioned data. Our solution is based on the fuzzy image (FZIM) concept. The basic idea about the FZIM is that both clients and nodes have an approximate …",Djahida Belayadi and Khaled-Walid Hidouci and Khadidja Midoun,0,,,,1-6,IEEE,OL-BaS: Efficient data load-balancing for skewed data with approximate load statistics,https://ieeexplore.ieee.org/abstract/document/8379005/,,2018,,q3KEGmAAAAAJ:j3f4tGmQtD8C
1021047,"One of the important issues in range partitioning schemes is data skew. Tuples distribution across nodes may be skewed (some nodes have many tuples, while others may have fewer tuples). Processing skewed data not only slows down the response time, but also generates hot nodes. In such a situation, data may need to be moved from the most-loaded partitions to the least-loaded ones in order to achieve storage balancing requirements. Early works from the State-of-The-Art focused on achieving load balancing. However, today’s works focus on reducing the load balancing cost. This latter involves reducing the cost of maintaining partition statistics. In this context, we propose to improve one of the best load balancing work, that is the one of Ganesan et al., to reduce the cost of maintaining the statistics of load balancing. We introduce the concept of fuzzy system image. Both nodes and clients have …",Djahida Belayadi and Khaled-Walid Hidouci and Khadidja Midoun,0,,,,281-290,"Springer, Cham",CARP: Cost Effective Load-Balancing Approach for Range-Partitioned Data,https://link.springer.com/chapter/10.1007/978-3-319-98352-3_30,,2018,,q3KEGmAAAAAJ:TQgYirikUcIC
1021048,"Big Data is the current challenge for the computing field not only because of the volume of data involved but also for the amazing promises to analyze and interpret massive data to generate useful and strategic knowledge in various fields such as security, sales and education. However, the massive volume of data in addition to other characteristics of Big Data such as the variety, velocity, and variability require a whole new set of techniques and technologies, which are not yet available, to effectively extract the desired knowledge. The KDD (Knowledge Discovery in Databases) process has achieved excellent results in the classical database context and that is why we examine the possibility of adapting it to the Big Data context to take advantage of its strong and effective data processing techniques. We introduce therefore a new process KUBD (Knowledge Unveiling in Big Data) inspired from the KDD …",Naima Lounes and Houria Oudghiri and Rachid Chalal and Walid-Khaled Hidouci,0,,,,931-937,"Springer, Cham",From KDD to KUBD: Big Data Characteristics Within the KDD Process Steps,https://link.springer.com/chapter/10.1007/978-3-319-77712-2_88,,2018,,q3KEGmAAAAAJ:M3ejUd6NZC8C
1021049,"The representation of sentences is a very important task. It can be used as a way to exchange data inter-applications. One main characteristic, that a notation must have, is a minimal size and a representative form. This can reduce the transfer time, and hopefully the processing time as well.Usually, sentence representation is associated to the processed language. The grammar of this language affects how we represent the sentence. To avoid language-dependent notations, we have to come up with a new representation which don't use words, but their meanings. This can be done using a lexicon like wordnet, instead of words we use their synsets. As for syntactic relations, they have to be universal as much as possible.",Abdelkrime Aries and Djamel Eddine Zegour and Walid Khaled Hidouci,0,,arXiv preprint arXiv:1801.00984,,,,Sentence Object Notation: Multilingual sentence notation based on Wordnet,https://arxiv.org/abs/1801.00984,,2018,,q3KEGmAAAAAJ:dhFuZR0502QC
1021050,"Range query has a crucial role in large-scale data analysis. Unfortunately, the performance may be severely degraded by data skew. Such problem is often faced in large-scale parallel databases, peer-to-peer (P2P) systems as well as in Cloud computing. State-of-the-art methods designed to handle this problem offer significant improvements over naive implementations. However, performance could be further improved by reducing the cost of global skew knowledge and broadcasting. Ganesan, Bawa and Garcia-Molina proposed a load-balancing algorithm that guarantees a good ratio between the maximum and minimum loads among nodes. However, their algorithm requires global max-min load information to use local load balancing operations. Global load information can be found with O (log n) messages. In order to reduce this cost, we propose OPTIMA, a novel online load balancing approach for range partitioned data. Whenever a partition becomes overloaded, data transfers are performed, in background, from the most loaded nodes to the least loaded ones as in Ganesan et al., work. As a result, the partition boundaries and data sizes change. The key point of our proposal is the imperfect knowledge of the global load information (partition statistics). We introduce the concept of “Imperfect Partitioning Vector”(IPV), where, both nodes and clients have an approximate information about the load distribution. They can nevertheless locate any data with almost the same efficiency as using exact partition statistics. Furthermore, maintaining load distribution statistics do not require exchanging additional messages or maintaining a data structure …",Djahida Belayadi and Khaled-Walid Hidouci and Khadidja Midoun,0,,,,,,OPTIMA: On-Line Balancing of Range-Partitioned Data with Imperfect Partitioning Vector,https://www.researchgate.net/profile/Khadidja_Midoun/publication/329889996_OPTIMA_On-Line_Balancing_of_Range-Partitioned_Data_with_Imperfect_Partitioning_Vector/links/5c4b01d5458515a4c73ef8d0/OPTIMA-On-Line-Balancing-of-Range-Partitioned-Data-with-Imperfect-Partitioning-Vector.pdf,,2018,,q3KEGmAAAAAJ:RHpTSmoSYBkC
1021051,"Grâce à la disponibilité de plus grandes capacités de mémoire principale, nous assistons à une présence des systèmes parallèles de bases de données gérées en mémoire offrant une performance accrue contrairement aux bases de données traditionnelles. Le partitionnement de données est une pré-condition de ces bases de données, car il permet d’améliorer de manière significative les performances de certaines requêtes (par ex. le cas de requêtes d’intervalle). Le partitionnement engendre un problème d’équilibrage de distribution des données. En conséquence, il peut contribuer à la dégradation de la performance de requêtes. Le groupe de Ganesan et al. a proposé un algorithme offrant un faible rapport entre les charges maximale et minimale des nœuds tout en exploitant des informations de la charge globale. Ces informations sont stockées dans une structure de données, appelée skip graphs nécessitant l’échange de (log p) messages entre les p nœuds de la machine parallèle lors du processus d’équilibrage. L’objectif de notre travail est de réduire le nombre de ces messages. Pour ce faire, nous proposons un vecteur de statistiques approximatives des partitions (VSP), où les nœuds et les clients ont une vue approximative sur la distribution de données. Le coût de maintenance de ce vecteur est quasiment nul. Notre approche est validée sur un cluster de 8 nœuds et 2 clients.",Djahida Belayadi and Khaled-Walid Hidouci and Ladjel Bellatreche and Carlos Ordonez,0,,Business Intelligence & Big Data,,,,Équilibrage de Distribution de Données d’une Base en Mémoire Parallèle Partitionnées par Intervalle,https://www.researchgate.net/profile/Badir_Hassan/publication/331160314_EDA18_Conference_Proceedings_Business_Intelligence_Big_data_14th_edition/links/5c695020a6fdcc404eb63c9b/EDA18-Conference-Proceedings-Business-Intelligence-Big-data-14th-edition.pdf#page=179,,2018,,q3KEGmAAAAAJ:mB3voiENLucC
1021052,"Join queries are widely used in wireless sensor networks. However, they engender high energy consumption, particularly for joins between a number of tables more than two: the n-way joins. The challenge is then to perform such queries while reducing consumed energy. Many techniques were proposed in this way, but most of them addressed only binary joins. N-way joins were rarely treated. With nway joins, the consumed energy is excessively high, and the number of execution orders grows exponentially with the number of considered tables. We present in this paper, a filtering technique to perform n-way join queries in wireless sensor networks. We try to significantly reduce the used energy, by adopting semi-join approach to filter out non-joinable tuples. We evaluate the performance of our technique by a comparison with the technique: Sens-join proposed par Stern and al. Obtained results show that our solution significantly outperforms Sens-join.",Boubekeur Djail and Walid-Khaled Hidouci and Malik Loudini,0,,UNIVERSITY POLITEHNICA OF BUCHAREST SCIENTIFIC BULLETIN SERIES C-ELECTRICAL ENGINEERING AND COMPUTER SCIENCE,4,23-34,POLYTECHNIC UNIV BUCHAREST,NMSJ: A FILTERING TECHNIQUE FOR N-WAY JOINS IN WIRELESS SENSOR NETWORKS,https://pdfs.semanticscholar.org/1eaf/7d2fa98b24ad832fc9ddec66410bd0b99726.pdf,80,2018,,q3KEGmAAAAAJ:4TOpqqG69KYC
1021053,"This paper considers the design problem of efficient feedback control schemes to enhance the quality of service (QoS) of a web server (WS) whose input/output dynamic behavior is modeled by discrete mathematical representations. Discrete models allowing the digital simulation of the WS responses to different scenarios of client requests are adopted. The capabilities to guarantee performing service delays, under dynamic workload variations, are the main investigations of this work. To try to provide prospective solutions, advanced feedback control strategies are proposed. First, a fuzzy logic controller (FLC) is implemented as a regulating solution in a closed-loop control architecture. Then, the tabu search (TS) algorithm (TSA) is used to optimize the FLC parameters with innovative tuning procedures. The TS optimized FLC (TSOFLC) is also implemented and applied to attempt to improve the WS QoS. To demonstrate the effectiveness of the adopted closed-loop intelligent control strategies, digital simulation experiments are carried out and examined.",Malik Loudini and Sawsen Rezig and Walid-Khaled Hidouci and Yahia Salhi,0,,Journal of Control Engineering and Applied Informatics,2,54-66,,Design and Application of Intelligent Control Schemes for the Performance Enhancement of a Web Server,http://www.ceai.srait.ro/index.php?journal=ceai&page=article&op=view&path%5B%5D=1923&path%5B%5D=0,15,2013,,q3KEGmAAAAAJ:Tyk-4Ss8FVUC
1021054,"In this paper, we present the design and the architecture of a parallel main memory database management system. We focus on concurrency control scheme and recovery. Our prototype is based on the concept of “database actors”, an object-oriented data model well suited for parallelmanipulations. The storage sub system is built upon distributed Ram-files using SDDS (Scalable Distributed Data Structures) techniques. A nested transaction model is proposed and used to handle concurrency access and recovery. We have also proposed novel approach, based on wait-die, to implement a distributed deadlock prevention technique for our model of nested transactions.",Walid-Khaled Hidouci and Djamel Eddine Zegour,0,,Journal of computing and information technology,2,71-82,SRCE-Sveučilišni računski centar,Using Actors to Build a Parallel DBMS,https://hrcak.srce.hr/index.php?id_clanak_jezik=105743&show=clanak,19,2011,,q3KEGmAAAAAJ:kNdYIx-mwKoC
1021055,"Performance modeling is an important topic in overload control for web servers. Several attempts have been made to create performance models for web servers. The paper describes modeling a Web server to be controlled by Feedback control scheme. Feedback command theory was initially used to control of industrial processes. Its use for the control of performance software is recent. It provides a number of mathematical tools which can be used to analyze the stability of the commanded system and find the best adjustment that responds to the performance criteria. Our approach proceeds in two steps: system identification and controller design. In system identification, we construct mathematical models of the target system in forms of discrete transfer function focused on single-input single-output (SISO) systems. The role of controller is to modify the transfer function of the target system with regard to the control …",Atika Badaoui and Malik Loudini and Walid-Khaled Hidouci,0,,,,191-196,IEEE,SISO modelling of a web server to be controlled by a Feedback control scheme,https://ieeexplore.ieee.org/abstract/document/5898884/,,2011,,q3KEGmAAAAAJ:YsMSGLbcyi4C
1021056,"Grid computing involves sharing heterogeneous calculation and storage resources. Recently, the use of grid infrastructure has been focused on applications of distribution of large volumes of data. The modern methods of data management are no longer based on centralized systems. To provide better time of research, we must apply structures dedicated to distributed environments. PBST*(Distributed Partitioned Binary Search Tree) is variant of SDDS (Scalable Distributed Data Structure). It is a tree data structure dedicated to distributed environments. This method is particularly characterized by the dynamic partitioning of data in the offing to distribute it on multiple storage resources and to treat it in parallel. In this paper, we propose a protocol for data distribution according PBST* for data placement on grids.",Amina Chikhaoui and Djamel-Eddine Zegour and Walid-Khaled Hidouci,0,,International Conference on Information Systems and Technologies (ICIST),,,,Towards dynamic data placement in grid,http://zegour.esi.dz/Ftp/Pbst_icist_11.pdf,,2011,,q3KEGmAAAAAJ:9ZlFYXVOiuMC
1021057,"Le besoin en haute performance ne cesse de croître, particulièrement dans le domaine de gestion de données, cela est dû à la multiplication des volumes de données et la complexité des traitements. Le présent travail vise à explorer les perspectives de haute performance dans le contexte des bases de données répliquées. En effet, on adresse plus exactement le problème de l’exécution parallèle des requêtes de lecture sur un cluster de stations, avec la réplication comme stratégie de partitionnement de données. Traditionnellement, la réplication était, par excellence, une solution de haute disponibilité. Toutefois, ses caractéristiques la rendent un champ fertile pour les différentes techniques de parallélisation. La plupart des solutions existantes tendent pour le parallélisme interrequêtes via le routage des requêtes, qui améliore le débit de système sans agir sur les requêtes individuelles. A travers ce travail, on se …",Walid-Khaled HIDOUCI,0,,,,,,Etude comparative entre les techniques de parallélisation dans un environnement de bases de données répliquées,http://scholar.google.com/scholar?cluster=14420990556636466737&hl=en&oi=scholarr,,2011,,q3KEGmAAAAAJ:4DMP91E08xMC
1021058,"This thesis presents a new approach to build parallel Main Memory DataBase systems (MMDB). It is based on : (1) the use of programing actors to handle all database components (types, instances, constraints, ...) and (2) the adaptation of the new “Scalable Distributed Data Structures” (SDDS) for storing and fragmenting data. In this new approach, a database is seen as composed by a number of actors (or active autonomous objects) managing each, a partial knowledge of the database. The collaboration of these actors makes use1""s queries and application programs executed by the system in a distributed manner. The use of SDDS in the storage subsystem implies that the database is memory resident and the fragmentation scheme is dynamically changing to provide data load balancing. This is done Without global reorganisation ofthe database. To validate our propositions, we have contributed (with the Act21 …",Walid Khaled HIDOUCI,0,,,,,,Vers une approche des transaction avancées dans SGBD parallèles intégrant les modèles acteur et SDDS,http://scholar.google.com/scholar?cluster=4862231149157954821&hl=en&oi=scholarr,,2007,,q3KEGmAAAAAJ:WF5omc3nYNoC
1021059,"Les SGBDTR1 gagnent de plus en plus d'importance ces dernières années. Plusieurs SGBDTR ont vu le jour, mais la plupart sont des solutions propriétaires comme STRIP (STranford Real-time Information Processor)[2], EagleSpeed [12], Polyhedra [14], et TimesTen [17]. Dans cet article, on présente notre extension temps réel de PostgreSql, un SGBD traditionnel open source, par l'implémentation de EDF2, une méthode d'ordonnancement en ligne utilisée sur la plupart des SGBDTR. Les performances de cette extension temps réel seront évaluées par notre simulateur réalisé à cet effet.",Tirse Abdelghani and Hidouci Walid Khaled and Loudini Malik,0,,,,,,Du temps réel sous PostgreSql,http://www.univ-msila.dz/ar/wp-content/uploads/2009/12/STIC09/articles/paper_76.pdf,,,,q3KEGmAAAAAJ:JV2RwH3_ST0C
1021060,"Simplifying and structuring qualitatively complex knowledge, quantifying it in a certain way to make it reusable and easily accessible are all aspects that are not new to historians. Computer science is currently approaching a solution to some of these problems, or at least making it easier to work with historical data. In this paper, we propose a historical knowledge representation model taking into consideration the quality of imperfection of historical data in terms of uncertainty. To do this, our model design is based on a multilayer approach in which we distinguish three informational levels: information, source, and belief whose combination allows modeling and modulating historical knowledge. The basic principle of this model is to allow multiple historical sources to represent several versions of the history of a historical event with associated degrees of belief. In our model, we differentiated three levels of granularity (attribute, object, relation) to express belief and defined 11 degrees of uncertainty in belief. The proposed model can be the object of various exploitations that fall within the historian’s decision-making support for the plausibility of the history of historical events. c 2019 ISC. All rights reserved.",Fairouz Zendaoui and Walid Khaled Hidouci,0,,,,,,ISeCure,http://scholar.google.com/scholar?cluster=14649978737395904306&hl=en&oi=scholarr,,,,q3KEGmAAAAAJ:r0BpntZqJG4C
1021061,"Scalable and Distributed Data Structures (SDDS) are a class of data structures completely dedicated to distributed environments. They allow the management of large amounts of data while keeping steady and optimum performances. Several families of SDDS have been proposed: LH*, RP*, DRT*, CTH*. None of these SDDS treated the mobile environment. In this paper, we present a novel architecture that use scalable and distributed data structure to manage insert/find/rang query operations for mobile clients. We describe the design and the implementation of a mobile CTH* prototype. Our experimental results prove the validity of the design choices and show attractive access performance. The capabilities of the mobile CTH* platform offer new perspectives for high performance and ubiquitous data intensive applications.",A Bennaceur and DE Zegour and WK Hidouci,0,,,,,,Mobile Client for Scalable Distributed Trie Hashing,http://zegour.esi.dz/Ftp/Mobile%20client.pdf,,,,q3KEGmAAAAAJ:ZeXyd9-uunAC
1021062,"In wireless sensor networks, the critical factor is the sensors energy. The exhaustion of this energy causes network paralysis. In wireless sensor networks, the join operation needs a lot of energy consumption. This energy is so very high for nway join queries, and more very high for nway stream queries. Little work has been done to address this problem. We present in this paper, an energy-efficiency technique for n-way joins execution between data streams in wireless sensor networks. The experiment conducted has shown good performance of the proposed technique compared to SENS-join technique.",Djail Boubekeur and Hidouci Walid Khaled and Loudini Malik,0,,,,,,An energy-efficiency technique for n-way stream joins in wireless sensor networks,https://www.univ-chlef.dz/RevueNatec/issue-18/Article_A/Article_452.pdf,,,,q3KEGmAAAAAJ:L8Ckcad2t8MC
1021063,"Design by Component composition using connectors as a glue to produce software system represents the fundamental practice in software Architecture. Software Architecture approaches use a component model which explicitly exposes through its interfaces the needed and the provided resources. Component in Software Architecture are deployable unit of composition. They may be instantiated many times and deployed in different containers. Web Services and services in general, are usually already deployed software. They may correspond to third party services which cannot be touched in any way. The Integrate",Djamal BENNOUAR and Walid Khaled Hidouci and Oued Smar and Kahdidja Bentlemsan,0,,,,,,Dealing With Web Services Composition at the Architectural Level,http://dspace.univ-bouira.dz:8080/jspui/bitstream/123456789/8422/1/Dealing%20With%20Web%20Services%20Composition%20at%20the%20Architectural%20Level.pdf,,,,q3KEGmAAAAAJ:mVmsd5A6BfQC
1021064,"La grille de calcul (Grid Computing) est une technologie en pleine expansion dont le but est d'offrir aux organisations virtuelles, ainsi qu’à la communauté scientifique des ressources informatiques virtuellement illimitées. L’apparition des Services Web a fourni un cadre qui a initié l’alignement des technologies du grille et celles des Services Web qui à été à l’origine des grilles de services.La découverte dynamique et effective des grilles de services est l’un des grands défis de la technologie grille et des services Web. C’est le mécanisme qui consiste à trouver (localiser), dans de vastes registres, le service qui convient aux besoins du demandeur ainsi que toutes les informations (c'est-à-dire la description du service et/ou des renseignements sur son fournisseur) permettant d’interagir avec le service. Les projets actuels, qui s’ intéressent à la découverte de grilles de services, utilisent un seul registre ou un …",Djamel Eddine ZEGOUR and Habiba DRIAS and Youcef AKLOUF and Walid Khaled HIDOUCI and Rachid CHALAL,0,,,,,,INTEGRATION DU WEB SEMANTIQUE DANS LES GRILLES DE SERVICES,http://scholar.google.com/scholar?cluster=11286617806148099736&hl=en&oi=scholarr,,,,q3KEGmAAAAAJ:Zph67rFs4hoC
1021065,"The work described in this paper is related to three areas in the programming world: logic, functional and object oriented programming. The main objective is essentially pedagogical since it is question here to make a synthesis on non procedural languages. To achieve this, we have developed a set of programming environments (Ecole), each one is devoted to a particular style of non procedural programming. This includes logical programming (Horn clauses), functional programming with variables (a λcalculus based language), functional programming without variables (combinators usage), structured object programming (classes), knowledge object programming (frames) and active object programming (actors). The main purpose of Ecole is to let the user be familiar with the concepts of a particular non procedural language and discover the evaluation mechanism in detail.",DRDE Zegour and WK Hidouci,0,,,,,,"ECOLE*: an Environment of COnstruction, transformation and evaLuation of logical, functional and objEctconstructions.",http://hidouci.esi.dz/ecole2000.pdf.gz,,,,q3KEGmAAAAAJ:8k81kl-MbHgC
1021066,"Les grilles informatiques impliquent le partage des ressources hétérogènes de calcul et de stockage à l’échelle planétaire. Récemment, l’utilisation des infrastructures de grilles a été centrée sur les applications de distribution des grands volumes de données. Les méthodes de gestion des données modernes ne reposent plus sur des systèmes centralisés. Pour offrir de meilleurs temps, il faut appliquer des structures dédiées aux environnements distribués. PBST*(Distributed Partitioned Binary Search Tree) est une structure de données arborescente dédiée aux environnements distribués. Cette méthode se caractérise particulièrement par le partitionnement dynamique de données en vue de les distribuer sur plusieurs ressources informatiques et de les traiter en parallèle. Dans cet article, nous proposons un protocole de distribution de données selon PBST* pour le placement de données sur les grilles.",Amina Chikhaoui and Djamel-Eddine Zegour and Walid-Khaled Hidouci,0,,,,,,Distribution de données selon la méthode PBST* sur une grille informatique,http://zegour.esi.dz/Ftp/Pbst_stic11.pdf,,,,q3KEGmAAAAAJ:Se3iqnhoufwC
1021067,"Page 1. 1/19 ID TITLE AUTHORS 2 Quad-band Microstrip Patch Antenna for WLAN/WiMAX/
C/X Applications Mouloud CHALLAL, Faiza MOUHOUCHE, Kahina DJAFRI and Ahmed
BOUTEJDAR 3 Thinning of Concentric Circular Arrays using Galaxy Based Search Algorithm
Abdelmadjid RECIOUI 5 Diagnosis of the Induction Machine by the Kalman Filter Abdelghani
CHAHMI, Abdelhak Djoudi 6 Development and design of Helmholtz coil for NBTI degradation
studies Sidi Mohammed MERAH, bouchra Nadji 7 MIMO Identification and Digital Compensator
Design For Quadruple Tank Process Belkacem Bekhiti, DAHIMENE Abdelhakim, HARICHE
Kamel, Mohamed A. Moustafa Hassan 21 A Low Complexity Joint Semi-Blind Estimation of
CFO and Channel for OFDM Systems Masmoudi Ramadhan, DJEBBAR Ahmed BOUZIDI,
Dayoub Iyad 22 Electrostatic Characterization of Cereal Grains … 
",Mouloud CHALLAL and Faiza MOUHOUCHE and Kahina DJAFRI and Ahmed BOUTEJDAR and Belkacem Bekhiti and Abdelhakim DAHIMENE and Kamel HARICHE and Mohamed A Moustafa Hassan and Masmoudi Ramadhan and Ahmed DJEBBAR and Dayoub Iyad and Abdelkader NADJEM and Omar Boudraa and Walid Khaled Hidouci and Dominique Michelucci and Redha BENDOUMIA and Mohamed Djendi and Abderrezak Guessoum and Imene Soussi and Mohamed Ouslim,0,,,,,,ID TITLE AUTHORS,https://ieeexplore.ieee.org/abstract/document/8191965/,,,,q3KEGmAAAAAJ:ufrVoPGSRksC
