id,abstract,author,cites,cites_id,journal,number,pages,publisher,title,url,volume,year,citation_link,id_citations
1024000,"The Maximum Power Point Tracking controller (MPPT) is a key element in Photovoltaic systems (PV). It is used to maintain the PV operating point at its maximum under different temperatures and sunlight irradiations. The goal of a MPPT controller is to satisfy the following performances criteria: accuracy, precision, speed, robustness and handling the partial shading problem when climatic changes variations occur. To achieve this goal, several techniques have been proposed ranging from conventional methods to artificial intelligence and bio-inspired methods. Each technique has its own advantage and disadvantage. In this context, we propose in this paper, a new Bio- inspired MPPT controller based on the Ant colony Optimization algorithm with a New Pheromone Updating strategy (ACO_NPU MPPT) that saves the computation time and performs an excellent tracking capability with high accuracy, zero …",Sabrina Titri and Cherif Larbes and Kamal Youcef Toumi and Karima Benatchba,107,12109637922553396745,Applied Soft Computing,,465-479,Elsevier,A new MPPT controller based on the Ant colony optimization algorithm for Photovoltaic systems under partial shading conditions,https://www.sciencedirect.com/science/article/pii/S1568494617302703,58,2017,/scholar?cites=12109637922553396745,7iGY4M0AAAAJ:u_35RYKgDlwC
1024001,"Partitioning and scheduling are two central issues in the design of embedded systems since they can widely influence the characteristics of the system under design. The numerous constraints imposed by the environment and/or the underlying target architecture of mixed systems (containing hardware and software parts) make these two problems hard to solve. This paper introduces an automatic approach that integrates simultaneously partitioning and scheduling. It is inspired by the collective behavior of social insects such as bees in order to find a feasible solution to partitioning, using scheduling to find the shortest execution time to the system under design.",Mouloud Koudil and Karima Benatchba and Amina Tarabet and El Batoul Sahraoui,78,16829893643301486729,Applied Mathematics and Computation,2,1710-1722,Elsevier,Using artificial bees to solve partitioning and scheduling problems in codesign,https://www.sciencedirect.com/science/article/pii/S0096300306011064,186,2007,/scholar?cites=16829893643301486729,7iGY4M0AAAAJ:2osOgNQ5qMEC
1024002,"The “NP-Complete” class gathers very significant practical problems such as Sat, Max-Sat, partitioning. There is not polynomial algorithm for the resolution of these problems. As a result, the interest in heuristics and meta-heuristics is still growing. In this paper, we present a very recent metaheuristic introduced to solve a 3-sat problem. This metaheuristic can be classified as an evolutionary algorithm. It is based on the process of bees’ reproduction. We adapted it for the resolution of the Max-Sat problem. We tested it on a medical benchmark obtained from a data-mining problem that we translated into a Max-Sat problem.",Karima Benatchba and Lotfi Admane and Mouloud Koudil,68,14003007639557935675,,,212-220,"Springer, Berlin, Heidelberg",Using bees to solve a data-mining problem expressed as a max-sat one,https://link.springer.com/chapter/10.1007/11499305_22,,2005,/scholar?cites=14003007639557935675,7iGY4M0AAAAJ:qjMakFHDy7sC
1024003,"This paper presents a survey of previous studies done on the problem of tracking community evolution over time in dynamic social networks. This problem is of crucial importance in the field of social network analysis. The goal of our paper is to classify existing methods dealing with the issue. We propose a classification of various methods for tracking community evolution in dynamic social networks into four main approaches using as a criterion the functioning principle: the first one is based on independent successive static detection and matching; the second is based on dependent successive static detection; the third is based on simultaneous study of all stages of community evolution; finally, the fourth and last one concerns methods working directly on temporal networks. Our paper starts by giving basic concepts about social networks, community structure and strategies for evaluating community detection …",Narimene Dakiche and Fatima Benbouzid-Si Tayeb and Yahya Slimani and Karima Benatchba,50,457353002101659467,Information Processing & Management,3,1084-1102,Pergamon,Tracking community evolution in social networks: A survey,https://www.sciencedirect.com/science/article/pii/S0306457317305551,56,2019,/scholar?cites=457353002101659467,7iGY4M0AAAAJ:pyW8ca7W8N0C
1024004,"Tree topologies are widely used in WSN in order to route convergecast traffic to the sink. We consider in this paper the Shortest Path routing Tree (SPT) problem in WSN under different metrics; we show that the basic SPT based strategies are unsuitable for the many-to-one WSN when considering some metrics to compute link costs. Indeed, existing SPT approaches aim to construct a tree rooted at the sink such that the cost of the path from any node to the sink is minimal, while the cost of a given path is computed as summation of the costs of links that compose this path. However, in many-to-one WSN, links which are close to the sink are more critical than other links when using some metrics. We propose in this paper a new weighted path cost function, and we show that our cost function is more suitable for WSN. Based on this cost function, we propose a simple and efficient weighted shortest path tree construction …",Walid Bechkit and Mouloud Koudil and Yacine Challal and Abdelmadjid Bouabdallah and Brahim Souici and Karima Benatchba,46,15499402060837518010,,,000187-000192,IEEE,A new weighted shortest path tree for convergecast traffic routing in WSN,https://ieeexplore.ieee.org/abstract/document/6249291/,,2012,/scholar?cites=15499402060837518010,7iGY4M0AAAAJ:UeHWp8X0CEIC
1024005,"Unsupervised classification is one of the tasks of data-mining. In this paper, a method named AntPart for the resolution of exclusive unsupervised classification is introduced. It is inspired by the behavior of a particular species of ants called Pachycondyla apicalis. The performances of this method are compared with those of three other ones, also inspired by the social behavior of ants: AntClass, AntTree and AntClust.",Lotfi Admane and Karima Benatchba and Mouloud Koudil and Lamri Siad and Said Maziz,30,18446458946249788441,Applied Mathematics and Computation,1,16-28,Elsevier,AntPart: an algorithm for the unsupervised classification problem using ants,https://www.sciencedirect.com/science/article/pii/S0096300305010933,180,2006,/scholar?cites=18446458946249788441,7iGY4M0AAAAJ:IjCSPb-OGe4C
1024006,"On one hand, image segmentation is a low-level processing task which consists in partitioning an image into homogeneous regions. It can be seen as being a combinatorial optimization problem. In fact, considering the huge amount of information that an image carries, it is impossible to find the best segmentation. On the other hand, quantum genetic algorithms are characterized by their high diversity, and by a good balance between global and local search. In this paper, we present a quantum genetic algorithm for image segmentation",Karima Benatchba and Mouloud Koudil and Yacine Boukir and Nadjib Benkhelat,17,6712214051032602395,,,3556-3563,IEEE,Image segmentation using quantum genetic algorithms,https://ieeexplore.ieee.org/abstract/document/4153487/,,2006,/scholar?cites=6712214051032602395,7iGY4M0AAAAJ:zYLM7Y9cAGgC
1024007,"Partitioning problem in codesign is of great importance since it can widely influence the characteristics of the system under design. The numerous constraints imposed by the environment and/or the underlying target architecture, in addition to its NP-Completeness makes the problem hard to solve. This paper introduces an automatic partitioning approach inspired by the collective behavior of social insects such as ants, which are able to find the shortest path from their nest to a food source.",Mouloud Koudil and Karima Benatchba and Said Gharout and Nacer Hamani,13,6857999032034121992,,,324-337,"Springer, Berlin, Heidelberg",Solving partitioning problem in codesign with ant colonies,https://link.springer.com/chapter/10.1007/11499305_34,,2005,/scholar?cites=6857999032034121992,7iGY4M0AAAAJ:Tyk-4Ss8FVUC
1024008,"Semantic Web services (SWs) and P2P computing have emerged as new paradigms for solving complex problems by enabling large-scale aggregation and sharing of distributed computational resources. In this paper, we present a scalable approach based on epidemic discovery algorithm to discover new distributed and heterogeneous collaborative applications of large-scale distributed systems in a P2P network, and to rank the results according to a similarity score expressing the affinities between each of them and a user-submitted query. In order to reduce the execution time and improve the applicability of the epidemic discovery algorithm for discovering SWs, we propose the matching of ontology OWL-S process model in the heart of this algorithm which reduces the search space while keeping an acceptable matching quality level. Moreover, our matching approach is able to detect complex mappings …",Adel Boukhadra and Karima Benatchba and Amar Balla,10,1057950392807801830,,,106-113,IEEE,Ranked matching of OWL-S process model for distributed discovery of SWs in P2P systems,https://ieeexplore.ieee.org/abstract/document/7023941/,,2014,/scholar?cites=1057950392807801830,7iGY4M0AAAAJ:ufrVoPGSRksC
1024009,"On one hand, there is the problem to solve which is the image segmentation. It is a low-level processing task which consists in partitioning an image into homogeneous regions. Segmentation can be seen as a combinatorial optimization problem. In fact, considering the huge amount of information that an image carries, it is impossible to find the best segmentation. On the other hand, the reduced individual properties of ants as well as the simplicity of their behaviours led to the design of several methods of optimization by ants such as: optimization by colony of ants (ant colony optimization) and classification by co-operating ants (AntClass, AntTree, AntClust...). In this paper, we present an algorithm for the resolution of the segmentation problem. This algorithm, named ISA (image segmentation using ants), is based on the behavior of ants while cleaning their nest. The image to be segmented represents the …",Karima Benatcha and Mouloud Koudil and Nadjib Benkhelat and Yacine Boukir,10,12667183297119603035,,,2503-2507,IEEE,ISA an algorithm for image segmentation using ants,https://ieeexplore.ieee.org/abstract/document/4677258/,,2008,/scholar?cites=12667183297119603035,7iGY4M0AAAAJ:k_IJM867U9cC
1024010,"Semantic Web services  (SWs) has become the most dominant paradigm of the service-oriented computing and one of the hot issues in the area of distributed computing technology to perform business services composition more efficiently and effectively for a number of years now. The distributed composition of SWs according to their functionality increases the capability of an application to fulfill the user’s requirements. In this paper, we describe an efficient approach for improving the performance and effectiveness of automatic and cooperative composition of SWs in P2P systems. It implements a distributed solution based on scalable epidemic algorithm to discover and compose SWs in P2P systems. The main idea of our approach is to develop hybrid matching technique that operates on OWL-S process models in order to ensure high recall, further reduce the number of messages exchanged and reduce …",Adel Boukhadra and Karima Benatchba and Amar Balla,9,2697433755509868381,Journal of Ambient Intelligence and Humanized Computing,2,187-203,Springer Berlin Heidelberg,Efficient distributed discovery and composition of OWL-S process model in P2P systems,https://link.springer.com/content/pdf/10.1007/s12652-015-0313-8.pdf,7,2016,/scholar?cites=2697433755509868381,7iGY4M0AAAAJ:UebtZRa9Y70C
1024011,"Data mining is a constantly growing area. More and more domains of the daily life take advantage of the available tools (medicine, trade, meteorology, ...). However, such tools are confronted to a particular problem: the great number of characteristics that qualify data samples. They are more or less victims of the abundance of information. Sat domain benefits from the appearance of powerful solvers that can process huge amounts of data in short times. This paper proposes to solve supervised learning problems expressed as Sat ones. This is done to take advantage of an existing environment that allows experimenting different heuristics, such as: tabu search, genetic algorithm, ant colonies, etc., in order to extract solutions that satisfy a maximum number of clauses (Max-Sat problem). Finally, the best solutions are back-translated into rules that are applied to the data sets in order to verify that they really satisfy a …",Lotfi Admane and Karima Benatchba and Mouloud Koudil and M Drias and Said Gharout and Nacer Hamani,8,11036703517330403468,,,3151-3157,IEEE,Using ant colonies to solve data-mining problems,https://ieeexplore.ieee.org/abstract/document/1400824/,4,2004,/scholar?cites=11036703517330403468,7iGY4M0AAAAJ:Y0pCki6q_DkC
1024012,"Partitioning problem in codesign is of critical importance since it has big impact on cost/performance characteristics of the final product. Tt is an NP-Complete problem that deals with the different constraints relative to the system and the underlying target architecture. The reported partitioning approaches have several drawbacks (they are often dedicated to a particular application or target architecture, they operate at a unique granularity level, most of them are manual and impossible to apply for complex systems, the number of constraints they deal with is generally limited...). This paper introduces an automatic approach using genetic algorithms to solve partitioning in codesign. This approach is totally independent of target architecture. Another advantage of this approach is that it allows determining dynamically the granularity of the objects to partition, making it possible to browse more efficiently solution …",Mouloud Koudil and Karima Benatchba and Daniel Dours,7,11837316894553961473,,,393-400,"Springer, Berlin, Heidelberg",Using genetic algorithms for solving partitioning problem in codesign,https://link.springer.com/chapter/10.1007/3-540-44869-1_50,,2003,/scholar?cites=11837316894553961473,7iGY4M0AAAAJ:eQOLeE2rZwMC
1024013,"We introduce a novel game theory approach to the problem of integrating periodic and flexible preventive maintenance and production scheduling for permutation flowshops. Our main contribution is to propose game modeling that allows decision maker to have compromise solutions meeting at best production and maintenance criteria. To achieve this, two new games formulations for the problem are proposed, and a stable solution for the players is obtained through the concept of equilibrium. The first game follows a constructive approach while the second one follows an improvement one. Moreover, to cope with the concept of game types, we proposed two player’s behaviors: rational and non-rational. Extensive experiments are carried out to validate our proposed approaches and developed methods. Besides, the results of the proposed methods are compared against the state of the art, highlighting our …",Fatima Benbouzid-Si Tayeb and Karima Benatchba and Abd-Essalam Messiaid,6,13763169790325844915,Operational Research,1,221-255,Springer Berlin Heidelberg,Game theory-based integration of scheduling with flexible and periodic maintenance planning in the permutation flowshop sequencing problem,https://link.springer.com/article/10.1007/s12351-016-0261-x,18,2018,/scholar?cites=13763169790325844915,7iGY4M0AAAAJ:bEWYMUwI8FkC
1024014,,K Benatchba and L Admane and M Koudil and H Drias,6,16885290376849720109,"International Conference on Mathematical Methods for Learning, MML",,,,Application of ant colonies to data-mining expressed as Max-Sat problems,http://scholar.google.com/scholar?cluster=16885290376849720109&hl=en&oi=scholarr,,2004,/scholar?cites=16885290376849720109,7iGY4M0AAAAJ:WF5omc3nYNoC
1024015,"In wireless sensor networks, trust management schemes are designed to preserve them against misbehavior of malicious sensor nodes. These schemes observe the behavior of nodes, check their conformity to what is expected, compute and assign them trust values, and avoid any interaction with untrustworthy nodes. In this paper, we introduce Adaptive and dual Data-Communication Trust scheme (ADCT) for clustered wireless sensor networks to effectively deal with untrustworthy nodes. Unlike prior works, we propose an adaptive trust function to assess the direct trust between nodes according to the application’s requirement in terms of trust severity. We also consider data trust to cope with untrustworthy nodes during the data collection despite their communication capabilities. Moreover, we use the duality data-communication trust to deal with untrustworthy recommendations when building cluster …",Said Talbi and Mouloud Koudil and Abdelmadjid Bouabdallah and Karima Benatchba,5,4121175823795987767,Telecommunication Systems,4,605-619,Springer US,Adaptive and dual data-communication trust scheme for clustered wireless sensor networks,https://link.springer.com/article/10.1007/s11235-016-0254-3,65,2017,/scholar?cites=4121175823795987767,7iGY4M0AAAAJ:TFP_iSt0sucC
1024016,"Feature selection is an important data-preprocessing step that often precedes the classification task. Because of large amount of features in real world applications, feature selection is considered as a hard optimization problem. For such problems, metaheuristics have been shown to be a very promising solving approach. In this work, we propose to use Bee Swarm Optimization (BSO) for feature selection. The proposed algorithm, BSO-FS, is based on the wrapper approach that uses BSO for the generation of feature subsets, and a classifier algorithm to evaluate the solutions. BSO-FS is tested on well-known datasets and its performances are compared with those of recently published methods. Obtained results show that for the majority of datasets, BSO-FS selects efficiently relevant features while improving the classification accuracy.",Souhila Sadeg and Leila Hamdad and Karima Benatchba and Zineb Habbas,5,15166481081923817971,,,387-399,"Springer, Cham",BSO-FS: bee swarm optimization for feature selection in classification,https://link.springer.com/chapter/10.1007/978-3-319-19258-1_33,,2015,/scholar?cites=15166481081923817971,7iGY4M0AAAAJ:kNdYIx-mwKoC
1024017,"In this paper, we describe our participation in the INEX 2015 Social Book Search Suggestion Track (SBS). We have exploited in our experiments only the tags assigned by users to books provided from LibraryThing (LT). We have investigated the impact of the weight of each term of the topic in the retrieval model using two methods. In the first method, we have used the TF-IQF formula to assign a weight to each term of the topic. In the second method, we have used Rocchio algorithm to expand the query and calculate the weight of the tags assigned to the example books mentioned in the book search request. Parameters of our models have been tuned using the topics of INEX 2014 and tested on INEX 2015 Social Book Search track.",Messaoud Chaa and Omar Nouali and Youcef Djenouri and Ahcène Bendjoudi and Djamel Djenouri,5,6646912437190704447,,,,,CERIST at INEX 2015: Social Book Search Track.,http://ceur-ws.org/Vol-1391/18-CR.pdf,,2015,/scholar?cites=6646912437190704447,7iGY4M0AAAAJ:fPk4N6BV_jEC
1024018,"Palmprint is one of the modalities that offer high recognition accuracy. The recognition process depends on an optimized ROI (Region of Interest) extraction. This extraction is affected by several factors including the device used and the acquisition conditions. The acquisition mode can alter some image properties like rotation, translation and scale. Some devices are designed to maintain hand in a fixed position and delimit a subspace of the hand. On the other hand, contactless devices offer more convenience and flexibility but lead to altered images. ROI extraction methods must consider the acquisition device (with contact or contactless). In this paper, we propose a ROI extraction method that addresses this issue. We test our method on two databases PolyU and CASIA which illustrate the impact of using contactless device unlike the PolyU device. Then, we test performances of the palmprint biometric system. We …",Artabaz Saliha and Benatchba Karima and Koudil Mouloud and Dellys Hachemi Nabil and Bouridane Ahmed,5,9198236942876727248,,,77-82,IEEE,Extraction method of Region of Interest from hand palm: Application with contactless and touchable devices,https://ieeexplore.ieee.org/abstract/document/7064624/,,2014,/scholar?cites=9198236942876727248,7iGY4M0AAAAJ:u5HHmVD_uO8C
1024019,"B&B algorithms are well known techniques for exact solving of combinatorial optimization problems (COP). They perform an implicit enumeration of the search space instead of exhaustive one. Based on a pruning technique, they reduce considerably the computation time required to explore the whole search space. Nevertheless, these algorithms remain inefficient when dealing with large combinatorial optimization instances. They are time-intensive and they require a huge computing power to be solved optimally. Nowadays, multi-core-based processors and GPU accelerators are often coupled together to achieve impressive performances. However, classical B&B algorithms must be rethought to deal with their two divergent architectures. In this paper, we propose a new B&B approach exploiting both the multi-core aspect of actual processors and GPU accelerators. The proposed approaches have been executed …",Ahcene Bendjoudi and Mehdi Chekini and Makhlouf Gharbi and Malika Mehdi and Karima Benatchba and Fatima Sitayeb-Benbouzid and Nouredine Melab,5,10706927417048487110,,,914-921,IEEE,Parallel B&B Algorithm for Hybrid Multi-core/GPU Architectures,https://ieeexplore.ieee.org/abstract/document/6832012/,,2013,/scholar?cites=10706927417048487110,7iGY4M0AAAAJ:Se3iqnhoufwC
1024020,"Choices of decision makers in a basketball team are not limited to the strategies to be adopted during games. The most important ones are outside the field and concern team composition and talented and productive players to acquire on which the team can rely to raise its game level. In this paper, we propose to use data mining tasks to help decision makers to make appropriate decisions that will lead to the improvement of the performance of their players and their team. Tasks such as clustering, classification and regression are used to detect weaknesses of a team; best players that can help overcome these weaknesses; predict performance and salaries of players. These will be done on the NBA dataset.",Leila Hamdad and Karima Benatchba and Fella Belkham and Nesrine Cherairi,4,14976657871572447045,,,13-24,"Springer, Cham",Basketball Analytics. Data Mining for Acquiring Performances,https://link.springer.com/chapter/10.1007/978-3-319-89743-1_2,,2018,/scholar?cites=14976657871572447045,7iGY4M0AAAAJ:f2IySw72cVMC
1024021," Multi-biometrics is a solution which is sought to overcome functional and security deficiency in a baseline biometric configuration. In this paper, we propose a multi-biometrics scheme and we apply the cross validation between two databases to study the Equal Error Rate improvement of score level fusion. Our fusion function is constructed using an evolutionary GA on the XM2VTS score database. The best one is tested on a sub-sequence of the BioSecure Score database. As this database offers quality measurement, we transform our function into a weighted function with user-specific approach to study performance enhancement with quality integration. The results are significantly improved with a high confidence and quality measurement becomes inherent to reduce recognition errors. ",Saliha Artabaz and Layth Sliman and Hachemi Nabil Dellys and Karima Benatchba and Mouloud Koudil,4,5729823467197983974,,,260-267,"Springer, Cham",Multibiometrics enhancement using quality measurement in score level fusion,https://link.springer.com/chapter/10.1007/978-3-319-53480-0_26,,2016,/scholar?cites=5729823467197983974,7iGY4M0AAAAJ:zA6iFVUQeVQC
1024022,"Multibiometric systems are a promising area that addresses a number of unimodal biometric systems drawbacks. The main limit of these systems is the lack of information in terms of quantity (number of discriminant features) and quality (diversity of information, correlation…). Using multiple sources of information and/or treatment is a solution to overcome these problems and enhance system performances. Performance requirements of current systems related to context use involve designed solutions that optimally satisfy security requirements. This can represent an optimization problem that aims at searching the optimal solution matching security needs. In our study, we are interested in combining different score level rules using an evolutionary algorithm. We use Genetic Algorithm to derive a score fusion function based on primitive operations. The process uses an optimized tree to determine function …",Saliha Artabaz and Layth Sliman and Karima Benatchba and Hachemi Nabil Dellys and Mouloud Koudil,4,15222675747046712012,,,166-177,"Springer, Cham",Score level fusion scheme in hybrid multibiometric system,https://link.springer.com/chapter/10.1007/978-3-319-25939-0_15,,2015,/scholar?cites=15222675747046712012,7iGY4M0AAAAJ:j3f4tGmQtD8C
1024023,"Fuzzy Vault is an interesting error tolerant method to encrypt data. This method has been widely used in the field of biometrics because of the unstable nature of captured biometric modalities. In this paper, we present main works on Fuzzy Vault when used to secure fingerprint templates. We describe the contributions proposed in different stages of the two Fuzzy Vault phases. The purpose of this work is to show the implementation to be chosen at each stage of a specific Fuzzy Vault application. To this end, in this paper, we conduct a comparative study of these works from a theoretical point of view, and according to some practical criteria.",Hachemi Nabil Dellys and Noussaiba Benadjimi and Meriem Romaissa Boubakeur and Layth Sliman and Karima Benatchba and Saliha Artabaz and Mouloud Koudil,4,12846597115392190281,,,178-188,"Springer, Cham",A critical comparison of fingerprint fuzzy vault techniques,https://link.springer.com/chapter/10.1007/978-3-319-25939-0_16,,2015,/scholar?cites=12846597115392190281,7iGY4M0AAAAJ:MXK_kJrjxJIC
1024024,"Semantic Web services (SWs) paradigm is considered as the most dominant technology of the Service-Oriented Computing (SOC). SWs have emerged as a major technology for deploying automated interactions between distributed and heterogeneous applications. This computing technology can be used to discover new distributed and heterogeneous collaborative applications of large-scale distributed systems in P2P systems. In this paper, we present a scalable P2P approach for distributed discovery of SWs. In this approach, we define a distributed solution based on epidemic discovery algorithm to achieve a specific goal through the distributed discovery of SWs in P2P networks. In order to improve the applicability of the epidemic discovery algorithm for discovering SWs, we propose the matching of ontology OWL-S in the heart of this algorithm which reduces the search space while keeping an acceptable …",Adel Boukhadra and Karima Benatchba and Amar Balla,4,6780537270079221709,,,896-903,IEEE,Hybrid ontology-based matching for distributed discovery of sws in p2p systems,https://ieeexplore.ieee.org/abstract/document/7056851/,,2014,/scholar?cites=6780537270079221709,7iGY4M0AAAAJ:LkGwnXOMwfcC
1024025,"Web services are the new generation of distributed software components. They are important for deploying automated interactions between distributed and heterogeneous applications of large-scale distributed systems. But with the evolution of the number of services available on the Web, in organizations and their large-scale use, a discovery mechanism of such a Web service in a distributed and heterogeneous environment has become a real challenge. In this paper, we describe a scalable P2P approach for automatic discovery of Semantic Web services (SWs), which supports the complexity of both SWs and task. Our architecture is based on P2P technology that has proven its effectiveness and robustness as distributed system. The particularity of our approach is to place the alignment of OWL-S in the heart of this architecture.",Adel Boukhadra and Karima Benatchba and Amar Balla,4,8963761276884808921,,,29-36,IEEE,HPS5DSWS: A hybrid P2P strategy of the distributed discovery mechanism for semantic web services,https://ieeexplore.ieee.org/abstract/document/6681206/,,2013,/scholar?cites=8963761276884808921,7iGY4M0AAAAJ:roLk4NBRz8UC
1024026,"Financial markets are complex systems consisting of entities interacting and evolving in an uncertain environment. Their modelling and simulation requires the use on the one hand of a suited technology that is multi-agent systems (MASs) to model the various actors of a market, and on the other hand the evolutionary game theory to formalise interactions and heterogeneous investment strategies. The goal of this paper is to model, simulate and analyse financial markets dynamics. For this purpose, we propose three market models (fundamentalist, strategic, conventionalist) summarising various facets of real market speculation depending on the information held and the price formation process chosen by the investors. Each model is built using a multi-agent system. Moreover, investors’ agents are modelled by classifier systems that are advanced structures to study their evolutionary and adaptive aspects.",Badiâa Hedjazi and Mohamed Ahmed-Nacer and Samir Aknine and Karima Benatchba,4,10888646503605922303,International Journal of Simulation and Process Modelling,2-3,185-199,Inderscience Publishers Ltd,Multi-agent financial market simulation: evolutionist approach,https://www.inderscienceonline.com/doi/abs/10.1504/IJSPM.2013.057538,8,2013,/scholar?cites=10888646503605922303,7iGY4M0AAAAJ:9yKSN-GCB0IC
1024027,"Several biometric threats systems models have been proposed to facilitate the design, implementation and validation techniques for securing these systems. Some models classify threats by type of attacks, others by specific attacks and other by using vulnerabilities and threat agent. Each model proposes a vision and a different approach to identify these threats. For example, to design security techniques for wireless biometric card, one should identify all threats facing this kind of device. In this paper, a comparative study and synthesis to help choose the most fitting model, depending on the security problems addressed, is given.",Dellys Hachemi Nabil and Benatchba Karima and Koudil Mouloud and Bouridane Ahmed,4,1967860201009897355,,,186-191,IEEE,Threats models on biometri systems: A comparative study,https://ieeexplore.ieee.org/abstract/document/6412400/,,2012,/scholar?cites=1967860201009897355,7iGY4M0AAAAJ:u-x6o8ySG0sC
1024028,,K Benatchba and M Kondil and H Drias and R Belkacem,4,6146140224898759124,"October, ISSN",,1109-2777,,An adapted genetic algorithms for solving Max-Sat problems. WSEAS TRANSACTIONS on SYSEMS. Issue 4,http://scholar.google.com/scholar?cluster=6146140224898759124&hl=en&oi=scholarr,,2003,/scholar?cites=6146140224898759124,7iGY4M0AAAAJ:YsMSGLbcyi4C
1024029,"This paper deals with induction machines bearing failures detection and diagnosis using vibration and temperature signals. It proposes the use of a new Classical Mechanics-inspired Optimization (CMO) metaheuristic for data clustering. To ensure failure detection, transitions from a state to another is analyzed in order to form a transitional model between system states generated by the clustering. The performances of the proposed new metaheuristic are evaluated on the PRONOSTIA experimental platform data.",Charaf Eddine Khamoudj and Fatima Benbouzid-Si Tayeb and Karima Benatchba and Mohamed Benbouzid,3,6370746833790027499,,,3803-3808,IEEE,Classical mechanics-inspired optimization metaheuristic for induction machines bearing failures detection and diagnosis,https://ieeexplore.ieee.org/abstract/document/8216649/,,2017,/scholar?cites=6370746833790027499,7iGY4M0AAAAJ:yD5IFk8b50cC
1024030,"Recent technology advances allow new generation reconfigurable-based embedded systems to contain a large number of cores and reconfigurable logic elements. Consequently, to take benefit of such very powerful hybrid reconfigurable MPSoC, designers need tools to explore the large design space of the possible configurations. In this paper, we develop a new hybrid bi-objective genetic and parallel variable neighborhood descent algorithm (GA-PVNS) to determine close to optimal configurations for heterogeneous FPGA-based MPSoC (Ht-MPSoC). Our exploration method aims to optimize simultaneously two objectives, namely area on the FPGA and execution time, taking advantage of the Genetic Algorithm (GA) diversification ability and the intensification provided by Variable Neighborhood Search (VNS) algorithm. Our design space includes Ht-MPSoC with private and shared HW accelerators on FPGA …",Braham Lotfi Mediouni and Smail Niar and Rachid Benmansour and Karima Benatchba and Mouloud Koudil,3,10076134149970698930,,,90-95,IEEE,A bi-objective heuristic for heterogeneous MPSoC design space exploration,https://ieeexplore.ieee.org/abstract/document/7396742/,,2015,/scholar?cites=10076134149970698930,7iGY4M0AAAAJ:qUcmZB5y_30C
1024031,"In this paper, we introduce Adaptive Data-Communication Trust Mechanism for clustered wireless sensor networks (ADCT) to effectively deal with compromise or malicious nodes. Unlike prior works, we propose an adaptive function to evaluate the direct trust between nodes according to the need of the application in terms of trust severity. We also consider data trust to cope with untrustworthy nodes during the data collection despite their communication capabilities. Finally, we introduce a new method to discard a malicious recommendation when building feedback at the base station or cluster-head level. Theoretical analysis shows that our trust mechanism allows a good trade-off between memory requirement and trust cooperation.",Said Talbi and Mouloud Koudil and Abdelmadjid Bouabdallah and Karima Benatchba,3,4481692595390547612,,,1-6,IEEE,Adaptive data-communication trust mechanism for clustered wireless sensor networks,https://ieeexplore.ieee.org/abstract/document/7416963/,,2015,/scholar?cites=4481692595390547612,7iGY4M0AAAAJ:8k81kl-MbHgC
1024032,"The default KVM setup included in Open Nebula, Eucalyptus and Apache Cloud Stack could not perform well enough under certain circumstances, because it does not expose to the guest VMs some of the features included in the modern processors. In order to tune up the cloud platform for obtaining a better CPU performance for the virtualized software executed under the KVM hyper visor, we have proposed and tested an alternative KVM setup in Apache Cloud Stack. The setup provided could also be applied to other cloud platforms.",Fernando Gomez Folgar and Antonio Garcia Loureiro and Tomas Fernandez Pena and J Isaac Zablah and Natalia Seoane,3,13621742954245603628,,,260-263,IEEE,Implementation of the kvm hypervisor on several cloud platforms: Tuning the apache cloudstack agent,https://ieeexplore.ieee.org/abstract/document/7056749/,,2014,/scholar?cites=13621742954245603628,7iGY4M0AAAAJ:abG-DnoFyZgC
1024033,"The Web services technology is now widely used in support of interoperability between distributed and heterogeneous applications. With the evolution of Semantic Web services (SWs) within organizations and their uses in a large-scale, composition of services in a distributed setting has become a real challenge. A mechanism for automatic composition of SWs according to their functionality is necessary, since the features are the most important thing that partners seek. In this paper, we describe a distributed approach to automatic composition of SWs, which supports the complexity of both SWs and the task at hand. The approach is based on the notion of alignment of OWL-S, in order to achieve semantic interoperability in a heterogeneous, and distributed architecture, to ensure correct operation of Web services provided, and meet the needs and users' preferences. The objective is to optimize the time of the …",Adel Boukhadra and Karima Benatchba and Amar Balla,3,15612192352902283506,,,182-187,IEEE,DA5DCSWS: a distributed architecture for semantic web services discovery and composition,https://ieeexplore.ieee.org/abstract/document/6750188/,,2013,/scholar?cites=15612192352902283506,7iGY4M0AAAAJ:0EnyYjriUFMC
1024034,"Decision Support Systems (DSS) are a constantly growing area. More and more domains of the daily life take advantage of the available tools (medicine, trade, meteorology…). However, such tools are confronted to a particular problem: the great number of characteristics that qualify data samples. They are more or less victims of the abundance of information.Sat domain benefits from the appearance of powerful solvers that can process huge amounts of data in short times. This paper presents an approach for translating timetable problems (which are a particular case of DSS), into a Boolean formula, which is then provided to an environment that allows experimenting different heuristics in order to extract solutions that satisfy a maximum number of clauses (Max-Sat problem). Finally, the best solutions are back-translated into the original problem in order to find an adequate schedule that satisfies the characteristics and constraints of the timetable problem.",Fahima Nader and Mouloud Koudil and Karima Benatchba and Lotfi Admane and Said GHAROUT and Nacer HAMANI,3,5687496714563534823,"Rapport Interne LMCS, INI",,,,Application of Satisfiability algorithms to time-table problems,http://www.wseas.us/e-library/conferences/digest2003/papers/459-184.pdf,,2004,/scholar?cites=5687496714563534823,7iGY4M0AAAAJ:hqOjcs7Dif8C
1024035,"Partitioning has a big impact on cost/performance characteristics of the system under design. It is an NP-Complete problem that deals with the different constraints relative to the system and the underlying target architecture. The existing partitioning approaches have a major drawback: they are generally dedicated to particular classes of applications and/or target architectures and this makes them difficult to generalize as soon as small changes are performed on the system under design. Besides, it is generally difficult to include new strategies that might be better suited to the applications to partition. This paper introduces a parallel environment that offers the user the opportunity to describe, experiment new heuristics and test different sets of parameters. It is also possible to explore new hybridization schemes between different strategies.",Abderrazak Henni and Mouloud Koudil and Karima Benatchba and Hassane Oumsalem and Kamel Chaouche,3,2008889557973922762,WSEAS Transactions on Systems,,8-13,,A parallel environment using taboo search and genetic algorithms for solving partitioning problems in codesign,https://www.researchgate.net/profile/Mouloud_Koudil/publication/267305841_A_parallel_environment_using_taboo_search_and_genetic_algorithms_for_solving_partitioning_problems_in_codesign/links/54786e970cf205d1687df4bf.pdf,3,2004,/scholar?cites=2008889557973922762,7iGY4M0AAAAJ:_FxGoFyzp5QC
1024036," We propose a Late Acceptance Hill-Climbing (LAHC) approach to solve the unrelated parallel machine scheduling problem with sequence and machine-dependent setup times. LAHC is an iterative list-based single-parameter metaheuristic that exploits information from one iteration to another to decide whether the new candidate solution is accepted. A dynamic job insertion heuristic is used to generate initial solutions. Three local search operators (job swap between different machines, job swap within the same machine and job insertion from one machine to another) are used to improve solutions. A Variable Neighborhood Descent (VND) method is proposed to improve the candidate solution and accelerate the convergence of the LAHC. To the best of our knowledge, this is the first application of LAHC to parallel machine scheduling problems. We evaluate and compare the proposed algorithm against …",Mourad Terzi and Taha Arbaoui and Farouk Yalaoui and Karima Benatchba,2,10132756686851913690,,,249-258,"Springer, Cham",Solving the Unrelated Parallel Machine Scheduling Problem with Setups Using Late Acceptance Hill Climbing,https://link.springer.com/chapter/10.1007/978-3-030-41964-6_22,,2020,/scholar?cites=10132756686851913690,7iGY4M0AAAAJ:XiSMed-E-HIC
1024037,"This paper deals with induction machines bearing failures detection and diagnosis using vibration and temperature signals. The failure detection is managed by a clustering graphical representation creating transition classes. Motivated by the computational complexity of the problem, a Variable Neighborhood Search (VNS) metaheuristic is developed including well-designed local search algorithms for data clustering to the system diagnosis. Computational experiments carried out on the PRONOSTIA experimental platform data show that the proposed algorithm seems to be efficient and effective.",Charaf Eddine Khamoudj and Fatima Benbouzid-Si Tayeb and Karima Benatchba and Mohamed Benbouzid,2,13021207629108256358,,,6010-6015,IEEE,Induction machines bearing failures detection and diagnosis using variable neighborhood search,https://ieeexplore.ieee.org/abstract/document/8927697/,1,2019,/scholar?cites=13021207629108256358,7iGY4M0AAAAJ:KxtntwgDAa4C
1024038,"Feature selection is often used before a data mining or a machine learning task in order to build more accurate models. It is considered as a hard optimization problem and metaheuristics give very satisfactory results for such problems. In this work, we propose a hybrid metaheuristic that integrates a reinforcement learning algorithm with Bee Swarm Optimization metaheuristic (BSO) for solving feature selection problem. QBSO-FS follows the wrapper approach. It uses a hybrid version of BSO with Q-learning for generating feature subsets and a classifier to evaluate them. The goal of using Q-learning is to benefit from the advantage of reinforcement learning to make the search process more adaptive and more efficient. The performances of QBSO-FS are evaluated on 20 well-known datasets and the results are compared with those of original BSO and other recently published methods. The results show that …",Souhila Sadeg and Leila Hamdad and Amine Riad Remache and Mehdi Nedjmeddine Karech and Karima Benatchba and Zineb Habbas,2,16762941122174442964,,,785-796,"Springer, Cham",QBSO-FS: A Reinforcement Learning Based Bee Swarm Optimization Metaheuristic for Feature Selection,https://link.springer.com/chapter/10.1007/978-3-030-20518-8_65,,2019,/scholar?cites=16762941122174442964,7iGY4M0AAAAJ:xtRiw3GOFMkC
1024039,"Deadlocks, livelock, congestion and faults are the four most important factors that reduce the NoC routing efficiency [1]. This paper proposes a new fully adaptive routing protocol for 2D-mesh NoC. It is inspired from the A-star search algorithm and called HRA (Heuristic based Routing Algorithm). The latter is distributed, congestion-aware and fault-tolerant by using only the local information of each router neighbors. HRA does not use VCs (Virtual Channels) but tries to reduce the risk of deadlock by avoiding the 2-nodes and the 4-nodes loops. Results show that HRA ensures a good reliability rate despite of the presence of many faulty links. In addition, it has interesting latencies values in different NoC sizes.",Asma Benmessaoud Gabis and Marc Sevaux and Pierre Bomel and Mouloud Koudil and Karima Benatchba,2,16914492016100267913,,,39-45,IEEE,Heuristic based routing algorithm for network on chip,https://ieeexplore.ieee.org/abstract/document/7774418/,,2016,/scholar?cites=16914492016100267913,7iGY4M0AAAAJ:iH-uZ7U-co4C
1024040,"In this paper, we present a scalable approach for visualizing and browsing the search space of available Web services to effectively and efficiently resolve the problem of distributed discovery for Semantic Web services (SWs). We investigate the use of matching technique of ontologies OWL-S, an approach to provide a collaborative mechanism to discover basic SWs distributed among all peers in a purely distributed and heterogeneous P2P network. Our scalable approach is based on the matching technique of OWL-S in order to reduce the time complexity of the distributed discovery for SWs with respect to their semantic similarity, to simplify the management of the P2P network, to optimize the ratio of service exchange and to ensure the quality of service. The network peers offer their SWs to other ones in a distributed and heterogeneous P2P computing, and are able to use distant services to improve …",Adel Boukhadra and Karima Benatchba and Amar Balla,2,14398565638899537827,,,277-284,"Springer, Cham",Efficient P2P approach for a better automation of the distributed discovery of sws,https://link.springer.com/chapter/10.1007/978-3-319-19638-1_32,,2015,/scholar?cites=14398565638899537827,7iGY4M0AAAAJ:3fE2CSJIrl8C
1024041,"We propose in this work a new self organized biomimitic approach for unsupervised classification, named BFC, based on BBO (Biogeography based optimization). This method is tested on several real datasets(IRIS, Satimages and heart). These benchmarks are characterized by increasing overlap degree. Moreover, a comparison of BFC with other clustering methods having proven their efficiency is presented. We will highlight the impact of this overlap on the performance of the methods.",Leila Hamdad and Anissa Achab and Amira Boutouchent and Fodil Dahamni and Karima Benatchba,2,2616649217564427681,,,396-405,"Springer, Berlin, Heidelberg",Self organized biogeography algorithm for clustering,https://link.springer.com/chapter/10.1007/978-3-642-38637-4_41,,2013,/scholar?cites=2616649217564427681,7iGY4M0AAAAJ:M3ejUd6NZC8C
1024042,"Pour résoudre des problèmes NP-Complets tels que le Max-Sat, différentes approches existent dans la littérature, présentant chacune des avantages et des inconvénients. Afin de déterminer une méthode efficace pour résoudre ces problèmes, de nombreux tests doivent être effectués avec différentes stratégies et valeurs des paramètres. C'est la raison pour laquelle le besoin s' est fait sentir de développer un environnement permettant aux utilisateurs d'introduire n'importe quelle méthode ou d'en combiner plusieurs et de les étudier en profondeur. Cet article présente un environnement nommé PARME, basé sur une architecture parallèle, permettant d'implanter différentes approches pour résoudre le problème Max-Sat. Il offre à l'utilisateur un moyen efficace pour étudier les méthode de résolution des problèmes NB-Complets. L'utilisateur peut pratiquer de manière empirique différentes approches d'optimisation (Recherche Tabou, Algorithmes Génétiques, GSAT,...), évaluer leurs performances et étudier l'importance et l'influence des paramètres de la méthode sur son comportement. Afin de bénéficier des avantages des qualités de chaque méthode et de surmonter ses inconvénients, de nombreuses méthodes peuvent collaborer dans PARME, à la recherche de la solution du problème.",K Benatchba and M Koudil and H Drias and H Oumsalem and K Chaouche,2,16918129589190847531,CARI'02,,,,"PARME, un environnement pour la résolution du problème Max-Sat",ftp://131.254.254.45/local/msance/Actes_CARI02/N168.doc,,2002,/scholar?cites=16918129589190847531,7iGY4M0AAAAJ:5nxA0vEk-isC
1024043,"This paper proposes a three-phase metaheuristic-based approach for induction machine bearing failure detection and diagnosis. It consists of extracting and processing different failure types features to set up a knowledge base, which contains different failure types. The first phase consists in pre-processing the measured signals by aggregating them and preparing the data in exploitable formats for the clustering. The second phase ensures the induction machine operating mode diagnosis. A measured signals clustering is performed to build classes where each one represents a health state. A variable neighborhood search (VNS) metaheuristic is designed for data clustering. Moreover, VNS is hybridized with a classical mechanics-inspired optimization (CMO) metaheuristic to balance global exploration and local exploitation during the evolutionary process. The third phase consists of two-step failure detection, setting up a knowledge base containing different failure types, and defining a representative model for each failure type. In the learning step, different class features are extracted and inserted in the knowledge base to be used during the decision step. The proposed metaheuristic-based failure detection diagnosis approach is evaluated using PRONOSTIA and CWR bearing data experimental platforms vibration and temperature measurements. The achieved results clearly demonstrate the failure detection and diagnosis, efficiency, and effectiveness of the proposed metaheuristic approach. View Full-Text",Charaf Eddine Khamoudj and Fatima Benbouzid-Si Tayeb and Karima Benatchba and Mohamed Benbouzid and Abdenaser Djaafri,1,5712820161916069478,Energies,11,2953,Multidisciplinary Digital Publishing Institute,A Learning Variable Neighborhood Search Approach for Induction Machines Bearing Failures Detection and Diagnosis,https://www.mdpi.com/1996-1073/13/11/2953,13,2020,/scholar?cites=5712820161916069478,7iGY4M0AAAAJ:WbkHhVStYXYC
1024044,"Genetic algorithms (GA) are widely used in the literature to extract interesting association rules. However, they are time consuming mainly due to the growing size of databases. To speed up this process, we propose two parallel GAs (ARMGPU and ARM-CPU/GPU). In ARM-GPU, parallelism is used to compute the fitness which is the most time consuming task; while, ARM-CPU/GPU proposes a two-level-based parallel GA. In the first level, the different cores of the CPU execute a GAARM on a sub-population. The second level of parallelism is used to compute the fitness, in parallel, on GPU. To validate the proposed two parallel GAs, several tests were conducted to solve well-known large ARM instances. Obtained results show that our parallel algorithms outperform state-of-the-art exact algorithms (APRIORI and FP-GROWTH) and approximate algorithms (SEGPU and ME-GPU) in terms of execution time.",Leila Hamdad and Zakaria Ournani and Karima Benatchba and Ahcène Bendjoudi,1,1577498803469268833,International Journal of Computational Science and Engineering,2-3,335-345,Inderscience Publishers (IEL),Two-level parallel CPU/GPU-based genetic algorithm for association rule mining,https://www.inderscienceonline.com/doi/abs/10.1504/IJCSE.2020.107366,22,2020,/scholar?cites=1577498803469268833,7iGY4M0AAAAJ:Tiz5es2fbqcC
1024045,"Recently, palmprint recognition in forensic domain has gained considerable attention since 30 % of evidence left in crime scene originate from palms. Like most of recognition systems, palmprint one is composed of three steps: preprocessing, features extraction and representation and finally features matching. Minutiae are the most reliable and discriminating features used in these systems. Minutiae matching is then very critical. Quantifying the similarity between two sets of extracted minutiae and assigning a score is particularly important in this step. In this paper, we designed similarity scores for a minutiae based recognition system using a minimum of extracted information. Our proposed scores are based on the score of [1], used in point pattern matching. They are tested and compared on the database used in [2]. The best one is tested and compared to the one presented in the same work [2]. Obtained results …",Touka Faisal and Karima Benatchba and Mouloud Koudil,1,1203740838753016853,,,132-137,IEEE,Matching similarity scores for a minutiae-based palmprint recognition,https://ieeexplore.ieee.org/abstract/document/8927035/,1,2019,/scholar?cites=1203740838753016853,7iGY4M0AAAAJ:nb7KW1ujOQ8C
1024046,"In this work, we investigate the use of unsupervised data mining techniques to speed up Bee Swarm Optimization metaheuristic (BSO). Knowledge is extracted dynamically during the search process in order to reduce the number of candidate solutions to be evaluated. One approach uses clustering (for grouping similar solutions) and evaluates only clusters centers considered as representatives. The second uses Frequent itemset mining for guiding the search process to promising solutions. The proposed hybrid algorithms are tested on MaxSAT instances and results show that a significant reduction in time execution can be obtained for large instances while maintaining equivalent quality compared to the original BSO.",Souhila Sadeg and Leila Hamdad and Mouloud Haouas and Kouider Abderrahmane and Karima Benatchba and Zineb Habbas,1,17496300684190429826,,,773-784,"Springer, Cham",Unsupervised Learning Bee Swarm Optimization Metaheuristic,https://link.springer.com/chapter/10.1007/978-3-030-20518-8_64,,2019,/scholar?cites=17496300684190429826,7iGY4M0AAAAJ:CHSYGLWDkRkC
1024047,"The first goal of this paper is to study the impact of Genetic Algorithms (GA’s) components such as encoding, different crossover and replacement strategies on the number and quality of extracted association rules. Moreover, we propose a strategy to manage the population. The later is organized in sub-populations where each one encloses same size rules. Each sub-population can be seen as a population on which a GA is applied. Hence, we propose two GAs, a sequential one and a parallel one. All tests are conducted on two types of benchmarks: synthetic and real ones of different sizes.",Leila Hamdad and Karima Benatchba and Ahcene Bendjoudi and Zakaria Ournani,1,13154712514545145405,,,747-759,"Springer, Cham",Impact of Genetic Algorithms Operators on Association Rules Extraction,https://link.springer.com/chapter/10.1007/978-3-030-20518-8_62,,2019,/scholar?cites=13154712514545145405,7iGY4M0AAAAJ:7PzlFSSx8tAC
1024048,"In this paper, we investigate the prediction of community future occurring events in dynamic social networks, based on change rates of features that describe a community throughout its evolution life-cycle rather than absolute values of features. Besides, we explore the most predictive features for each event. Our experiments on DBLP and Facebook datasets, using community structural features and its influential members' features, confirm that the prediction of the next event that may occur to an evolving community using change rates of features can be achieved with a very high accuracy. We further observe that the most significant features vary according to each event prediction.",Narimene Dakiche and Fatima Benbouzid-Si Tayeb and Yahya Slimani and Karima Benatchba,1,9190003209663915129,,,2078-2085,,Community evolution prediction in dynamic social networks using community features' change rates,https://dl.acm.org/doi/abs/10.1145/3297280.3297484,,2019,/scholar?cites=9190003209663915129,7iGY4M0AAAAJ:NhqRSupF_l8C
1024049,"One of the most interesting issues in the field of social network analysis is community evolution prediction in dynamic social networks. To start with, the dynamic network is split into a series of timeframes, each one containing interactions aggregated over a time period such as a month, a day or an hour. Splitting the network into timeframes is of crucial importance to capture the right communities' temporal evolution before predicting their future. Our paper investigates the problem of choosing the appropriate scale for network splitting which would improve the prediction. The experiments we conducted on Facebook and Higgs Twitter datasets offer strong empirical evidence of the usefulness of considering the appropriate network splitting as a first step in predicting community evolution in dynamic social networks.",Narimene Dakiche and Fatima Benbouzid-Si Tayeb and Yahya Slimani and Karima Benatchba,1,14738724062623100061,,,1-8,IEEE,Sensitive analysis of timeframe type and size impact on community evolution prediction,https://ieeexplore.ieee.org/abstract/document/8491668/,,2018,/scholar?cites=14738724062623100061,7iGY4M0AAAAJ:_xSYboBqXhAC
1024050,"In this paper, we introduce a new chaff-points generation method in fuzzy vault fingerprint. Our method is based on squares boundaries and Knapsack problem. Chaff-points generation process consists of creating a set of chaff points similar to authentic minutiae feature representation. Squares based chaff-points generation consist of delimiting a square boundary around each chaff-point in such a way that a square must never overlap with other squares. Unlike the typical squares method where chaff-points and their boundaries are generated sequentially, in our proposal, the referred chaff-points are generated all together then the knapsack problem formulation is used along with 0/1 dynamic programing resolution to determine if each chaff-point respects the constraints. The experiments results show that the chaff-points generation based on Knapsack method generates the referred number of chaff-points …",Hachemi Nabil Dellys and Layth Sliman and Saliha Artabaz and Karima Benatchba and Mouloud Koudil,1,2008446711000198221,,,507-516,"Springer, Cham",Chaff-Points Generation Using Knapsack Problem Resolution in Fingerprint Fuzzy Vault,https://link.springer.com/chapter/10.1007/978-3-319-52941-7_50,,2016,/scholar?cites=2008446711000198221,7iGY4M0AAAAJ:rO6llkc54NcC
1024051,"In this work, we focus on image segmentation by simulating the natural phenomenon of the bodies moving through space. For this, a subset of image pixels is regularly selected as planets and the rest as satellites. The attraction force is defined by Newton’s third law (gravitational interaction) according to the distance and color similarity. In the first phase of the algorithm, we seek an equilibrium state of the earth-moon system in order to achieve the second phase, in which we search an equilibrium state of the earth-apple system. As a result of these two phases, bodies in space are constructed; they represent segments in the image. The objective of this simulation is to find and then extract the multiple segments from an image. ",Charaf Eddine Khamoudj and Karima Benatchba and Mohand Tahar Kechadi,1,3617530679908511210,,,102-110,"Springer, Cham",Classical mechanics optimization for image segmentation,https://link.springer.com/chapter/10.1007/978-3-319-50307-3_8,,2016,/scholar?cites=3617530679908511210,7iGY4M0AAAAJ:qxL8FJ1GzNcC
1024052,"In this paper, we will focus on the contribution an efficient and an effective approach for a distributed discovery of Semantic Web services (SWs), which address some aspects, related to problems the time complexity of collaboration in the process of automatic discovery for SWs in order to achieve adaptability in a highly-dynamic distributed computing. For this purpose, our approach is based on P2P computing that proved to be scalable, efficient and robust solutions for distributed discovery of SWs. Indeed, we propose a matching technique of ontology OWL-S process model, in order to efficiently and effectively discover appropriate Web services distributed among all peers in a large-size P2P network. For improving performance and effectiveness, our scalable approach is mapped on unstructured P2P networks by exploiting Pareto efficiency to reduce considerably the execution time and message exchanged for …",Adel Boukhadra and Karima Benatchba and Amar Balla,1,12470071825111472326,,,77-84,IEEE,Towards Efficient and Effective Distributed Discovery of SWs in P2P Overlay Networks,https://ieeexplore.ieee.org/abstract/document/7424545/,,2015,/scholar?cites=12470071825111472326,7iGY4M0AAAAJ:TQgYirikUcIC
1024053,"The work described in this paper is about building a general model capable of simulating human behaviour and emotions using virtual characters. To make the simulation realistic enough, virtual characters need to express emotions according to the environment and deal with those emotions in a parallel way where an emotional experience can be triggered at the same time as another emotional response. The virtual character will have perceptions, feel and express emotions and respond to different situations. To make the simulation realistic, we used a method allowing the virtual characters to execute tasks, perceive events and display emotions in a parallel way. To do that, we used the multiple resources model [1] to control the attention and to predict when two or more actions can be executed at the same time. The used emotional model is based on Scherer's theory [2]. However, in this paper we focus on the …",Mohamed Redha Sidoumou and Scott Turner and Phil Picton and Kamal Bechkoum and Karima Benatchba,1,11328710076051531649,,,308-314,IEEE,Multitasking in emotion modelling: Attention Control,https://ieeexplore.ieee.org/abstract/document/7344588/,,2015,/scholar?cites=11328710076051531649,7iGY4M0AAAAJ:-f6ydRqryjwC
1024054,"Palmprint is one of the modalities that offer high recognition accuracy. The recognition process depends on an optimized ROI (Region of Interest) extraction. This extraction is affected by several factors including the device used and the acquisition conditions. The acquisition step can alter some image properties like rotation, translation and scale. Some devices are designed to maintain hand in a fixed position and delimit a subspace of the hand. On the other hand, contactless devices offer more convenience and flexibility but lead to altered images. ROI extraction methods must consider the acquisition device (with contact or contactless). In this paper, we propose palmprint recognition system considering this issue. A ROI extraction method is implemented and tested on different databases taking into account the acquisition device with different sensor conditions. Our research to test this method, are conducted on …",Artabaz Saliha and Dellys Hachemi Nabil and Benatchba Karima and Koudil Mouloud and Bouridane Ahmed,1,11108911744637926528,Journal of Information Assurance & Security,3,,,Palmprint recognition system: Case Study with different databases.,http://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=15541010&AN=102127408&h=LOHom5xdfT4BhTn7blRrpy7SO4aY4I4GCsEXat1ad%2FXt2pV%2BYqVrKCufs22wLsFwAXjOYbEMrNYnGf9ZSwsQWA%3D%3D&crl=c,10,2015,/scholar?cites=11108911744637926528,7iGY4M0AAAAJ:d1gkVwhDpl0C
1024055,"Recent works in combinatorial optimization shows that the cooperation of activities allows obtaining good results. In this work, we are interested in a parallel cooperation between Ant Colony System (ACS) and Marriage in honey Bees Optimisation (MBO) for the resolution of the graph coloring problem (GCP). We first present two ACS new strategies (ACS1 and ASC2) and an MBO approach (BeesCol) for the GCP, then, we offer several collaboration modes and parallelisation for the proposed methods using a parallel machine simulated on a cluster of PCs. An empirical study is undertaken for each method. Moreover, to test our approach, we have also implemented effective algorithms for the GCP. A comparison between the different algorithms shows that ACS1 (construction strategy) gives best results and is quite fast compared to other methods. Moreover, the parallel implementation of ACS reduces …",Malika Bessedik and Asma Daoudi and Karima Benatchba,1,2143033540354118721,,,179-190,"Springer, Cham",A Cooperative Approach Using Ants and Bees for the Graph Coloring Problem,https://link.springer.com/chapter/10.1007/978-3-319-01692-4_14,,2014,/scholar?cites=2143033540354118721,7iGY4M0AAAAJ:_kc_bZDykSQC
1024056,"Detection of moving objects in a video sequence is a growing field, used in various domains. There are, in the literature, several approaches to detect such movements. In this paper, we will focus on one of these approaches namely block matching. We propose to speed the performances of the block matching algorithm using the Bees' Algorithm which is known for its efficient exploration of search space as it uses two interesting strategies intensification and diversification. The proposed algorithm, BAforBM, is evaluated and compared to two existing ones: genetic bloc matching algorithm and a block matching algorithm based on PSO (Particule Swarm Optimisation).",Daoud Boumazouza and Yasmine Sefouane and Mohamed Djeddi and Boualem Khelouat and Karima Benatchba,1,5116280346529272207,,,2390-2394,IEEE,Bees for block matching,https://ieeexplore.ieee.org/abstract/document/6699505/,,2013,/scholar?cites=5116280346529272207,7iGY4M0AAAAJ:aqlVkmm33-oC
1024057,"In this paper we present a study that looks at modelling drivers’ behaviour with a view to contribute to the problem of road rage. The approach we adopt is based on agent technology, particularly multi-agent systems. Each driver is represented by a software agent. A virtual environment is used to simulate drivers’ behaviour, thus enabling us to observe the conditions leading to road rage. The simulated model is then used to suggest possible ways of alleviating this societal problem. Our agents are equipped with an emotional module which will make their behaviours more human-like. For this, we propose a computational emotion model based on the OCC model and probabilistic cognitive maps. The key influencing factors that are included in the model are personality, emotions and some social/personal attributes.",Mohamed Redha Sidoumou and Kamal Bechkoum and Karima Benatchba,1,18412565321296835334,,,1-15,"Springer, Heidelberg",Drivers’ behaviour modelling for virtual worlds,https://link.springer.com/chapter/10.1007/978-3-319-00804-2_1,,2013,/scholar?cites=18412565321296835334,7iGY4M0AAAAJ:KlAtU1dfN6UC
1024058,"Meta-heuristics are high-level methods widely used in different fields of applications. To enhance their performance, they are often combined to concepts borrowed from machine learning and statistics in order to improve the quality of solutions and/or reduce the response time.In this paper, we investigate the use of feature selection to speed-up the search process of Bee Swarm Optimisation (BSO) meta-heuristic in solving the MaxSAT problem.The general idea is to extract a subset of the most relevant features that describe an instance of a problem in order to reduce its size.We propose to translate a MaxSAT instance into a dataset following one of several representations proposed in this study, and then apply a FS technique to select the most relevant variables or clauses. Two data organizations are proposed depending on whether we want to remove variables or clauses …",Souhila Sadeg and Leila Hamdad and Hadjer Chettab and Karima Benatchba and Zineb Habbas and M-Tahar Kechadi,0,,Memetic Computing,4,283-298,Springer Berlin Heidelberg,Feature selection based bee swarm meta-heuristic approach for combinatorial optimisation problems: a case-study on MaxSAT,https://link.springer.com/article/10.1007/s12293-020-00310-9,12,2020,,7iGY4M0AAAAJ:l7t_Zn2s7bgC
1024059,"Several metaheuristics can be considered for solving a given optimization problem. Unfortunately none of them is better on all instances. Selecting a priori the best metaheuristic for a given instance is a difficult task which can be addressed using meta-learning. In this work, we propose a method to recommend, for a MaxSAT instance, the best metaheuristic among three: Genetic Algorithm (GA), Bee Swarm Optimization (BSO) and Greedy Randomized Adaptive Search Procedure (GRASP). Basically, a learning model is trained to induce associations between MaxSAT instances’ characteristics and metaheuristics’ performances. The built model is able to select the best metaheuristic for a new MaxSAT instance. We experiment different learning algorithms on different instances from several benchmarks. Experimental results show that the best metaheuristic is selected with a prediction rate exceeding 80% regardless …",Souhila Sadeg and Leila Hamdad and Omar Kada and Karima Benatchba and Zineb Habbas,0,,,,122-135,"Springer, Cham",Meta-learning to Select the Best Metaheuristic for the MaxSAT Problem,https://link.springer.com/chapter/10.1007/978-3-030-58861-8_9,,2020,,7iGY4M0AAAAJ:K3LRdlH-MEoC
1024060,"Recently, electroencephalogram (EEG) has been used as a biometric modality. An EEG-based biometric system allows an automatic recognition of people based on their EEG signals. The quantity and quality of identity information extracted from EEG determine the performance of the EEG-based biometric system. In this paper, we evaluate the loss in identity information through different signal segmentation scenarios using Autoregressive model and K-Nearest Neighbor classifier. Our objective is to find some criteria linked to data segmentation allowing to reduce as far as possible the simulated loss of identity information. Experiments were conducted on EEG publicly available datasets collected in resting state for both opened and closed eyes. Results show that overlapped segmentation with longer segments’ length stands the best to the simulated loss favoring larger percentages of overlap.",Meriem Romaissa Boubakeur and Guoyin Wang and Ke Liu and Karima Benatchba,0,,,,201-211,"Springer, Cham",Evaluation of Identity Information Loss in EEG-Based Biometric Systems,https://link.springer.com/chapter/10.1007/978-3-030-37078-7_20,,2019,,7iGY4M0AAAAJ:P5F9QuxV20EC
1024061,"In this paper, we propose HHGA, a new hyper-heuristic for the Permutation Flowshop Problem with makespan minimization. It consists of a high-level genetic algorithm which goal is to tailor a dedicated and effective genetic algorithm for each instance. The goal of the proposed hyper-heuristic is to find among a set of genetic operators, a configuration that is suitable for solving a PFSP problem instance and compare the tailored GAs to investigate the existence of any patterns. Our experiments on well-known Taillard’s benchmark showed the performance of tailored GAs. HHGA was able to build genetic algorithms that reached optimal solutions in 50 instances out of 120 and was at least as good as state-of-the-art approaches. Through results, we show also the performance of some operators compared to others.",Sarra Zohra Ahmed Bacha and Mohamed Walid Belahdji and Karima Benatchba and Fatima Benbouzid-Si Tayeb,0,,,C,1365-1374,,A New Hyper-Heuristic to Generate Effective Instance GA for the Permutation Flow Shop Problem,https://dl.acm.org/doi/abs/10.1016/j.procs.2019.09.307,159,2019,,7iGY4M0AAAAJ:738O_yMBCRsC
1024062,"In this paper, we propose HHGA, a new hyper-heuristic for the Permutation Flowshop Problem with makespan minimization. It consists of a high-level genetic algorithm which goal is to tailor a dedicated and effective genetic algorithm for each instance. The goal of the proposed hyper-heuristic is to find among a set of genetic operators, a configuration that is suitable for solving a PFSP problem instance and compare the tailored GAs to investigate the existence of any patterns. Our experiments on well-known Taillard’s benchmark showed the performance of tailored GAs. HHGA was able to build genetic algorithms that reached optimal solutions in 50 instances out of 120 and was at least as good as state-of-the-art approaches. Through results, we show also the performance of some operators compared to others.",Sarra Zohra Ahmed Bacha and Mohamed Walid Belahdji and Karima Benatchba and Fatima Benbouzid-Si Tayeb,0,,Procedia Computer Science,,1365-1374,Elsevier,A New Hyper-Heuristic to Generate Effective Instance GA for the Permutation Flow Shop Problem,https://www.sciencedirect.com/science/article/pii/S1877050919315078,159,2019,,7iGY4M0AAAAJ:1sJd4Hv_s6UC
1024063,"The spatial data mining (SDM) is a process that extracts knowledge from large volumes of spatial data. It takes into account the spatial relationships between the data. To integrate these relations in the mining process, SDM uses two main approaches: Static approach that integrates spatial relationships in a preprocessing phase, and dynamic approach that takes into consideration the spatial relationship during the process. In this work, we are interested in this last approach. Our proposition consists on taking into consideration the spatial component in the similarity measure. We propose two similarity measures; , . We will use those distances on the main task of SDM, spatial clustering, particularly on K-means algorithm. Moreover, a comparaison between these two approaches and other methods of clustering will be given. The tests are conducted on Boston dataset with 590 objects.",Leila Hamdad and Karima Benatchba and Soraya Ifrez and Yasmine Mohguen,0,,,,25-36,"Springer, Cham",Similarity Measures for Spatial Clustering,https://link.springer.com/chapter/10.1007/978-3-319-89743-1_3,,2018,,7iGY4M0AAAAJ:bFI3QPDXJZMC
1024064,"Chaff-points generation is one of the most important steps in the fuzzy vault encryption process. This phase is time and computational resource consuming. Several methods were proposed in the literature to optimize this step for resource constrained environments. The challenge is to generate the desired number of chaff-points in a minimum and homogeneous time and a minimum amount of computational re-sources. In this paper, we propose a new chaff-points generation method based on genetic algorithm and non-fixed squares boundaries for resource constrained devices. The obtained results showed that our method gives the desired number of chaff-points in a better time than other methods.",Hachemi Nabil Dellys and Karima Benatchba and Layth Sliman and Yen Wei Chen,0,,,,1-4,IEEE,Chaff-Points Generation Method Based on Adaptive Genetic Algorithms and Non-Fixed Size Squares Boundaries for Resource Constrained Devices,https://ieeexplore.ieee.org/abstract/document/8328727/,,2018,,7iGY4M0AAAAJ:D03iK_w7-QYC
1024065,"In Service Computing (SC), online Semantic Web services (SWs) is evolving over time and the increasing number of SWs with the same function on the Internet, a great amount of candidate services emerge. So, efficiency and effectiveness has become a stern challenge for distributed discovery to tackle uniformed behavior evolution of service and maintain high efficiency for large-scale computing. The distributed discovery of SWs according to their functionality increases the capability of an application to fulfill their own goals. In this paper, we describe an efficient and an effective approach for improving the performance and effectiveness of distributed discovery of SWs in P2P systems. As most Web services lack a rich semantic description, we extend the distributed discovery process by exploiting collaborative ranking to estimate the similarity of a SWs being used by existing hybrid matching technique of …",Adel Boukhadra and Karima Benatchba and Amar Balla,0,,,,13-22,"Springer, Cham",A Dynamic Model to enhance the Distributed Discovery of services in P2P Overlay Networks,https://link.springer.com/chapter/10.1007/978-3-319-48829-5_2,,2016,,7iGY4M0AAAAJ:L8Ckcad2t8MC
1024066,"In this paper, we study the impact of GAs’ components such as encoding, different crossover, mutation and replacement strategies on the number of extracted association rules and their quality. Moreover, we propose a strategy to manage the population. The later is organized in classes where each one encloses same size rules. Each class can be seen as a population on which a GA is applied. All tests are conducted on two types of benchmarks : synthetic and real ones of different sizes.",Zakaria Ournani and Karima Benatchba and Ahcène Bendjoudi and Leila Hamdad,0,,,CERIST-DTISI-16-000000015--DZ,,CERIST,Impact of Genetic Algorithms Operators on Association Rules Extraction,http://scholar.google.com/scholar?cluster=4610968161968659071&hl=en&oi=scholarr,,2016,,7iGY4M0AAAAJ:UxriW0iASnsC
1024067,"In this paper, the main purpose and work is to propose scheduling algorithm based on the non-cooperative game theory for the integrated permutation flowshop problem with preventive maintenance. The goal is to optimize two criteria simultaneously: minimization of total completion time (makespan) for production part and minimization of total Earliness/Tardiness of PM activities for maintenance part. Moreover, to cope with the concept of game types we proposed two player behaviors: non-rational and rational behavior. In this research, the Nash equilibrium in game theory based approach is used to deal with the multiple objectives. Computational experiment on both standard PFSP problems and non- standard PM instances shows the effectiveness of the proposed solving algorithms.",Fatima Benbouzid-Si Tayeb and Abdessalam Messiaid and Karima Benatchba,0,,,,5184-5189,IEEE,Game theoretic modelling of the integrated production and preventive maintenance scheduling problem in permutation flowshops,https://ieeexplore.ieee.org/abstract/document/7403030/,,2015,,7iGY4M0AAAAJ:HDshCWvjkbEC
1024068,,Badiâa Hedjazi and Samir Aknine and Karima Benatchba,0,,,,,,ARTIFICIAL FINANCIAL MARKET. Risk Analysis Approach,https://hal.archives-ouvertes.fr/hal-01184566/,,2015,,7iGY4M0AAAAJ:Wp0gIr-vW9MC
1024069,"Image segmentation is a central problem in image analysis. It consists of extracting objects from an image and separating between the background and the regions of interest. In the literature, there are mainly two dual approaches, namely the region-based segmentation and the edge-based segmentation. In this article, we propose to take advantage of Game theory in image segmentation by results fusion. Thus, the presented game is cooperative in a way that both players represented by the two segmentation modules (region-based and edge-based) try coalitionary to enhance the value of a common characteristic function. This is a variant of the parallel decision-making procedure based on Game theory proposed by Chakraborty and Duncan [1]. The involved pixels are those generated from the cooperation by results fusion between the edge detector (Active contour) and the region detector (Region …",Omar Boudraa and Karima Benatchba,0,,,,515-526,"Springer, Cham",Region-Edge Cooperation for Image Segmentation Using Game Theory,https://link.springer.com/chapter/10.1007/978-3-319-19578-0_42,,2015,,7iGY4M0AAAAJ:ULOm3_A8WrAC
1024070,"Financial market is in constant confrontation with various financial risks. These contribute to market instabilities, financial crises and substantial losses for investors. To effectively manage these risks, we should understand the complexity of the market due to its evolution in an uncertain environment. This is possible through multi-agent modeling and simulation while taking into consideration risk indicators. We, propose, in this paper, to model a financial market simulation system using a multi-agent model, where agents represent the different market participants. The reasoning model of our agents is based on different risk indicators. We use the classifier systems as reasoning and learning model for the cognitive agents of our system. This system is a decision tool dedicated to managers or experts wanting to analyze and understand through the behaviour of the different participants, the evolution of the global dynamics of the market and the influence of the different risk factors on the market and on the various categories of market participants.",Karima Benatchba and Samir Aknine and Badiâa Hedjazi Dellal,0,,,ISRN CERIST-DSISM/RR--15-000000020--DZ,,CERIST,Artificial financial market. Risk analysis approach,http://scholar.google.com/scholar?cluster=6744709482495923200&hl=en&oi=scholarr,,2015,,7iGY4M0AAAAJ:uWQEDVKXjbEC
1024071,"Due the increasing number of published Semantic Web services (SWs) rendered the distributed discovery within repositories a critical issue and a major problem that can reduce the capability and functionality of SWs in terms of efficiency and scalability. Peer-to-Peer (P2P) computing is considered as the most dominant technology to discover new distributed and heterogeneous collaborative applications for SWs. In this paper, we propose an efficient approach for improving the performance and effectiveness of automatic and cooperative discovery of large-scale distributed systems in the unstructured P2P networks. The approach exploits a scalable epidemic algorithm that uses different sources of network knowledge, such as exponential distribution, to fulfill the users requirements in order to ensure high recall, further reduce the number of messages exchanged and reduce the execution time for discovering SWs in the unstructured P2P network. In order to improve the applicability of the scalable epidemic algorithm for discovering SWs, we propose the semantic matching of OWL-S process model which improves the recall while keeping an acceptable matching quality level. The experimental results show that our efficient approach is able dynamically to adapt to network changes and preserve high levels of recall. c 2015 The Authors. Published by Elsevier BV Peer-review under responsibility of the Conference Program Chairs.",Adel Boukhadra and Karima Benatchba and Amar Balla,0,,,,317-324,,Similarity Flooding for Efficient Distributed Discovery of OWL-S Process Model in P2P Networks.,https://core.ac.uk/download/pdf/82418082.pdf,,2015,,7iGY4M0AAAAJ:RHpTSmoSYBkC
1024072,"The Web services technology is now widely used in support of interoperability between distributed and heterogeneous applications. With the evolution of Semantic Web services (SWs) within organizations and their uses in a large-scale, composition of services in a distributed setting has become a real challenge. A mechanism for automatic composition of SWs according to their functionality is necessary, since the features are the most important thing that partners seek. In this paper, we describe a distributed approach to automatic composition of SWs, which supports the complexity of both SWs and the task at hand. The approach is based on the notion of alignment of OWL-S, in order to achieve semantic interoperability in a heterogeneous and distributed architecture, to ensure correct operation of Web services provided, and meet the needs and users’ preferences. The objective is to optimize the time of the completion of the automatic composition of SWs, and to overcome the problem of communication within and between SWs and network saturation.",Adel Boukhadra and Karima Benatchba and Amar Balla,0,,,,,,A Distributed Framework for Semantic Web services Automatic Discovery and Composition Based on Matching of OWL-S,http://infonomics-society.ie/wp-content/uploads/ijmip/published-papers/volume-4-2014/A-Distributed-Framework-for-Semantic-Web-services-Automatic-Discovery-and-Composition-Based-on-Matching-of-OWL-S.pdf,,2014,,7iGY4M0AAAAJ:e5wmG9Sq2KIC
1024073,"B&B algorithms are well known techniques for exact solving of combinatorial optimization problems (COP). They perform an implicit enumeration of the search space instead of exhaustive one. Based on a pruning technique, they reduce considerably the computation time required to explore the whole search space. Nevertheless, these algorithms remain inefficient when dealing with large combinatorial optimization instances. They are time-intensive and they require a huge computing power to be solved optimally. Nowadays, multi-core-based processors and GPU accelerators are often coupled together to achieve impressive performances. However, classical B&B algorithms must be rethought to deal with their two divergent architectures. In this paper, we propose a new B&B approach exploiting both the multi-core aspect of actual processors and GPU accelerators. The proposed approaches have been executed to solve FSP instances that are well-known combinatorial optimization benchmarks. Real experiments have been carried out on an Intel Xeon 64-bit quad-core processor E5520 coupled to an Nvidia Tesla C2075 GPU device. The results show that our hybrid B&B approach speeds up the execution time up to x123 over the sequential mono-core B&B algorithm.",Nouredine Melab and Fatima Sitayeb-Benbouzid and Karima Benatchba and Makhlouf Gharbi and Malika Mehdi and Mehdi Chekini and Ahcène Bendjoudi,0,,IEEE International Conference on High Performance Computing and Communications,,,IEEE,Parallel B&B Algorithm on Hybrid Multicore/GPU Architecture,http://scholar.google.com/scholar?cluster=6163915812921612777&hl=en&oi=scholarr,15,2013,,7iGY4M0AAAAJ:SP6oXDckpogC
1024074,"Author Index Aguiar, Rui L. 143 Bai, Yang 267 Bart Jr., Henry 215 Batnyam, Nomin 171 
Bechkoum, Kamal 1 Benatchba, Karima 1 Bhuyan, MK 103, 115 Chen, Yi 231 Chen, Yixin 215 
Cheng, Jingde 17 Church, James 215 Cruz, Christophe 267 Dang, Xin 215 Davis, Spencer 231 
Dbouk, Mohamed 201 de Barros, Roberto Souto Maior 129 Du, Wencai 267 Duan, Yucong 267 
Elfaki, Abdelrahman Osman 267 Fukui, Shinji 103 Furukawa, Zengo 187 Gantulga, Ariundelger 
171 Goto, Yuichi 17 Hochin, Teruhisa 51 Inaba, Hiroyuki 77 Ishida, Shuya 103 Ishii, Naohiro 
159 Iwahori, Yuji 103, 115 Iwashita, Motoi 247 Jiang, Hai 231 Júnior, Paulo Mauricio Gonçalves 
129 Kanai, Atsushi 247 Karawash, Ahmad 201 Kawaguchi, Masashi 159 Keiki, Takadama 259 
Kimura, Satoshi 77 Li, Kuan-Ching 231 Liu, Dapeng 33 Liu, Huafu 33 Matsui, Shinsuke 247 
Mcheick, Hamid 201 Murai, Chihiro 247 Nakagawa, Takuya 115 Nomiya, Hiroki 51 Oh … ",Kamal Bechkoum and Karima Benatchba and MK Bhuyan and Yi Chen and Yixin Chen and Jingde Cheng and James Church and Christophe Cruz and Xin Dang and Spencer Davis and Mohamed Dbouk and Roberto Souto Maior de Barros and Wencai Du and Yucong Duan and Abdelrahman Osman Elfaki and Shinji Fukui and Zengo Furukawa and Ariundelger Gantulga and Yuichi Goto and Teruhisa Hochin and Hiroyuki Inaba and Shuya Ishida and Naohiro Ishii and Atsushi Kanai and Ahmad Karawash and Masashi Kawaguchi and Takadama Keiki and Satoshi Kimura and Kuan-Ching Li and Dapeng Liu and Huafu Liu and Shinsuke Matsui and Hamid Mcheick and Chihiro Murai and Takuya Nakagawa and Hiroki Nomiya and Sejong Oh and Óscar Mortágua Pereira and Zhi Qiao and Khan Md Mahfuzus Salam and Maribel Yasmina Santos and Hiroyuki Sato and Ray Schmidt and Yosiaki Seki and Kai Shi,0,,Computer and Information Science,,279,Springer,"Aguiar, Rui L. 143 Bai, Yang 267 Bart Jr., Henry 215 Batnyam, Nomin 171",https://link.springer.com/content/pdf/10.1007/978-3-319-00804-2.pdf#page=281,493,2013,,7iGY4M0AAAAJ:hC7cP41nSMkC
1024075,"A net settlement system is a payment system between banks, where a large number of transactions are accumulated, usually waiting until the end of each day to be settled through payment instruments like: wire transfers, direct debits, cheques, .... These systems also provide clearing functions to reduce interbank payments but are sometimes exposed to liquidity risks. Monitoring, and optimizing the interbank exchanges through suitable tools is useful for the proper functioning of these systems. The goal is to add to these systems an intelligent software layer integrated with the existing system for the improvement of transactions processing and consequently avoid deadlock situations, deficiencies and improve system efficiency. We model and develop by multi-agent an intelligent tracking system of the interbank exchanged transactions to optimize payments settlement and minimize liquidity risks.",Badiâa Hedjazi and Mohamed Ahmed-Nacer and Samir Aknine and Karima Benatchba,0,,,,103-114,"Springer, Berlin, Heidelberg",Multi-Agent liquidity risk management in an interbank net settlement system,https://link.springer.com/chapter/10.1007/978-3-642-35236-2_11,,2012,,7iGY4M0AAAAJ:4JMBOYKVnBMC
1024076,"Open complex systems such as financial markets evolve in highly dynamic and uncertain environments. They are often subject to significant fluctuations due to unanticipated behaviours and information. Modelling and simulating these systems by means of multi-agent systems, i.e., through artificial markets is a valuable approach. Initial Public Offering (IPO) is a process based on finding a reasonable offering price or the price of the first assets sale by a firm to public. The study of the firms' strategic choices at the IPO requires the use of formal tools like game theory. This article is about the study, analysis and simulation of a firm's dynamic evolution at IPO using the EGT (Evolutionary Game Theory) as a formal framework for IPO strategies (offering prices) through modeling a financial market by multi-agent system. The firm in the system is a cognitive agent built around a classifier system. Simulations with our prototype …",Badiâa Hedjazi and Mohamed Ahmed-Nacer and Samir Aknine and Karima Benatchba,0,,,,236-242,IEEE,Initial Public Offering (IPO) pricing using a multi-agent system,https://ieeexplore.ieee.org/abstract/document/6511576/,2,2012,,7iGY4M0AAAAJ:4TOpqqG69KYC
1024077,"Open complex systems such as financial markets evolve in highly dynamic and uncertain environments. They are often subject to significant fluctuations due to unanticipated behaviours and information. Modelling and simulating these systems by means of multi-agent systems, i.e., through artificial markets is a valuable approach. Initial Public Offering (IPO) is a process based on finding a reasonable offering price or the price of the first assets sale by a firm to public. The study of the firms' strategic choices at the IPO requires the use of formal tools like game theory. This article is about the study, analysis and simulation of a firm's dynamic evolution at IPO using the EGT (Evolutionary Game Theory) as a formal framework for IPO strategies (offering prices) through modeling a financial market by multi-agent system. The firm in the system is a cognitive agent built around a classifier system. Simulations with our prototype allow us to deduce the factors that cause IPO under pricing.",Badiaa Hedjazi and M Ahmed-Nacer and Samir Aknine and K Benatchba,0,,,,,,Game theory for Initial Public Offering (IPO): A multi-agent approach,https://hal.archives-ouvertes.fr/hal-01353070/,,2012,,7iGY4M0AAAAJ:Zph67rFs4hoC
1024078,"This work consists in simulating a real time interbank gross payment system (RTGS) through a multi-agent model, to analyze the evolution of the liquidity brought by the banks to the system. In this model, each bank chooses the amount of a daily liquidity provided in the system on the basis of costs minimization (costs of liquidity and delaying) by taking into account the liquidity brought by the other banks. Banks agents reasoning is based on a repeated aggregate game of over several payment days where each bank plays against the other banks. For adaptive behaviour we integrate into bank agents a learning classifier system. We carry out then several simulations to follow the system total liquidity evolution as that of each bank agent with varying costs coefficients. The question to be answered is: what are the cash amounts that banks must provide and under what constraints (costs of liquidity and delaying) the system beyond the lack of liquidity (illiquidity)? We find that liquidity e volution depends on costs coefficients.",Badiaa Hedjazi and Mohamed Ahmed-Nacer and Samir Aknine and Karima Benatchba,0,,,,,,Interbank Payment System (RTGS) Simulation Using a Multi-agent Approach,https://hal.archives-ouvertes.fr/hal-01353081/,,2012,,7iGY4M0AAAAJ:mB3voiENLucC
1024079,"This work consists in simulating a real time interbank gross payment system (RTGS) through a multi-agent model, to analyze the evolution of the liquidity brought by the banks to the system. In this model, each bank chooses the amount of a daily liquidity on the basis of costs minimization (costs of liquidity and delaying) by taking into account the liquidity brought by the other banks. Banks agents’ strategies are based on a liquidity game during several payment days where each bank plays against the others. For their adaptability, we integrate into bank agents learning classifier systems. We carry out several simulations to follow the system total liquidity evolution as that of each bank agent with varying costs coefficients. The question to answer is: what are the cash amounts that banks must provide and under what costs of liquidity and delaying, the system avoids the lack of liquidity? We find that liquidity depends on costs coefficients.",Karima Benatchba and Samir Aknine and Mohamed Ahmed-Nacer and Badiâa Hedjazi Dellal,0,,,CERIST-DSISM/RR--12-000000029--dz,,CERIST,Game theory for Initial Public Offering (IPO): A multi-agent approach,http://scholar.google.com/scholar?cluster=16344553783746157142&hl=en&oi=scholarr,,2012,,7iGY4M0AAAAJ:p2g8aNsByqUC
1024080,"A net settlement system is a payment system between banks, where a large number of transactions are accumulated, usually waiting until the end of each day to be settled through payment instruments like: wire transfers, direct debits, cheques, .... These systems also provide clearing functions to reduce interbank payments but are sometimes exposed to liquidity risks. Monitoring, and optimizing the interbank exchanges through suitable tools is useful for the proper functioning of these systems. The goal is to add to these systems an intelligent software layer integrated with the existing system for the improvement of transactions processing and consequently avoid deadlock situations, deficiencies and improve system efficiency. We model and develop by multi-agent an intelligent tracking system of the interbank exchanged transactions to optimize payments settlement and minimize liquidity risks.",Karima Benatchba and Samir Aknine and Mohamed Ahmed-Nacer and Badiâa Hedjazi Dellal,0,,,,,Springer Berlin Heidelberg,Multi-agent liquidity risk management in an interbank net settlement system,http://scholar.google.com/scholar?cluster=10182154991859615926&hl=en&oi=scholarr,,2012,,7iGY4M0AAAAJ:OU6Ihb5iCvQC
1024081,"Open complex systems as financial markets evolve in a highly dynamic and uncertain environment. They are often subject to significant fluctuations due to unanticipated behaviours and information. Modelling and simulating these systems by means of agent systems, i.e., through artificial markets is a valuable approach. In this article, we present our model of asynchronous artificial market consisting of a set of adaptive and heterogeneous agents in interaction. These agents represent the various market participants (investors and institutions). Investor Agents have advanced mental models for ordinary investors which do not relay on fundamental or technical analysis methods. On one hand, these models are based on the risk tolerance and on the other hand on the information gathered by the agents. This information results from overhearing influential investors in the market or the order books. We model the system through investor agents using learning classifier systems as reasoning models. As a result, our artificial market allows the study of overhearing impacts on the market. We also present the experimental evaluation results of our model.",Karima Benatchba and Samir Aknine and Mohamed Ahmed-Nacer and Badiâa Hedjazi Dellal,0,,,,342-350,SciTePress Science and Technology Publications,OVERHEARING IN FINANCIAL MARKETS: A Multi-agent Approach,http://scholar.google.com/scholar?cluster=6206062854181514492&hl=en&oi=scholarr,2,2011,,7iGY4M0AAAAJ:hFOr9nPyWt4C
1024082,"Open complex systems as financial markets evolve in a highly dynamic and uncertain environment. They are often subject to significant fluctuations due to unanticipated behaviours and information. Modelling and simulating these systems by means of agent systems, i.e., through artificial markets is a valuable approach. In this article, we present our model of asynchronous artificial market consisting of a set of adaptive and heterogeneous agents in interaction. These agents represent the various market participants (investors and institutions). Investor Agents have advanced mental models for ordinary investors which do not relay on fundamental or technical analysis methods. On one hand, these models are based on the risk tolerance and on the other hand on the information gathered by the agents. This information results from overhearing influential investors in the market or the order books. We model the system through investor agents using learning classifier systems as reasoning models. As a result, our artificial market allows the study of overhearing impacts on the market. We also present the experimental evaluation results of our model.",Karima Benatchba and Samir Aknine and Mohamed Ahmed-Nacer and Badiâa Hedjazi Dellal,0,,,CERIST-DSISM/RR--10-000000019--dz,,CERIST,Overhearing in financial markets: a multi-agent approach markets: a multi-agent approach,http://scholar.google.com/scholar?cluster=3090399722652632769&hl=en&oi=scholarr,,2010,,7iGY4M0AAAAJ:dshw04ExmUIC
1024083,,Karima Benatchba and Lotfi Admane and Mouloud Koudil,0,,Lecture Notes in Computer Science,,212-220,"Berlin: Springer-Verlag, 1973-",Evolutionary Computation-Using Bees to Solve a Data-Mining Problem Expressed as a Max-Sat One,http://scholar.google.com/scholar?cluster=5019081219868709177&hl=en&oi=scholarr,3562,2005,,7iGY4M0AAAAJ:EUQCXRtRnyEC
1024084,"Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut être utilisé dans le cadre d’une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya señalado antes, el contenido de este registro bibliográfico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS",K BENATCHBA and A BENKRID and M KOUDIL,0,,TSI. Technique et science informatiques,6,699-720,,FO+ outil d'insertion automatique de points de test dans des circuits combinatoires,https://pascal-francis.inist.fr/vibad/index.php?action=getRecordDetail&idt=2367092,17,1998,,7iGY4M0AAAAJ:dhFuZR0502QC
1024085,"Cet article présente quelques solutions ayant pour but d'améliorer la testabilité des circuits combinatoires testés de manière pseudo-aléatoire. S'inscrivant dans l'approche Force-Observe, les solutions préconisées consistent en la modzjlcation des circuits par l'insertion de deux types de points de test: les points d'observation et les points de contrôle.",Karima BENATCHBA and Abdelhak BENKRID and Mouloud KOUDIL,0,,,,617-628,,Techniques d'insertion automatique de points de test dans des circuits combinatoires,http://horizon.documentation.ird.fr/exl-doc/pleins_textes/pleins_textes_6/colloques2/010008770.pdf,,1996,,7iGY4M0AAAAJ:_Qo2XoVZTnwC
1024086,,Karima Benatchba,0,,,,,,Algorithm for testing physical failure in VLSI digital circuits,http://scholar.google.com/scholar?cluster=7198650129267327138&hl=en&oi=scholarr,,1989,,7iGY4M0AAAAJ:9ZlFYXVOiuMC
1024087,"Tiramisu is a polyhedral compiler for generating fast code. It provides high level scheduling commands to optimize programs. Selecting what scheduling commands to apply to a piece of code, the parameters of those commands, and the ordering between them is a challenging task. It requires substantial time, effort, and expertise to construct beneficial combinations of optimizations that improve the run-time of the program. Our work is an attempt to automate code optimization within the Tiramisu framework, by leveraging the advances in deep learning techniques. More concretely, we aim to use a neural-network-based cost model to evaluate schedules, which would allow fast and efficient search space exploration to find well-performing schedules for an input program. We developed a code generation module for Tiramisu and used it to construct a starting dataset to train our neural network.",Mohammed Henni and Ilhem I Mekki and Riyadh Baghdadi and Taha Arbaoui and Karima Benatchba and Saman Amarasinghe,0,,,,,,A deep learning approach for automatic code optimization in Tiramisu,https://www.researchgate.net/profile/Henni_Mohammed/publication/336568297_A_Deep_Learning_Approach_for_Automatic_Code_Optimization_in_the_Tiramisu_Compiler/links/5da64fa0a6fdccdad5460ca0/A-Deep-Learning-Approach-for-Automatic-Code-Optimization-in-the-Tiramisu-Compiler.pdf,,,,7iGY4M0AAAAJ:u9iWguZQMMsC
1024088,"Les accélérateurs matériels ont été depuis longtemps utilisés pour booster les performances dans les MPSoC. Cependant, ces derniers introduisent un surplus d’occupation de surface sur ces systèmes. Le travail présenté dans cet article présente un outil pour trouver un compromis entre l’accélération apportée par ces accélérateurs matériels et la surface occupée par ces derniers. Pour ce faire, nous proposons d’utiliser un nouveau type d’architectures basé sur le partage d’accélérateurs matériels. Nous présentons une approche d’exploration de l’espace de conception (ou DSE pour Design Space Exploration) basée sur un algorithme génétique hybridé à un nouveau type de recherche locale (PVNS), pour l’exploration bi-objectif de l’espace de conception, dans les architectures à base de partage d’accélérateurs matériels. L’approche proposée a été testée sur trois applications: le Multiple Target Tracking (MTT), le JPEG et une application synthétique. Notre algorithme apporte un gain en temps d’exploration pouvant atteindre les 99.86% par rapport aux travaux existants basés sur un modèle mixte de programmation linéaire en nombres entiers (MILP), tout en y ajoutant la considération de la contrainte d’accélération. Cette approche permet une réduction de la surface occupée par les accélérateurs pouvant atteindre les 81, 48%, par rapport à une implémentation sans partage d’accélérateurs.",Braham Lotfi Mediouni and Smail Niar and Rachid Benmansour and Karima Benatchba and Mouloud Koudil,0,,,,,,Approche Bi-objectif pour l’Exploration de l’Espace de Conception dans les MPSoC Hétérogènes,https://www.researchgate.net/profile/Smail_Niar/publication/277707553_Approche_Bi-Objectif_pour_l'Exploration_de_l'Espace_de_Conception_dans_les_MPSoC_Heterogenes/links/55705cf508ae193af41ff4be.pdf,,,,7iGY4M0AAAAJ:a0OBvERweLwC
1024089,"In this work, we focus on image segmentation by simulating the natural phenomenon of the bodies’ movement in space. For this, a subset of image pixels is regularly selected as planets and the rest as satellites. The attraction force is defined by Newton’s third law (gravitational interaction) according to the distance and color similarity. In the first phase of the algorithm, we seek an equilibrium state of the earth-moon system in order to achieve the second phase, in which we search an equilibrium state of the earth-apple system. As a result of these two phases, bodies in space are constructed; they represent segments in the image. The objective of this simulation is to find and then extract the multiple segments from an image.",Charaf eddine Khamoudj and Karima Benatchba and Mohand tahar Kechadi,0,,,,,,Classical Mechanics Optimization for image segmentation,https://www.researchgate.net/profile/Charaf_Eddine_Khamoudj/publication/313566398_Classical_Mechanics_Optimization_for_Image_Segmentation/links/589e7b1e45851598bab44582/Classical-Mechanics-Optimization-for-Image-Segmentation.pdf,,,,7iGY4M0AAAAJ:dfsIfKJdRG4C
1024090,"Nowadays, there is an increasing trend in the use of solar energy by using photovoltaic system (PVS). The power generated by a PVS highly relies on solar intensity. Therefore, a Maximum Power Point Tracker (MPPT) is one of the key components of solar electricity generation. It is used to extract the maximum power point (MPP) produced by a PVS. In this paper, we present an intelligent Ant Colony Optimization (ACO) algorithm to track the MPP thereby increasing the performance of the PVS. The proposed ACO algorithm is developed in Matlab/Simulink environment. Furthermore, the results obtained from the ACO algorithm are compared with the well-known conventional Perturb and Observe (P&O) algorithm.",S TITRI and C LARBES and K YOUCEF TOUMI and K BENATCHBA,0,,,,,,AN IMPROVED MAXIMUM POWER POINT TRACKING BASED ANT COLONY OPTIMIZATION METAHEURISTIC ALGORITHM FOR PV SYSTEMS,http://scholar.google.com/scholar?cluster=9041076187220992359&hl=en&oi=scholarr,,,,7iGY4M0AAAAJ:4OULZ7Gr8RgC
